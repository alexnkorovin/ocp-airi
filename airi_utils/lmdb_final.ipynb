{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2182ae7-be2b-4e68-8c8d-ead0fb6ab762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lmdb\n",
    "import torch\n",
    "from ocpmodels.datasets import SinglePointLmdbDataset, TrajectoryLmdbDataset\n",
    "from open_lmdb import lmdb_dataset\n",
    "import time\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lmdb\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5ef90-7218-4f0a-8066-9b55ee16f681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = SinglePointLmdbDataset({\"src\": \"train/\"})\n",
    "# len(dataset)\n",
    "# datasets = {\n",
    "# 'train_10k': '../10k/train/data.lmdb',\n",
    "# 'train_100k': '../100k/train/data.lmdb',\n",
    "# 'train_all': '../all/train/data.lmdb',\n",
    "# 'val_id': '../all/val_id/data.lmdb',\n",
    "# 'val_ood_ads': '../all/val_ood_ads/data.lmdb'\n",
    "##  continue\n",
    "# `data/is2re/all/val_ood_cat/data.lmdb`\n",
    "# `data/is2re/all/val_ood_both/data.lmdb`\n",
    "# `data/is2re/all/test_id/data.lmdb`\n",
    "# `data/is2re/all/test_ood_ads/data.lmdb`\n",
    "# `data/is2re/all/test_ood_cat/data.lmdb`\n",
    "# `data/is2re/all/test_ood_both/data.lmdb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0cd6d-6e80-4fe6-a14a-303872d694e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k_old = SinglePointLmdbDataset({\"src\": \"../../ocp_datasets/data/is2re/10k/train/data.lmdb\"})\n",
    "# dataset_train_all = SinglePointLmdbDataset({\"src\": \"../../ocp_datasets/data/is2re/all/test_ood_cat/data.lmdb\"})\n",
    "# dataset_test_id = SinglePointLmdbDataset({\"src\": \"../../ocp_datasets/data/is2re/all/test_id/data.lmdb\"})\n",
    "# dataset_val_ood_both = SinglePointLmdbDataset({\"src\": \"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\"})\n",
    "# dataset_val_id = SinglePointLmdbDataset({\"src\": \"../../ocp_datasets/data/is2re/all/val_id/data.lmdb\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3feaeea-7734-4bbd-9ec5-9d0e1b03559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k = lmdb_dataset({\"src\": \"../../ocp_datasets/data/is2re/10k/train/data_mod.lmdb\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da6da1-0920-4e29-9f1c-49c8cf1d5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(dataset, idx=0):\n",
    "    dataset = dataset[idx]\n",
    "    print(f'item: {idx}')\n",
    "    for key in dataset.keys:\n",
    "        obj = dataset.__getitem__(key)\n",
    "        dot = 25\n",
    "\n",
    "        if type(obj) is Tensor:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{str(list(obj.shape)):>10}')\n",
    "        elif type(obj) is float:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{obj:>10.4f}')\n",
    "        else:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{obj:>10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd8c40-94bf-4a80-9be1-b789481007a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948ade3-8399-472e-a130-16c96f58525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_train_10k\n",
    "\n",
    "for item in range(len(dataset)):\n",
    "    for key in dataset.keys:\n",
    "            obj = dataset.__getitem__(key)\n",
    "            dot = 25\n",
    "\n",
    "            if type(obj) is Tensor:\n",
    "                print(f'{key}:{\".\"*(dot-len(key))}{str(list(obj.shape)):>10}')\n",
    "            elif type(obj) is float:\n",
    "                print(f'{key}:{\".\"*(dot-len(key))}{obj:>10.4f}')\n",
    "            else:\n",
    "                print(f'{key}:{\".\"*(dot-len(key))}{obj:>10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefab96-5138-498b-b1ae-e044f2d1b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lmdb.open(\n",
    "    \"sample_CuCO_test.lmdb\",\n",
    "    map_size=1099511627776 * 2,\n",
    "    subdir=False,\n",
    "    meminit=False,\n",
    "    map_async=True,\n",
    ")\n",
    "\n",
    "system_paths = [\"CuCO_adslab.traj\"]\n",
    "idx = 0\n",
    "\n",
    "for system in system_paths:\n",
    "    # Extract Data object\n",
    "    data_objects = read_trajectory_extract_features(a2g, system)\n",
    "    initial_struc = data_objects[0]\n",
    "    relaxed_struc = data_objects[1]\n",
    "    \n",
    "    initial_struc.y_init = initial_struc.y # subtract off reference energy, if applicable\n",
    "    del initial_struc.y\n",
    "    initial_struc.y_relaxed = relaxed_struc.y # subtract off reference energy, if applicable\n",
    "    initial_struc.pos_relaxed = relaxed_struc.pos\n",
    "    \n",
    "    # Filter data if necessary\n",
    "    # OCP filters adsorption energies > |10| eV\n",
    "    \n",
    "    initial_struc.sid = idx  # arbitrary unique identifier \n",
    "    \n",
    "    # no neighbor edge case check\n",
    "    if initial_struc.edge_index.shape[1] == 0:\n",
    "        print(\"no neighbors\", traj_path)\n",
    "        continue\n",
    "    \n",
    "    # Write to LMDB\n",
    "    txn = db.begin(write=True)\n",
    "    txn.put(f\"{idx}\".encode(\"ascii\"), pickle.dumps(initial_struc, protocol=-1))\n",
    "    txn.commit()\n",
    "    db.sync()\n",
    "    idx += 1\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0e199c2-d9bf-472b-a7e9-36c8982c91be",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# create DataFrame of .natom keys\n",
    "def natom_hist(dataset):\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    sec = time.time()\n",
    "    dic = defaultdict(int)\n",
    "    for struct in dataset:\n",
    "        dic[struct.natoms] += 1\n",
    "    print(time.time() - sec)\n",
    "\n",
    "    dic_mod = {k:[v] for k,v in dict(dic).items()}\n",
    "    return pd.DataFrame.from_dict(dic_mod, orient='index', columns=['N']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc892a1-af62-4e81-a6e3-4d5063b4ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def natom_hist(dataset):\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    sec = time.time()\n",
    "    dic = defaultdict(int)\n",
    "    for struct in dataset:\n",
    "        dic[struct.natoms] += 1\n",
    "    print(time.time() - sec)\n",
    "\n",
    "    dic_mod = {k:[v] for k,v in dict(dic).items()}\n",
    "    return pd.DataFrame.from_dict(dic_mod, orient='index', columns=['N']).sort_index()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18ac157b-498f-4773-9c7f-058594e50042",
   "metadata": {
    "tags": []
   },
   "source": [
    "# long time to run (~20 min)\n",
    "dataset_train_10k_df = natom_hist(dataset_train_10k)\n",
    "dataset_test_id_df = natom_hist(dataset_test_id)\n",
    "dataset_val_ood_both_df = natom_hist(dataset_val_ood_both)\n",
    "df_train_all_df.natom_hist(dataset_val_ood_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23ee39-9a84-481c-96ac-287054f3cd54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_distr(dic):\n",
    "    dic = pd.DataFrame.to_dict(dic)\n",
    "    key = list(dic.keys())[0]\n",
    "    dic1 = {key:{i:0 for i in range(1, 301)}}\n",
    "    \n",
    "    for k, v in dic[key].items():\n",
    "        dic1[key][k] = v\n",
    "    return pd.DataFrame.from_dict(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f0b07-4b71-4a8f-9ed6-d3eb031b0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (df_train_all, dataset_test_id_df, dataset_train_10k_df, dataset_val_ood_both_df)\n",
    "frames_distr = [0]*len(frames)\n",
    "for i, frame in enumerate(frames):\n",
    "    frames_distr[i] = df_distr(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555aa717-ff17-43e6-93d6-9ea14385eaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat(frames_distr, axis=1)\n",
    "df_all.columns = ['df_train_all', 'dataset_test_id_df', 'dataset_train_10k_df', 'dataset_val_ood_both_df']\n",
    "df_all_norm = df_all.fillna(0)\n",
    "df_all_norm = df_all_norm.apply(lambda x: x / x.max())\n",
    "df_all_norm.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e4aedfb-d042-4ced-aa46-3677dad15f5e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# alternative normalizing by sklearn\n",
    "from sklearn import preprocessing\n",
    "df_index = df_all.index.to_list()\n",
    "x = df_all.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_all_norm = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610cebf-ff90-4186-be01-26452f533a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train_keys_10k_keys = set(dataset_train_10k[0].keys)\n",
    "dataset_val_ood_both_keys = set(dataset_val_ood_both[0].keys)\n",
    "dataset_test_keys_id_keys = set(dataset_test_id[0].keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542c615-544c-435f-b813-e4063d862186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_keys_10k_keys, dataset_val_ood_both_keys, dataset_test_keys_id_keys, sep='\\n')\n",
    "print(dataset_train_keys_10k_keys - dataset_test_keys_id_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba76ae-5cda-4209-bd4f-d0c1eda52ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_10k[0])\n",
    "# for i in dataset_train_keys_10k_keys:\n",
    "#         print((i, getattr(dataset_train_10k[0], i)))\n",
    "\n",
    "for i in dataset_train_keys_10k_keys:\n",
    "        temp = getattr(dataset_train_10k[0], i)\n",
    "        print(i, temp)\n",
    "#         if type(temp) not in [float, int]:\n",
    "#             print(temp.shape)\n",
    "#         else: print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe6277-11bf-42d0-a346-d03653ed5e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train_10k[0].cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8889b5-8607-4467-959f-27d4d02d7b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Counter(list(dataset_train_10k[0].atomic_numbers))\n",
    "dataset_train_10k[0].atomic_numbers[0].item()\n",
    "Counter([dataset_train_10k[0].atomic_numbers[i].item() for i in range(dataset_train_10k[0].atomic_numbers.shape[0])])\n",
    "# compare = [(\"\\n\".join((getattr(dataset_train_10k[0], i), getattr(dataset_test[0], i)))) for i in dataset_test[0].keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974aa66-3d68-4973-bd59-756fb48eaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k[0].edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52481b2-87c6-4461-a0a9-314cea3d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k[0].natoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5209b-a250-4474-ac36-8aef799722d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "86**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99af59c-b4b2-4d75-bdfa-31acb01a049b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_10k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec8583-ba3e-4c3f-af04-51a604060f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dic = pd.read_pickle(\"/Users/korovin/Documents/GitHub/ocp_datasets/oc20_data_mapping.pkl\")\n",
    "# or use online https://dl.fbaipublicfiles.com/opencatalystproject/data/oc20_data_mapping.pkl\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fceef3-7aff-426c-b1a4-70ea2d069aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa59d34-56ce-4987-9793-4f2579a9f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['random2472718']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4b96e-dae9-448c-b915-061353dc0a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mendeleev import element\n",
    "\n",
    "def print_var_name(variable):\n",
    "     for name in locals():\n",
    "        if eval(name) == variable:\n",
    "            print(name)\n",
    "\n",
    "def getAtomSequence (sequence):\n",
    "    result = list([[sequence[0], 1]])\n",
    "    for i in range(1, len(sequence)):\n",
    "        if sequence[i] == result[-1][0]:\n",
    "            result[-1][1] += 1\n",
    "        else:\n",
    "            result.append([sequence[i], 1])\n",
    "    return dict(result)\n",
    "\n",
    "def structureToVASP(structure, file='POSCAR', str_name='structure', relaxed=False):\n",
    "    with open(f'{str_name}_POSCAR{\"_relaxed\" if relaxed else \"\"}', 'w') as f:\n",
    "        f.write(str_name + '\\n')\n",
    "        f.write(str(1.0) + '\\n')\n",
    "        for axis in np.array(structure.cell[0]):\n",
    "            for i in range(3):\n",
    "                f.write(str(axis[i]) + '   ')\n",
    "                if i == 2:\n",
    "                    f.write('\\n')\n",
    "        atoms = getAtomSequence(np.array(structure.atomic_numbers, dtype=int))\n",
    "        for k in atoms.keys():\n",
    "            f.write('   ' + element(round(k)).symbol)\n",
    "        f.write('\\n')\n",
    "        for v in atoms.values():\n",
    "            f.write('   ' + str(round(v)))\n",
    "        f.write('\\n')\n",
    "        f.write('Cartesian\\n')\n",
    "        for position in np.array(structure.pos if not relaxed else structure.pos_relaxed):\n",
    "            for i in range(3):\n",
    "                f.write(str(position[i]) + '   ')\n",
    "                if i == 2:\n",
    "                    f.write('\\n')          \n",
    "    return None\n",
    "\n",
    "for relaxed in [True, False] :\n",
    "    structureToVASP(dataset_train_10k[0], relaxed=relaxed, str_name='dataset_train10k[0]')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "593e1d66-a274-4828-9c07-08ae97034278",
   "metadata": {},
   "source": [
    "PyG training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c708c-f3d7-4e20-a7af-a98bd092e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13b95c-d925-436d-831e-30a3c23eeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "sec = time.time()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "data = dataset[0]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % int(200/10) == 0:\n",
    "        print(epoch,':', time.time() - sec)\n",
    "\n",
    "print('Total:', time.time() - sec)\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2e661-ddc5-47b6-9b21-731fce1d251c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
