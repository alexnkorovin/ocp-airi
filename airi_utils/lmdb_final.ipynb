{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0189f7-ddc5-407a-976f-d517aac571e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2182ae7-be2b-4e68-8c8d-ead0fb6ab762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# import lmdb\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataloader import lmdb_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceab79ac-0915-4093-bf18-16e809c55eed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04fcd3-f4c1-453f-ba03-8dce97c3d538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"../../ocp_datasets/data/is2re/\"\n",
    "file_name = 'data_mod2.lmdb'\n",
    "\n",
    "datasets = {\n",
    "    \n",
    "    'train_10k':     '10k/train/',\n",
    "    'train_100k':    '100k/train/',\n",
    "    'train_all':     'all/train/',\n",
    "\n",
    "    'val_id':        'all/val_id/',\n",
    "    'val_ood_ads':   'all/val_ood_ads/',\n",
    "    'val_ood_cat':   'all/val_ood_cat/',\n",
    "    'val_ood_both':  'all/val_ood_both/',\n",
    "\n",
    "    'test_id':       'all/test_id/',\n",
    "    'test_ood_ads':  'all/test_ood_ads/',\n",
    "    'test_ood_cat':  'all/test_ood_cat/',\n",
    "    'test_ood_both': 'all/test_ood_both/'\n",
    "}\n",
    "\n",
    "datasets = {k:(root_dir + v + file_name) for k, v in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d7d966-04df-4a7f-8598-40568bec952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10k = lmdb_dataset(datasets['train_10k'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cc6e66d-8662-43f8-b2ff-e7dac111d3d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "def describe(dataset, idx=0):\n",
    "    dataset = dataset[idx]\n",
    "    print(f'item: {idx}')\n",
    "    for key in dataset.keys:\n",
    "        obj = dataset.__getitem__(key)\n",
    "        dot = 25\n",
    "\n",
    "        if type(obj) is Tensor:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{str(list(obj.shape)):>10}')\n",
    "        elif type(obj) is float:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{obj:>10.4f}')\n",
    "        else:\n",
    "            print(f'{key}:{\".\"*(dot-len(key))}{obj:>10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3332d-dfa9-4c7e-8f0c-88566cdc4d24",
   "metadata": {},
   "source": [
    "## Analyzing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127a0139-e1bc-416b-91c2-20a026757c1e",
   "metadata": {},
   "source": [
    "#### Describe dataset function (already used as method .describe() in lmdb_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0881e6-4c48-4ec9-b985-b34bba5151e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### create DataFrame of .natom keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79ad3a-90a9-430b-af23-470f88ef82d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create DataFrame of .natom keys\n",
    "def natom_hist(dataset):\n",
    "    from collections import defaultdict\n",
    "    import pandas as pd\n",
    "    sec = time.time()\n",
    "    dic = defaultdict(int)\n",
    "    for struct in dataset:\n",
    "        dic[struct.natoms] += 1\n",
    "    print(f'done for: {time.time() - sec:.2f} s')\n",
    "\n",
    "    dic_mod = {k:[v] for k,v in dict(dic).items()}\n",
    "    return pd.DataFrame.from_dict(dic_mod, orient='index', columns=['N']).sort_index()\n",
    "\n",
    "\n",
    "# TODO multiprocessing edition of function\n",
    "# from multiprocessing import Pool\n",
    "# def natom_hist(dataset):\n",
    "#     from collections import defaultdict\n",
    "#     import pandas as pd\n",
    "#     sec = time.time()\n",
    "#     dic = defaultdict(int)\n",
    "#     for struct in dataset:\n",
    "#         dic[struct.natoms] += 1\n",
    "#     print(time.time() - sec)\n",
    "\n",
    "#     dic_mod = {k:[v] for k,v in dict(dic).items()}\n",
    "#     return pd.DataFrame.from_dict(dic_mod, orient='index', columns=['N']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dccecf-30df-4812-a8cb-010db6f48ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# long time to run (~20 min)\n",
    "train_10k_df = natom_hist(train_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b013e2e-8151-4754-b120-76984a0b3777",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Sparce distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23ee39-9a84-481c-96ac-287054f3cd54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_distr(dic):\n",
    "    dic = dic.to_dict()\n",
    "    key = list(dic.keys())[0]\n",
    "    dic1 = {key:{i:0 for i in range(1, 301)}}\n",
    "    \n",
    "    for k, v in dic[key].items():\n",
    "        dic1[key][k] = v\n",
    "    return pd.DataFrame.from_dict(dic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7196cc-c2cd-4f4a-98fa-3dab99874dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = (train_10k_df,)\n",
    "frames_distr = [0]*len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a94c5f-8cf8-4717-a945-105e6dde5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frame in enumerate(frames):\n",
    "    frames_distr[i] = df_distr(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39081a-357d-4113-9922-7050d98df0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555aa717-ff17-43e6-93d6-9ea14385eaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat(frames_distr, axis=1)\n",
    "df_all.columns = ['df_train_all', 'dataset_test_id_df', 'dataset_train_10k_df', 'dataset_val_ood_both_df']\n",
    "df_all_norm = df_all.fillna(0)\n",
    "df_all_norm = df_all_norm.apply(lambda x: x / x.max())\n",
    "df_all_norm.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e4aedfb-d042-4ced-aa46-3677dad15f5e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# alternative normalizing by sklearn\n",
    "from sklearn import preprocessing\n",
    "df_index = df_all.index.to_list()\n",
    "x = df_all.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_all_norm = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610cebf-ff90-4186-be01-26452f533a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train_keys_10k_keys = set(dataset_train_10k[0].keys)\n",
    "dataset_val_ood_both_keys = set(dataset_val_ood_both[0].keys)\n",
    "dataset_test_keys_id_keys = set(dataset_test_id[0].keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542c615-544c-435f-b813-e4063d862186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_keys_10k_keys, dataset_val_ood_both_keys, dataset_test_keys_id_keys, sep='\\n')\n",
    "print(dataset_train_keys_10k_keys - dataset_test_keys_id_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba76ae-5cda-4209-bd4f-d0c1eda52ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_10k[0])\n",
    "# for i in dataset_train_keys_10k_keys:\n",
    "#         print((i, getattr(dataset_train_10k[0], i)))\n",
    "\n",
    "for i in dataset_train_keys_10k_keys:\n",
    "        temp = getattr(dataset_train_10k[0], i)\n",
    "        print(i, temp)\n",
    "#         if type(temp) not in [float, int]:\n",
    "#             print(temp.shape)\n",
    "#         else: print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe6277-11bf-42d0-a346-d03653ed5e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train_10k[0]['y_relaxed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8889b5-8607-4467-959f-27d4d02d7b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Counter(list(dataset_train_10k[0].atomic_numbers))\n",
    "dataset_train_10k[0].atomic_numbers[0].item()\n",
    "Counter([dataset_train_10k[0].atomic_numbers[i].item() for i in range(dataset_train_10k[0].atomic_numbers.shape[0])])\n",
    "# compare = [(\"\\n\".join((getattr(dataset_train_10k[0], i), getattr(dataset_test[0], i)))) for i in dataset_test[0].keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974aa66-3d68-4973-bd59-756fb48eaaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k[0].edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52481b2-87c6-4461-a0a9-314cea3d7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_10k[0].natoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5209b-a250-4474-ac36-8aef799722d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "86**2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99af59c-b4b2-4d75-bdfa-31acb01a049b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataset_train_10k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec8583-ba3e-4c3f-af04-51a604060f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dic = pd.read_pickle(\"/Users/korovin/Documents/GitHub/ocp_datasets/oc20_data_mapping.pkl\")\n",
    "# or use online https://dl.fbaipublicfiles.com/opencatalystproject/data/oc20_data_mapping.pkl\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fceef3-7aff-426c-b1a4-70ea2d069aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa59d34-56ce-4987-9793-4f2579a9f54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['random2472718']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3635428-2ec1-47b7-bbe9-a6566e1e64a8",
   "metadata": {},
   "source": [
    "### Calculate thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144d3dc-1352-47aa-9e67-82ceeeabdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_10k[0]['edge_angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2126b5c-1696-4321-83a1-85cc28310577",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_step = []\n",
    "n_steps = 10\n",
    "for i in range(n_steps+1):\n",
    "    pi_step.append(i*np.pi/n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb266804-770d-495a-96f8-c4ceec6d7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bins_torch(array_of_dfs, pi_step=pi_step):\n",
    "    thetas = []\n",
    "\n",
    "    for df in array_of_dfs:\n",
    "        theta = torch.tensor(df['edge_theta'].values) #.to('cpu')\n",
    "        theta = torch.histc(theta, bins=10, min=0, max=np.pi)\n",
    "        theta = torch.reshape(theta, (1, theta.shape[0]))\n",
    "        thetas.append(theta)\n",
    "        \n",
    "    thetas = torch.cat(thetas, 0)\n",
    "    \n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea465d-637e-4206-94ce-b05419b08101",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to_bins_torch(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d35ee3-3e81-4206-8f4f-a6987b648b9c",
   "metadata": {},
   "source": [
    "## Structure of element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4b96e-dae9-448c-b915-061353dc0a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mendeleev import element\n",
    "\n",
    "def print_var_name(variable):\n",
    "     for name in locals():\n",
    "        if eval(name) == variable:\n",
    "            print(name)\n",
    "\n",
    "def getAtomSequence (sequence):\n",
    "    result = list([[sequence[0], 1]])\n",
    "    for i in range(1, len(sequence)):\n",
    "        if sequence[i] == result[-1][0]:\n",
    "            result[-1][1] += 1\n",
    "        else:\n",
    "            result.append([sequence[i], 1])\n",
    "    return dict(result)\n",
    "\n",
    "def structureToVASP(structure, file='POSCAR', str_name='structure', relaxed=False):\n",
    "    with open(f'{str_name}_POSCAR{\"_relaxed\" if relaxed else \"\"}', 'w') as f:\n",
    "        f.write(str_name + '\\n')\n",
    "        f.write(str(1.0) + '\\n')\n",
    "        for axis in np.array(structure.cell[0]):\n",
    "            for i in range(3):\n",
    "                f.write(str(axis[i]) + '   ')\n",
    "                if i == 2:\n",
    "                    f.write('\\n')\n",
    "        atoms = getAtomSequence(np.array(structure.atomic_numbers, dtype=int))\n",
    "        for k in atoms.keys():\n",
    "            f.write('   ' + element(round(k)).symbol)\n",
    "        f.write('\\n')\n",
    "        for v in atoms.values():\n",
    "            f.write('   ' + str(round(v)))\n",
    "        f.write('\\n')\n",
    "        f.write('Cartesian\\n')\n",
    "        for position in np.array(structure.pos if not relaxed else structure.pos_relaxed):\n",
    "            for i in range(3):\n",
    "                f.write(str(position[i]) + '   ')\n",
    "                if i == 2:\n",
    "                    f.write('\\n')          \n",
    "    return None\n",
    "\n",
    "for relaxed in [True, False] :\n",
    "    structureToVASP(dataset_train_10k[0], relaxed=relaxed, str_name=dataset_train_10k[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3843a04b-a288-4988-83ee-9879b3c40314",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PyG training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c708c-f3d7-4e20-a7af-a98bd092e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13b95c-d925-436d-831e-30a3c23eeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "sec = time.time()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "data = dataset[0]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % int(200/10) == 0:\n",
    "        print(epoch,':', time.time() - sec)\n",
    "\n",
    "print('Total:', time.time() - sec)\n",
    "\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / int(data.test_mask.sum())\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
