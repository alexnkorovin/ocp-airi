{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd6cfb-9497-44ef-9021-6e071723c92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses_local import lmdb_dataset, Dataset#, DataListLoader\n",
    "from ModelFunctions_local import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48320d-740d-45a4-8461-7c7d48f9308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('../ocpmodels/models'))\n",
    "sys.path.append(os.path.expanduser('../../ocp_airi'))\n",
    "\n",
    "from spinconv_with_embeds_single import spinconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94d7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    keys = ['pos', 'atomic_numbers', 'cell', 'natoms']\n",
    "    features_dict = {}\n",
    "    for key in keys:\n",
    "        features_dict[key] = system[key]\n",
    "    return Data(**features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf0852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 30\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09825276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0184751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c69c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = DataLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2803a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868049d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 10000\n",
      "info for item: 0\n",
      "edge_index:............... [2, 2964]\n",
      "pos:......................   [86, 3]\n",
      "cell:..................... [1, 3, 3]\n",
      "atomic_numbers:...........      [86]\n",
      "natoms:...................        86\n",
      "cell_offsets:............. [2964, 3]\n",
      "force:....................   [86, 3]\n",
      "distances:................    [2964]\n",
      "fixed:....................      [86]\n",
      "sid:......................   2472718\n",
      "tags:.....................      [86]\n",
      "y_init:...................    6.2825\n",
      "y_relaxed:................   -0.0256\n",
      "pos_relaxed:..............   [86, 3]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d789924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = spinconv(None, None, 1, otf_graph=True, regress_forces=False)\n",
    "# model = DataParallel(model)\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae379cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-01-10-11-02\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bda981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no graph\n",
      "CPU times: user 416 µs, sys: 162 µs, total: 578 µs\n",
      "Wall time: 411 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id'\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeeec25",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de590137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-01-10-11-02\n",
      "Start training model spinconv(\n",
      "  (act): Swish()\n",
      "  (distance_expansion_forces): GaussianSmearing()\n",
      "  (embeddingblock2): EmbeddingBlock(\n",
      "    (act): Swish()\n",
      "    (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "    (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "    (source_embedding): Embedding(90, 32)\n",
      "    (target_embedding): Embedding(90, 32)\n",
      "    (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dist_block): DistanceBlock(\n",
      "    (distance_expansion): GaussianSmearing()\n",
      "    (dist_scalar): Embedding(8100, 1)\n",
      "    (dist_offset): Embedding(8100, 1)\n",
      "    (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  )\n",
      "  (message_blocks): ModuleList(\n",
      "    (0): MessageBlock(\n",
      "      (act): Swish()\n",
      "      (spinconvblock): SpinConvBlock(\n",
      "        (act): Swish()\n",
      "        (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "        (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "        (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "        (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (embeddingblock1): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (source_embedding): Embedding(90, 32)\n",
      "        (target_embedding): Embedding(90, 32)\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (embeddingblock2): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "        (source_embedding): Embedding(90, 32)\n",
      "        (target_embedding): Embedding(90, 32)\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (energyembeddingblock): EmbeddingBlock(\n",
      "    (act): Swish()\n",
      "    (fc1): Linear(in_features=32, out_features=200, bias=True)\n",
      "    (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "    (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "    (source_embedding): Embedding(90, 32)\n",
      "    (target_embedding): Embedding(90, 32)\n",
      "    (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (force_output_block): ForceOutputBlock(\n",
      "    (act): Swish()\n",
      "    (spinconvblock): SpinConvBlock(\n",
      "      (act): Swish()\n",
      "      (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "      (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "      (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "      (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "    )\n",
      "    (block1): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (source_embedding): Embedding(90, 32)\n",
      "      (target_embedding): Embedding(90, 32)\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (block2): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
      "      (source_embedding): Embedding(90, 32)\n",
      "      (target_embedding): Embedding(90, 32)\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch 0\n",
      "step 9 from 334 at epoch 0\n",
      "Loss: 2.264683723449707\n",
      "step 19 from 334 at epoch 0\n",
      "Loss: 1.9392696619033813\n",
      "step 29 from 334 at epoch 0\n",
      "Loss: 1.937281608581543\n",
      "step 39 from 334 at epoch 0\n",
      "Loss: 2.072054147720337\n",
      "step 49 from 334 at epoch 0\n",
      "Loss: 1.6322156190872192\n",
      "step 59 from 334 at epoch 0\n",
      "Loss: 1.5712019205093384\n",
      "step 69 from 334 at epoch 0\n",
      "Loss: 1.3448054790496826\n",
      "step 79 from 334 at epoch 0\n",
      "Loss: 1.8743120431900024\n",
      "step 89 from 334 at epoch 0\n",
      "Loss: 1.5760084390640259\n",
      "step 99 from 334 at epoch 0\n",
      "Loss: 1.7946287393569946\n",
      "step 109 from 334 at epoch 0\n",
      "Loss: 1.636336088180542\n",
      "step 119 from 334 at epoch 0\n",
      "Loss: 1.716536521911621\n",
      "step 129 from 334 at epoch 0\n",
      "Loss: 1.5947188138961792\n",
      "step 139 from 334 at epoch 0\n",
      "Loss: 1.5018128156661987\n",
      "step 149 from 334 at epoch 0\n",
      "Loss: 1.29444420337677\n",
      "step 159 from 334 at epoch 0\n",
      "Loss: 1.5802223682403564\n",
      "step 169 from 334 at epoch 0\n",
      "Loss: 1.9003612995147705\n",
      "step 179 from 334 at epoch 0\n",
      "Loss: 1.7087675333023071\n",
      "step 189 from 334 at epoch 0\n",
      "Loss: 1.6295089721679688\n",
      "step 199 from 334 at epoch 0\n",
      "Loss: 1.332861065864563\n",
      "step 209 from 334 at epoch 0\n",
      "Loss: 1.582680583000183\n",
      "step 219 from 334 at epoch 0\n",
      "Loss: 1.498409390449524\n",
      "step 229 from 334 at epoch 0\n",
      "Loss: 1.8310953378677368\n",
      "step 239 from 334 at epoch 0\n",
      "Loss: 1.4504005908966064\n",
      "step 249 from 334 at epoch 0\n",
      "Loss: 1.3732776641845703\n",
      "step 259 from 334 at epoch 0\n",
      "Loss: 1.1719411611557007\n",
      "step 269 from 334 at epoch 0\n",
      "Loss: 1.2047628164291382\n",
      "step 279 from 334 at epoch 0\n",
      "Loss: 1.512636423110962\n",
      "step 289 from 334 at epoch 0\n",
      "Loss: 1.4956289529800415\n",
      "step 299 from 334 at epoch 0\n",
      "Loss: 1.218891978263855\n",
      "step 309 from 334 at epoch 0\n",
      "Loss: 1.1033138036727905\n",
      "step 319 from 334 at epoch 0\n",
      "Loss: 1.2903112173080444\n",
      "step 329 from 334 at epoch 0\n",
      "Loss: 1.307881474494934\n",
      "epoch 0 evaluation\n",
      "epoch loss 1.1742921245484508\n",
      "========================================================================================================\n",
      "epoch 1\n",
      "step 9 from 334 at epoch 1\n",
      "Loss: 2.5092203617095947\n",
      "step 19 from 334 at epoch 1\n",
      "Loss: 1.3541834354400635\n",
      "step 29 from 334 at epoch 1\n",
      "Loss: 1.3336204290390015\n",
      "step 39 from 334 at epoch 1\n",
      "Loss: 1.4229694604873657\n",
      "step 49 from 334 at epoch 1\n",
      "Loss: 0.8685871362686157\n",
      "step 59 from 334 at epoch 1\n",
      "Loss: 1.1431156396865845\n",
      "step 69 from 334 at epoch 1\n",
      "Loss: 1.4124654531478882\n",
      "step 79 from 334 at epoch 1\n",
      "Loss: 1.14348304271698\n",
      "step 89 from 334 at epoch 1\n",
      "Loss: 1.2939163446426392\n",
      "step 99 from 334 at epoch 1\n",
      "Loss: 1.273409128189087\n",
      "step 109 from 334 at epoch 1\n",
      "Loss: 1.2380555868148804\n",
      "step 119 from 334 at epoch 1\n",
      "Loss: 1.226099967956543\n",
      "step 129 from 334 at epoch 1\n",
      "Loss: 1.3362776041030884\n",
      "step 139 from 334 at epoch 1\n",
      "Loss: 0.9932457208633423\n",
      "step 149 from 334 at epoch 1\n",
      "Loss: 1.016898274421692\n",
      "step 159 from 334 at epoch 1\n",
      "Loss: 0.9163138270378113\n",
      "step 169 from 334 at epoch 1\n",
      "Loss: 1.1597334146499634\n",
      "step 179 from 334 at epoch 1\n",
      "Loss: 1.2543420791625977\n",
      "step 189 from 334 at epoch 1\n",
      "Loss: 0.9139665961265564\n",
      "step 199 from 334 at epoch 1\n",
      "Loss: 0.8545573353767395\n",
      "step 209 from 334 at epoch 1\n",
      "Loss: 1.0175148248672485\n",
      "step 219 from 334 at epoch 1\n",
      "Loss: 1.3709007501602173\n",
      "step 229 from 334 at epoch 1\n",
      "Loss: 1.185989260673523\n",
      "step 239 from 334 at epoch 1\n",
      "Loss: 1.0053129196166992\n",
      "step 249 from 334 at epoch 1\n",
      "Loss: 0.9908280372619629\n",
      "step 259 from 334 at epoch 1\n",
      "Loss: 0.8523033857345581\n",
      "step 269 from 334 at epoch 1\n",
      "Loss: 1.0095734596252441\n",
      "step 279 from 334 at epoch 1\n",
      "Loss: 1.2195512056350708\n",
      "step 289 from 334 at epoch 1\n",
      "Loss: 1.2381516695022583\n",
      "step 299 from 334 at epoch 1\n",
      "Loss: 0.8644452691078186\n",
      "step 309 from 334 at epoch 1\n",
      "Loss: 1.0118567943572998\n",
      "step 319 from 334 at epoch 1\n",
      "Loss: 1.0769816637039185\n",
      "step 329 from 334 at epoch 1\n",
      "Loss: 1.1417722702026367\n",
      "epoch 1 evaluation\n",
      "epoch loss 1.0487537735364303\n",
      "========================================================================================================\n",
      "epoch 2\n",
      "step 9 from 334 at epoch 2\n",
      "Loss: 1.361231803894043\n",
      "step 19 from 334 at epoch 2\n",
      "Loss: 1.2841814756393433\n",
      "step 29 from 334 at epoch 2\n",
      "Loss: 1.0615023374557495\n",
      "step 39 from 334 at epoch 2\n",
      "Loss: 1.3037712574005127\n",
      "step 49 from 334 at epoch 2\n",
      "Loss: 0.6740013360977173\n",
      "step 59 from 334 at epoch 2\n",
      "Loss: 1.190878987312317\n",
      "step 69 from 334 at epoch 2\n",
      "Loss: 1.0724132061004639\n",
      "step 79 from 334 at epoch 2\n",
      "Loss: 1.0455992221832275\n",
      "step 89 from 334 at epoch 2\n",
      "Loss: 0.9804748296737671\n",
      "step 99 from 334 at epoch 2\n",
      "Loss: 1.1676303148269653\n",
      "step 109 from 334 at epoch 2\n",
      "Loss: 1.1713379621505737\n",
      "step 119 from 334 at epoch 2\n",
      "Loss: 1.0510478019714355\n",
      "step 129 from 334 at epoch 2\n",
      "Loss: 1.3337829113006592\n",
      "step 139 from 334 at epoch 2\n",
      "Loss: 0.8960782885551453\n",
      "step 149 from 334 at epoch 2\n",
      "Loss: 0.9192622900009155\n",
      "step 159 from 334 at epoch 2\n",
      "Loss: 0.8558438420295715\n",
      "step 169 from 334 at epoch 2\n",
      "Loss: 1.2232192754745483\n",
      "step 179 from 334 at epoch 2\n",
      "Loss: 1.1456674337387085\n",
      "step 189 from 334 at epoch 2\n",
      "Loss: 0.859589695930481\n",
      "step 199 from 334 at epoch 2\n",
      "Loss: 0.7329351305961609\n",
      "step 209 from 334 at epoch 2\n",
      "Loss: 0.94265216588974\n",
      "step 219 from 334 at epoch 2\n",
      "Loss: 1.4781166315078735\n",
      "step 229 from 334 at epoch 2\n",
      "Loss: 0.844731867313385\n",
      "step 239 from 334 at epoch 2\n",
      "Loss: 1.0660617351531982\n",
      "step 249 from 334 at epoch 2\n",
      "Loss: 1.0209424495697021\n",
      "step 259 from 334 at epoch 2\n",
      "Loss: 0.8614653944969177\n",
      "step 269 from 334 at epoch 2\n",
      "Loss: 1.0276411771774292\n",
      "step 279 from 334 at epoch 2\n",
      "Loss: 1.1932772397994995\n",
      "step 289 from 334 at epoch 2\n",
      "Loss: 1.0750696659088135\n",
      "step 299 from 334 at epoch 2\n",
      "Loss: 0.8263739943504333\n",
      "step 309 from 334 at epoch 2\n",
      "Loss: 1.0427441596984863\n",
      "step 319 from 334 at epoch 2\n",
      "Loss: 1.0834909677505493\n",
      "step 329 from 334 at epoch 2\n",
      "Loss: 1.1681621074676514\n",
      "epoch 2 evaluation\n",
      "epoch loss 1.0119527339362868\n",
      "========================================================================================================\n",
      "epoch 3\n",
      "step 9 from 334 at epoch 3\n",
      "Loss: 1.3852134943008423\n",
      "step 19 from 334 at epoch 3\n",
      "Loss: 1.245781660079956\n",
      "step 29 from 334 at epoch 3\n",
      "Loss: 1.0297768115997314\n",
      "step 39 from 334 at epoch 3\n",
      "Loss: 1.2180685997009277\n",
      "step 49 from 334 at epoch 3\n",
      "Loss: 0.6280774474143982\n",
      "step 59 from 334 at epoch 3\n",
      "Loss: 1.176127552986145\n",
      "step 69 from 334 at epoch 3\n",
      "Loss: 1.53525972366333\n",
      "step 79 from 334 at epoch 3\n",
      "Loss: 1.054091215133667\n",
      "step 89 from 334 at epoch 3\n",
      "Loss: 0.9433780908584595\n",
      "step 99 from 334 at epoch 3\n",
      "Loss: 1.1645747423171997\n",
      "step 109 from 334 at epoch 3\n",
      "Loss: 1.1751948595046997\n",
      "step 119 from 334 at epoch 3\n",
      "Loss: 1.0284992456436157\n",
      "step 129 from 334 at epoch 3\n",
      "Loss: 1.2571996450424194\n",
      "step 139 from 334 at epoch 3\n",
      "Loss: 0.7974256277084351\n",
      "step 149 from 334 at epoch 3\n",
      "Loss: 1.0190647840499878\n",
      "step 159 from 334 at epoch 3\n",
      "Loss: 0.8137032985687256\n",
      "step 169 from 334 at epoch 3\n",
      "Loss: 1.3247500658035278\n",
      "step 179 from 334 at epoch 3\n",
      "Loss: 1.0234113931655884\n",
      "step 189 from 334 at epoch 3\n",
      "Loss: 0.8768733143806458\n",
      "step 199 from 334 at epoch 3\n",
      "Loss: 0.7402597069740295\n",
      "step 209 from 334 at epoch 3\n",
      "Loss: 0.8852671980857849\n",
      "step 219 from 334 at epoch 3\n",
      "Loss: 1.4107800722122192\n",
      "step 229 from 334 at epoch 3\n",
      "Loss: 0.9865373373031616\n",
      "step 239 from 334 at epoch 3\n",
      "Loss: 0.9159280061721802\n",
      "step 249 from 334 at epoch 3\n",
      "Loss: 0.9953875541687012\n",
      "step 259 from 334 at epoch 3\n",
      "Loss: 0.8236809968948364\n",
      "step 269 from 334 at epoch 3\n",
      "Loss: 1.0061339139938354\n",
      "step 279 from 334 at epoch 3\n",
      "Loss: 1.010002613067627\n",
      "step 289 from 334 at epoch 3\n",
      "Loss: 1.1580058336257935\n",
      "step 299 from 334 at epoch 3\n",
      "Loss: 0.8333064913749695\n",
      "step 309 from 334 at epoch 3\n",
      "Loss: 1.1032030582427979\n",
      "step 319 from 334 at epoch 3\n",
      "Loss: 1.1045273542404175\n",
      "step 329 from 334 at epoch 3\n",
      "Loss: 0.9877464771270752\n",
      "epoch 3 evaluation\n",
      "epoch loss 1.04055068093617\n",
      "========================================================================================================\n",
      "epoch 4\n",
      "step 9 from 334 at epoch 4\n",
      "Loss: 3.0101983547210693\n",
      "step 19 from 334 at epoch 4\n",
      "Loss: 1.2913739681243896\n",
      "step 29 from 334 at epoch 4\n",
      "Loss: 1.0096383094787598\n",
      "step 39 from 334 at epoch 4\n",
      "Loss: 1.227916955947876\n",
      "step 49 from 334 at epoch 4\n",
      "Loss: 0.5881051421165466\n",
      "step 59 from 334 at epoch 4\n",
      "Loss: 1.1891388893127441\n",
      "step 69 from 334 at epoch 4\n",
      "Loss: 1.30784273147583\n",
      "step 79 from 334 at epoch 4\n",
      "Loss: 1.0368908643722534\n",
      "step 89 from 334 at epoch 4\n",
      "Loss: 0.9757574200630188\n",
      "step 99 from 334 at epoch 4\n",
      "Loss: 1.1536990404129028\n",
      "step 109 from 334 at epoch 4\n",
      "Loss: 1.162001132965088\n",
      "step 119 from 334 at epoch 4\n",
      "Loss: 0.9901637434959412\n",
      "step 129 from 334 at epoch 4\n",
      "Loss: 1.2242203950881958\n",
      "step 139 from 334 at epoch 4\n",
      "Loss: 0.8745028972625732\n",
      "step 149 from 334 at epoch 4\n",
      "Loss: 1.0444340705871582\n",
      "step 159 from 334 at epoch 4\n",
      "Loss: 0.8926382064819336\n",
      "step 169 from 334 at epoch 4\n",
      "Loss: 1.2361887693405151\n",
      "step 179 from 334 at epoch 4\n",
      "Loss: 0.9766066670417786\n",
      "step 189 from 334 at epoch 4\n",
      "Loss: 0.7615442276000977\n",
      "step 199 from 334 at epoch 4\n",
      "Loss: 0.7607895135879517\n",
      "step 209 from 334 at epoch 4\n",
      "Loss: 0.9250061511993408\n",
      "step 219 from 334 at epoch 4\n",
      "Loss: 1.3493175506591797\n",
      "step 229 from 334 at epoch 4\n",
      "Loss: 0.9817458987236023\n",
      "step 239 from 334 at epoch 4\n",
      "Loss: 0.8814955353736877\n",
      "step 249 from 334 at epoch 4\n",
      "Loss: 1.022322654724121\n",
      "step 259 from 334 at epoch 4\n",
      "Loss: 0.7770306468009949\n",
      "step 269 from 334 at epoch 4\n",
      "Loss: 0.9782880544662476\n",
      "step 279 from 334 at epoch 4\n",
      "Loss: 1.0690973997116089\n",
      "step 289 from 334 at epoch 4\n",
      "Loss: 1.084572672843933\n",
      "step 299 from 334 at epoch 4\n",
      "Loss: 0.8241782188415527\n",
      "step 309 from 334 at epoch 4\n",
      "Loss: 1.1341086626052856\n",
      "step 319 from 334 at epoch 4\n",
      "Loss: 0.9877445101737976\n",
      "step 329 from 334 at epoch 4\n",
      "Loss: 1.0098457336425781\n",
      "epoch 4 evaluation\n",
      "epoch loss 0.9673415571987843\n",
      "========================================================================================================\n",
      "epoch 5\n",
      "step 9 from 334 at epoch 5\n",
      "Loss: 1.4632912874221802\n",
      "step 19 from 334 at epoch 5\n",
      "Loss: 1.2856415510177612\n",
      "step 29 from 334 at epoch 5\n",
      "Loss: 0.8885669112205505\n",
      "step 39 from 334 at epoch 5\n",
      "Loss: 1.1351977586746216\n",
      "step 49 from 334 at epoch 5\n",
      "Loss: 0.5550578236579895\n",
      "step 59 from 334 at epoch 5\n",
      "Loss: 1.3705217838287354\n",
      "step 69 from 334 at epoch 5\n",
      "Loss: 1.2121498584747314\n",
      "step 79 from 334 at epoch 5\n",
      "Loss: 1.2188286781311035\n",
      "step 89 from 334 at epoch 5\n",
      "Loss: 0.877512514591217\n",
      "step 99 from 334 at epoch 5\n",
      "Loss: 1.1503971815109253\n",
      "step 109 from 334 at epoch 5\n",
      "Loss: 1.0897252559661865\n",
      "step 119 from 334 at epoch 5\n",
      "Loss: 1.1814038753509521\n",
      "step 129 from 334 at epoch 5\n",
      "Loss: 1.3106446266174316\n",
      "step 139 from 334 at epoch 5\n",
      "Loss: 0.8709825277328491\n",
      "step 149 from 334 at epoch 5\n",
      "Loss: 1.1679964065551758\n",
      "step 159 from 334 at epoch 5\n",
      "Loss: 0.8935886025428772\n",
      "step 169 from 334 at epoch 5\n",
      "Loss: 1.2253587245941162\n",
      "step 179 from 334 at epoch 5\n",
      "Loss: 0.9647430181503296\n",
      "step 189 from 334 at epoch 5\n",
      "Loss: 0.7794438004493713\n",
      "step 199 from 334 at epoch 5\n",
      "Loss: 0.7435200214385986\n",
      "step 209 from 334 at epoch 5\n",
      "Loss: 0.8009955286979675\n",
      "step 219 from 334 at epoch 5\n",
      "Loss: 1.3493579626083374\n",
      "step 229 from 334 at epoch 5\n",
      "Loss: 0.9387418627738953\n",
      "step 239 from 334 at epoch 5\n",
      "Loss: 0.7501205801963806\n",
      "step 249 from 334 at epoch 5\n",
      "Loss: 0.9034420251846313\n",
      "step 259 from 334 at epoch 5\n",
      "Loss: 0.801908552646637\n",
      "step 269 from 334 at epoch 5\n",
      "Loss: 0.9646720290184021\n",
      "step 279 from 334 at epoch 5\n",
      "Loss: 1.007694125175476\n",
      "step 289 from 334 at epoch 5\n",
      "Loss: 1.0545722246170044\n",
      "step 299 from 334 at epoch 5\n",
      "Loss: 0.8215884566307068\n",
      "step 309 from 334 at epoch 5\n",
      "Loss: 1.103049635887146\n",
      "step 319 from 334 at epoch 5\n",
      "Loss: 1.0152069330215454\n",
      "step 329 from 334 at epoch 5\n",
      "Loss: 1.0234661102294922\n",
      "epoch 5 evaluation\n",
      "epoch loss 0.9787507452884642\n",
      "========================================================================================================\n",
      "epoch 6\n",
      "step 9 from 334 at epoch 6\n",
      "Loss: 1.3866926431655884\n",
      "step 19 from 334 at epoch 6\n",
      "Loss: 1.1697009801864624\n",
      "step 29 from 334 at epoch 6\n",
      "Loss: 0.960808277130127\n",
      "step 39 from 334 at epoch 6\n",
      "Loss: 1.1075061559677124\n",
      "step 49 from 334 at epoch 6\n",
      "Loss: 0.5246543288230896\n",
      "step 59 from 334 at epoch 6\n",
      "Loss: 1.2173914909362793\n",
      "step 69 from 334 at epoch 6\n",
      "Loss: 1.3419862985610962\n",
      "step 79 from 334 at epoch 6\n",
      "Loss: 0.9834910035133362\n",
      "step 89 from 334 at epoch 6\n",
      "Loss: 0.8513813018798828\n",
      "step 99 from 334 at epoch 6\n",
      "Loss: 1.1481807231903076\n",
      "step 109 from 334 at epoch 6\n",
      "Loss: 1.01951265335083\n",
      "step 119 from 334 at epoch 6\n",
      "Loss: 1.0769633054733276\n",
      "step 129 from 334 at epoch 6\n",
      "Loss: 1.321047306060791\n",
      "step 139 from 334 at epoch 6\n",
      "Loss: 0.7686470150947571\n",
      "step 149 from 334 at epoch 6\n",
      "Loss: 0.995978593826294\n",
      "step 159 from 334 at epoch 6\n",
      "Loss: 0.9566197395324707\n",
      "step 169 from 334 at epoch 6\n",
      "Loss: 1.2145668268203735\n",
      "step 179 from 334 at epoch 6\n",
      "Loss: 0.9573071002960205\n",
      "step 189 from 334 at epoch 6\n",
      "Loss: 0.7544375658035278\n",
      "step 199 from 334 at epoch 6\n",
      "Loss: 0.771845817565918\n",
      "step 209 from 334 at epoch 6\n",
      "Loss: 0.8986801505088806\n",
      "step 219 from 334 at epoch 6\n",
      "Loss: 1.4147964715957642\n",
      "step 229 from 334 at epoch 6\n",
      "Loss: 0.9656147360801697\n",
      "step 239 from 334 at epoch 6\n",
      "Loss: 0.804247260093689\n",
      "step 249 from 334 at epoch 6\n",
      "Loss: 0.8841232657432556\n",
      "step 259 from 334 at epoch 6\n",
      "Loss: 0.7686805725097656\n",
      "step 269 from 334 at epoch 6\n",
      "Loss: 0.9956133961677551\n",
      "step 279 from 334 at epoch 6\n",
      "Loss: 0.9814882874488831\n",
      "step 289 from 334 at epoch 6\n",
      "Loss: 1.0979971885681152\n",
      "step 299 from 334 at epoch 6\n",
      "Loss: 0.818097710609436\n",
      "step 309 from 334 at epoch 6\n",
      "Loss: 1.0603076219558716\n",
      "step 319 from 334 at epoch 6\n",
      "Loss: 0.9481853246688843\n",
      "step 329 from 334 at epoch 6\n",
      "Loss: 1.006083369255066\n",
      "epoch 6 evaluation\n",
      "epoch loss 0.9660932102552554\n",
      "========================================================================================================\n",
      "epoch 7\n",
      "step 9 from 334 at epoch 7\n",
      "Loss: 1.2774447202682495\n",
      "step 19 from 334 at epoch 7\n",
      "Loss: 1.1362180709838867\n",
      "step 29 from 334 at epoch 7\n",
      "Loss: 1.0273641347885132\n",
      "step 39 from 334 at epoch 7\n",
      "Loss: 1.1104458570480347\n",
      "step 49 from 334 at epoch 7\n",
      "Loss: 0.5394583940505981\n",
      "step 59 from 334 at epoch 7\n",
      "Loss: 1.3119094371795654\n",
      "step 69 from 334 at epoch 7\n",
      "Loss: 1.2341492176055908\n",
      "step 79 from 334 at epoch 7\n",
      "Loss: 1.1125612258911133\n",
      "step 89 from 334 at epoch 7\n",
      "Loss: 0.8627521991729736\n",
      "step 99 from 334 at epoch 7\n",
      "Loss: 1.2194569110870361\n",
      "step 109 from 334 at epoch 7\n",
      "Loss: 0.9534749984741211\n",
      "step 119 from 334 at epoch 7\n",
      "Loss: 1.015838384628296\n",
      "step 129 from 334 at epoch 7\n",
      "Loss: 1.244301199913025\n",
      "step 139 from 334 at epoch 7\n",
      "Loss: 0.7681013941764832\n",
      "step 149 from 334 at epoch 7\n",
      "Loss: 1.0943666696548462\n",
      "step 159 from 334 at epoch 7\n",
      "Loss: 0.90012127161026\n",
      "step 169 from 334 at epoch 7\n",
      "Loss: 1.2404751777648926\n",
      "step 179 from 334 at epoch 7\n",
      "Loss: 0.9570460319519043\n",
      "step 189 from 334 at epoch 7\n",
      "Loss: 0.7377786040306091\n",
      "step 199 from 334 at epoch 7\n",
      "Loss: 0.6887331008911133\n",
      "step 209 from 334 at epoch 7\n",
      "Loss: 0.874403715133667\n",
      "step 219 from 334 at epoch 7\n",
      "Loss: 1.228438377380371\n",
      "step 229 from 334 at epoch 7\n",
      "Loss: 0.9550909399986267\n",
      "step 239 from 334 at epoch 7\n",
      "Loss: 0.8363442420959473\n",
      "step 249 from 334 at epoch 7\n",
      "Loss: 0.9686770439147949\n",
      "step 259 from 334 at epoch 7\n",
      "Loss: 0.7859711647033691\n",
      "step 269 from 334 at epoch 7\n",
      "Loss: 0.9598267078399658\n",
      "step 279 from 334 at epoch 7\n",
      "Loss: 0.9019889235496521\n",
      "step 289 from 334 at epoch 7\n",
      "Loss: 1.083426833152771\n",
      "step 299 from 334 at epoch 7\n",
      "Loss: 0.763174831867218\n",
      "step 309 from 334 at epoch 7\n",
      "Loss: 1.0340207815170288\n",
      "step 319 from 334 at epoch 7\n",
      "Loss: 0.9551771283149719\n",
      "step 329 from 334 at epoch 7\n",
      "Loss: 1.0000797510147095\n",
      "epoch 7 evaluation\n",
      "epoch loss 0.998960512883666\n",
      "========================================================================================================\n",
      "epoch 8\n",
      "step 9 from 334 at epoch 8\n",
      "Loss: 1.3298770189285278\n",
      "step 19 from 334 at epoch 8\n",
      "Loss: 1.1099703311920166\n",
      "step 29 from 334 at epoch 8\n",
      "Loss: 1.0127969980239868\n",
      "step 39 from 334 at epoch 8\n",
      "Loss: 1.0583993196487427\n",
      "step 49 from 334 at epoch 8\n",
      "Loss: 0.5435595512390137\n",
      "step 59 from 334 at epoch 8\n",
      "Loss: 1.0936110019683838\n",
      "step 69 from 334 at epoch 8\n",
      "Loss: 1.2250562906265259\n",
      "step 79 from 334 at epoch 8\n",
      "Loss: 0.9682327508926392\n",
      "step 89 from 334 at epoch 8\n",
      "Loss: 0.7496991753578186\n",
      "step 99 from 334 at epoch 8\n",
      "Loss: 1.2567986249923706\n",
      "step 109 from 334 at epoch 8\n",
      "Loss: 1.222605586051941\n",
      "step 119 from 334 at epoch 8\n",
      "Loss: 1.3307690620422363\n",
      "step 129 from 334 at epoch 8\n",
      "Loss: 1.2434858083724976\n",
      "step 139 from 334 at epoch 8\n",
      "Loss: 0.7757391333580017\n",
      "step 149 from 334 at epoch 8\n",
      "Loss: 1.0462634563446045\n",
      "step 159 from 334 at epoch 8\n",
      "Loss: 0.9012889266014099\n",
      "step 169 from 334 at epoch 8\n",
      "Loss: 1.223671317100525\n",
      "step 179 from 334 at epoch 8\n",
      "Loss: 0.9623996615409851\n",
      "step 189 from 334 at epoch 8\n",
      "Loss: 0.7450469136238098\n",
      "step 199 from 334 at epoch 8\n",
      "Loss: 0.6792241930961609\n",
      "step 209 from 334 at epoch 8\n",
      "Loss: 0.850434422492981\n",
      "step 219 from 334 at epoch 8\n",
      "Loss: 1.3286463022232056\n",
      "step 229 from 334 at epoch 8\n",
      "Loss: 0.976359486579895\n",
      "step 239 from 334 at epoch 8\n",
      "Loss: 0.6797012686729431\n",
      "step 249 from 334 at epoch 8\n",
      "Loss: 0.9067085981369019\n",
      "step 259 from 334 at epoch 8\n",
      "Loss: 0.7516428828239441\n",
      "step 269 from 334 at epoch 8\n",
      "Loss: 0.9009497165679932\n",
      "step 279 from 334 at epoch 8\n",
      "Loss: 0.9483898282051086\n",
      "step 289 from 334 at epoch 8\n",
      "Loss: 1.0963484048843384\n",
      "step 299 from 334 at epoch 8\n",
      "Loss: 0.762701690196991\n",
      "step 309 from 334 at epoch 8\n",
      "Loss: 1.059927225112915\n",
      "step 319 from 334 at epoch 8\n",
      "Loss: 0.9230555891990662\n",
      "step 329 from 334 at epoch 8\n",
      "Loss: 1.0094904899597168\n",
      "epoch 8 evaluation\n",
      "epoch loss 1.045295865023408\n",
      "========================================================================================================\n",
      "epoch 9\n",
      "step 9 from 334 at epoch 9\n",
      "Loss: 1.326367974281311\n",
      "step 19 from 334 at epoch 9\n",
      "Loss: 1.1321980953216553\n",
      "step 29 from 334 at epoch 9\n",
      "Loss: 0.8146451711654663\n",
      "step 39 from 334 at epoch 9\n",
      "Loss: 1.1013201475143433\n",
      "step 49 from 334 at epoch 9\n",
      "Loss: 0.5888980031013489\n",
      "step 59 from 334 at epoch 9\n",
      "Loss: 0.9417328238487244\n",
      "step 69 from 334 at epoch 9\n",
      "Loss: 1.3410359621047974\n",
      "step 79 from 334 at epoch 9\n",
      "Loss: 1.108497977256775\n",
      "step 89 from 334 at epoch 9\n",
      "Loss: 0.8030871152877808\n",
      "step 99 from 334 at epoch 9\n",
      "Loss: 1.176527976989746\n",
      "step 109 from 334 at epoch 9\n",
      "Loss: 0.9133509993553162\n",
      "step 119 from 334 at epoch 9\n",
      "Loss: 1.1433489322662354\n",
      "step 129 from 334 at epoch 9\n",
      "Loss: 1.222060203552246\n",
      "step 139 from 334 at epoch 9\n",
      "Loss: 0.7997215390205383\n",
      "step 149 from 334 at epoch 9\n",
      "Loss: 1.0247037410736084\n",
      "step 159 from 334 at epoch 9\n",
      "Loss: 0.9092823266983032\n",
      "step 169 from 334 at epoch 9\n",
      "Loss: 1.1571035385131836\n",
      "step 179 from 334 at epoch 9\n",
      "Loss: 0.9312453269958496\n",
      "step 189 from 334 at epoch 9\n",
      "Loss: 0.7285150289535522\n",
      "step 199 from 334 at epoch 9\n",
      "Loss: 0.7699167132377625\n",
      "step 209 from 334 at epoch 9\n",
      "Loss: 0.8641782999038696\n",
      "step 219 from 334 at epoch 9\n",
      "Loss: 1.3267031908035278\n",
      "step 229 from 334 at epoch 9\n",
      "Loss: 0.9566717147827148\n",
      "step 239 from 334 at epoch 9\n",
      "Loss: 0.7354598641395569\n",
      "step 249 from 334 at epoch 9\n",
      "Loss: 0.9153057932853699\n",
      "step 259 from 334 at epoch 9\n",
      "Loss: 0.7670094966888428\n",
      "step 269 from 334 at epoch 9\n",
      "Loss: 0.9908097982406616\n",
      "step 279 from 334 at epoch 9\n",
      "Loss: 0.9188043475151062\n",
      "step 289 from 334 at epoch 9\n",
      "Loss: 1.0427480936050415\n",
      "step 299 from 334 at epoch 9\n",
      "Loss: 0.7828150987625122\n",
      "step 309 from 334 at epoch 9\n",
      "Loss: 1.089769959449768\n",
      "step 319 from 334 at epoch 9\n",
      "Loss: 0.8561433553695679\n",
      "step 329 from 334 at epoch 9\n",
      "Loss: 1.047611117362976\n",
      "epoch 9 evaluation\n",
      "epoch loss 1.0339041201292682\n",
      "========================================================================================================\n",
      "epoch 10\n",
      "step 9 from 334 at epoch 10\n",
      "Loss: 1.3412848711013794\n",
      "step 19 from 334 at epoch 10\n",
      "Loss: 1.1499285697937012\n",
      "step 29 from 334 at epoch 10\n",
      "Loss: 0.9217819571495056\n",
      "step 39 from 334 at epoch 10\n",
      "Loss: 1.016361117362976\n",
      "step 49 from 334 at epoch 10\n",
      "Loss: 0.5902270078659058\n",
      "step 59 from 334 at epoch 10\n",
      "Loss: 0.9811772108078003\n",
      "step 69 from 334 at epoch 10\n",
      "Loss: 1.3266003131866455\n",
      "step 79 from 334 at epoch 10\n",
      "Loss: 1.0986965894699097\n",
      "step 89 from 334 at epoch 10\n",
      "Loss: 0.8739284873008728\n",
      "step 99 from 334 at epoch 10\n",
      "Loss: 1.1535528898239136\n",
      "step 109 from 334 at epoch 10\n",
      "Loss: 1.0075304508209229\n",
      "step 119 from 334 at epoch 10\n",
      "Loss: 1.1921963691711426\n",
      "step 129 from 334 at epoch 10\n",
      "Loss: 1.2968051433563232\n",
      "step 139 from 334 at epoch 10\n",
      "Loss: 0.7912017703056335\n",
      "step 149 from 334 at epoch 10\n",
      "Loss: 1.0158390998840332\n",
      "step 159 from 334 at epoch 10\n",
      "Loss: 0.896422266960144\n",
      "step 169 from 334 at epoch 10\n",
      "Loss: 1.167378544807434\n",
      "step 179 from 334 at epoch 10\n",
      "Loss: 0.9619677662849426\n",
      "step 189 from 334 at epoch 10\n",
      "Loss: 0.7929625511169434\n",
      "step 199 from 334 at epoch 10\n",
      "Loss: 0.7337085008621216\n",
      "step 209 from 334 at epoch 10\n",
      "Loss: 0.9441801309585571\n",
      "step 219 from 334 at epoch 10\n",
      "Loss: 1.2999180555343628\n",
      "step 229 from 334 at epoch 10\n",
      "Loss: 0.8653085231781006\n",
      "step 239 from 334 at epoch 10\n",
      "Loss: 0.8087905049324036\n",
      "step 249 from 334 at epoch 10\n",
      "Loss: 1.0228633880615234\n",
      "step 259 from 334 at epoch 10\n",
      "Loss: 0.7084583640098572\n",
      "step 269 from 334 at epoch 10\n",
      "Loss: 0.9463236927986145\n",
      "step 279 from 334 at epoch 10\n",
      "Loss: 0.9221848249435425\n",
      "step 289 from 334 at epoch 10\n",
      "Loss: 1.0722323656082153\n",
      "step 299 from 334 at epoch 10\n",
      "Loss: 0.8080568909645081\n",
      "step 309 from 334 at epoch 10\n",
      "Loss: 1.1633143424987793\n",
      "step 319 from 334 at epoch 10\n",
      "Loss: 0.9163877367973328\n",
      "step 329 from 334 at epoch 10\n",
      "Loss: 1.043952465057373\n",
      "epoch 10 evaluation\n",
      "epoch loss 1.0246955188525682\n",
      "========================================================================================================\n",
      "epoch 11\n",
      "step 9 from 334 at epoch 11\n",
      "Loss: 1.2778770923614502\n",
      "step 19 from 334 at epoch 11\n",
      "Loss: 1.0490728616714478\n",
      "step 29 from 334 at epoch 11\n",
      "Loss: 0.9014521241188049\n",
      "step 39 from 334 at epoch 11\n",
      "Loss: 1.1706093549728394\n",
      "step 49 from 334 at epoch 11\n",
      "Loss: 0.5222439169883728\n",
      "step 59 from 334 at epoch 11\n",
      "Loss: 0.978327751159668\n",
      "step 69 from 334 at epoch 11\n",
      "Loss: 1.3830711841583252\n",
      "step 79 from 334 at epoch 11\n",
      "Loss: 1.0523008108139038\n",
      "step 89 from 334 at epoch 11\n",
      "Loss: 0.7663463950157166\n",
      "step 99 from 334 at epoch 11\n",
      "Loss: 1.234643578529358\n",
      "step 109 from 334 at epoch 11\n",
      "Loss: 1.061737060546875\n",
      "step 119 from 334 at epoch 11\n",
      "Loss: 1.059257984161377\n",
      "step 129 from 334 at epoch 11\n",
      "Loss: 1.1866086721420288\n",
      "step 139 from 334 at epoch 11\n",
      "Loss: 0.7874746322631836\n",
      "step 149 from 334 at epoch 11\n",
      "Loss: 0.9380484819412231\n",
      "step 159 from 334 at epoch 11\n",
      "Loss: 0.8554096817970276\n",
      "step 169 from 334 at epoch 11\n",
      "Loss: 1.1081063747406006\n",
      "step 179 from 334 at epoch 11\n",
      "Loss: 0.9637472033500671\n",
      "step 189 from 334 at epoch 11\n",
      "Loss: 0.9257110953330994\n",
      "step 199 from 334 at epoch 11\n",
      "Loss: 0.8021659255027771\n",
      "step 209 from 334 at epoch 11\n",
      "Loss: 0.8862723708152771\n",
      "step 219 from 334 at epoch 11\n",
      "Loss: 1.3560619354248047\n",
      "step 229 from 334 at epoch 11\n",
      "Loss: 0.8751212358474731\n",
      "step 239 from 334 at epoch 11\n",
      "Loss: 0.7686530351638794\n",
      "step 249 from 334 at epoch 11\n",
      "Loss: 1.054039478302002\n",
      "step 259 from 334 at epoch 11\n",
      "Loss: 0.7396577596664429\n",
      "step 269 from 334 at epoch 11\n",
      "Loss: 0.9303559064865112\n",
      "step 279 from 334 at epoch 11\n",
      "Loss: 1.043241024017334\n",
      "step 289 from 334 at epoch 11\n",
      "Loss: 1.1187431812286377\n",
      "step 299 from 334 at epoch 11\n",
      "Loss: 0.7426232695579529\n",
      "step 309 from 334 at epoch 11\n",
      "Loss: 1.175355076789856\n",
      "step 319 from 334 at epoch 11\n",
      "Loss: 0.9430765509605408\n",
      "step 329 from 334 at epoch 11\n",
      "Loss: 1.0205681324005127\n",
      "epoch 11 evaluation\n",
      "epoch loss 1.0626044067300382\n",
      "========================================================================================================\n",
      "epoch 12\n",
      "step 9 from 334 at epoch 12\n",
      "Loss: 1.178040623664856\n",
      "step 19 from 334 at epoch 12\n",
      "Loss: 1.1210243701934814\n",
      "step 29 from 334 at epoch 12\n",
      "Loss: 0.9073183536529541\n",
      "step 39 from 334 at epoch 12\n",
      "Loss: 1.2621188163757324\n",
      "step 49 from 334 at epoch 12\n",
      "Loss: 0.5693906545639038\n",
      "step 59 from 334 at epoch 12\n",
      "Loss: 1.0394330024719238\n",
      "step 69 from 334 at epoch 12\n",
      "Loss: 1.4103386402130127\n",
      "step 79 from 334 at epoch 12\n",
      "Loss: 0.9800187945365906\n",
      "step 89 from 334 at epoch 12\n",
      "Loss: 0.8680710792541504\n",
      "step 99 from 334 at epoch 12\n",
      "Loss: 1.223225474357605\n",
      "step 109 from 334 at epoch 12\n",
      "Loss: 0.9505696892738342\n",
      "step 119 from 334 at epoch 12\n",
      "Loss: 0.9001148343086243\n",
      "step 129 from 334 at epoch 12\n",
      "Loss: 1.2074198722839355\n",
      "step 139 from 334 at epoch 12\n",
      "Loss: 0.7813826203346252\n",
      "step 149 from 334 at epoch 12\n",
      "Loss: 0.960593581199646\n",
      "step 159 from 334 at epoch 12\n",
      "Loss: 0.8555923700332642\n",
      "step 169 from 334 at epoch 12\n",
      "Loss: 1.101954698562622\n",
      "step 179 from 334 at epoch 12\n",
      "Loss: 0.89469975233078\n",
      "step 189 from 334 at epoch 12\n",
      "Loss: 0.8400463461875916\n",
      "step 199 from 334 at epoch 12\n",
      "Loss: 0.7251796126365662\n",
      "step 209 from 334 at epoch 12\n",
      "Loss: 0.8902730941772461\n",
      "step 219 from 334 at epoch 12\n",
      "Loss: 1.253846287727356\n",
      "step 229 from 334 at epoch 12\n",
      "Loss: 0.8270975947380066\n",
      "step 239 from 334 at epoch 12\n",
      "Loss: 0.8376955986022949\n",
      "step 249 from 334 at epoch 12\n",
      "Loss: 1.0258140563964844\n",
      "step 259 from 334 at epoch 12\n",
      "Loss: 0.6878392696380615\n",
      "step 269 from 334 at epoch 12\n",
      "Loss: 0.9260290265083313\n",
      "step 279 from 334 at epoch 12\n",
      "Loss: 0.8485286235809326\n",
      "step 289 from 334 at epoch 12\n",
      "Loss: 1.1380038261413574\n",
      "step 299 from 334 at epoch 12\n",
      "Loss: 0.6784488558769226\n",
      "step 309 from 334 at epoch 12\n",
      "Loss: 1.12689208984375\n",
      "step 319 from 334 at epoch 12\n",
      "Loss: 0.9139149188995361\n",
      "step 329 from 334 at epoch 12\n",
      "Loss: 1.0242366790771484\n",
      "epoch 12 evaluation\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
