{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d618c1-7bd7-4b54-b5c6-cd8fab531f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset, choose_dataloader\n",
    "from ModelFunctions import multigpu_available, train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    \n",
    "    atom_embeds = torch.cat(atom_features, 1)\n",
    "    \n",
    "    edge_index = system['edge_index_new'].long()\n",
    "\n",
    "    edges_embeds = torch.cat(edge_features, 1)\n",
    "    \n",
    "    return Data(x=atom_embeds.to(device), edge_index=edge_index.to(device), edge_attr=edges_embeds.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8f958",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)\n",
    "$$\n",
    "\n",
    "Гамма лежит в апдейт, квадратик в aggr, а фи в месседж; в этом примере квадратик -- суммирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae848d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super(GConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['x']\n",
    "        edge_index = batch['edge_index']\n",
    "        edge_attr = batch['edge_attr']\n",
    "        \n",
    "        # x has shape [N -- количество атомов в системе(батче), in_channels -- размерность вектора-атома]\n",
    "        # edge_index has shape [2, E] -- каждое ребро задаётся парой вершин\n",
    "\n",
    "        # Start propagating messages. \n",
    "    \n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "\n",
    "    def message(self, x, x_i, x_j, edge_attr):\n",
    "        # your function\n",
    "        pass\n",
    "        \n",
    "    def update(self, aggr_out, x, edge_attr, edge_index):        \n",
    "        #your function\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1232c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()          \n",
    "        self.conv = GConv()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        #your function\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 2\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099636a-c3a8-4bf5-86f8-4983eba165c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b308d-ffa4-4f48-adab-e218d7da0046",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8ed5d-ba8c-44e7-a343-1e7092ffca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = choose_dataloader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae852e60-b1ac-4a48-8120-af94ecec6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = choose_dataloader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = ConvNN(dim_atom=training_set[0][0]['x'].shape[1], dim_edge=training_set[0][0]['edge_attr'].shape[1])\n",
    "if multigpu_available():\n",
    "    model = DataParallel(model)\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models-env",
   "language": "python",
   "name": "ocp-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
