{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f924eba8-0439-4904-b006-9719246e1f1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903cb16-b534-4be6-9ba3-b70c13ec1a03",
   "metadata": {},
   "source": [
    "### Google colab\n",
    "\n",
    "This notebook can be used in colab (**this is the fastest way to run calculation on unconfigured system**):\n",
    "\n",
    "In google colab https://colab.research.google.com/ go to File | Open notebook | GitHub\n",
    "insert the path to the current notebook and open it: https://github.com/alexnkorovin/ocp-airi/blob/dev/airi_utils/our_base_model.ipynb\n",
    "\n",
    "Before start:\n",
    "\n",
    "1. Put this shared folder with datasets in your Google Drive root folder /drive/MyDrive/\n",
    "\n",
    "This folders  can are available by the sharing link below:\n",
    "\n",
    "*   ocp_datasets [[ share link to drive](https://drive.google.com/drive/folders/1Nn9t-zTJiRP1-34rdAugv6aY_2-BSQfN?usp=sharing)]<br>\n",
    "\n",
    "```\n",
    "Note:\n",
    "if this folder is saved by sharing link it should contain the following files\n",
    "\n",
    "ocp-datasets/data/is2re/train/all/val_ood_both/data.lmdb\n",
    "ocp-datasets/data/is2re/train/all/test_ood_both/data.lmdb\n",
    "ocp-datasets/data/is2re/train/all/test_ood_both/structures.pkl\n",
    "\n",
    " ```\n",
    "2. Enable GPU support in Edit/Notebook Settings\n",
    "\n",
    "### on local pc\n",
    "\n",
    "download specified data files by [link](https://drive.google.com/drive/folders/1Nn9t-zTJiRP1-34rdAugv6aY_2-BSQfN?usp=sharing) into local folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889e61b-744e-4aa5-bd73-a2e9f04b3361",
   "metadata": {},
   "source": [
    "### Use the cell below it to mount your google drive to dataset\n",
    " - go by the link\n",
    " - log in under your google accout\n",
    " - copy token key\n",
    " - imput it to this the imput line in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaaf688-bf49-403e-a92d-93f7b3197648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a12e1-cf2d-4239-a85f-40d5846b6d91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Enviroment installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa7b5e3-c933-4114-8170-e0e9b72d92a3",
   "metadata": {},
   "source": [
    "### on local pc\n",
    "```\n",
    "$ conda install pytorch-geometric -c rusty1s -c conda-forge\n",
    "```\n",
    "or via pip Wheels\n",
    "\n",
    "```\n",
    "$ python -c \"import torch; print(torch.__version__)\"\n",
    ">>> 1.9.0 - > {TORCH}=1.9.0\n",
    "python -c \"import torch; print(torch.version.cuda)\"\n",
    ">>> 11.1 - > {CUDA}=cu111\n",
    "```\n",
    "\n",
    "substite {TORCH} and {CUDA} in commands below by appropriate for your system\n",
    "```\n",
    "pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "pip install torch-geometric\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78411c-429f-4772-a54d-83d2a3572daf",
   "metadata": {},
   "source": [
    "#### on colab and also local pc (but on locat preferable is conda way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d43bf-7439-4e71-ac9e-3ec7318bca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take about 10 min in Colab\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
    "!pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b2ba5-9c51-41dc-8455-d087839379ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utils and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер\n",
    "def simple_preprocessing(batch):\n",
    "    tags = batch['tags'].long()\n",
    "    atom_numbers = batch['atomic_numbers'].long()\n",
    "    #voronoi_volumes = batch['voloroi_volumes'].long()\n",
    "    tags = F.one_hot(tags, num_classes=3)\n",
    "    atom_numbers = F.one_hot(atom_numbers, num_classes=100)\n",
    "    atom_embeds = torch.cat((tags, atom_numbers), 1)\n",
    "    edge_index = torch.Tensor(batch['edge_index_new']).long()\n",
    "    distances = torch.Tensor(batch['distances_new'])\n",
    "    angles = torch.Tensor(batch['contact_solid_angles'])\n",
    "    distances = torch.reshape(distances, (distances.shape[0], 1))\n",
    "    angles = torch.reshape(angles, (angles.shape[0], 1))                         \n",
    "    edges_embeds = torch.cat((distances, angles), 1)\n",
    "    \n",
    "    \n",
    "    return Data(x=atom_embeds, edge_index=edge_index, edge_attr=edges_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#датасет, который умеет возвращать эелемент и собственную длину\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, features_fields, target_field, type_='train', preprocessing=simple_preprocessing):\n",
    "        \n",
    "        self.data = data[features_fields]\n",
    "        self.length = len(data)\n",
    "        self.target = torch.Tensor(data[target_field].values)\n",
    "        self.type_ = type_\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        system = self.preprocessing(self.data.iloc[index])\n",
    "        \n",
    "        if self.type_ == 'train':\n",
    "            y = self.target[index]\n",
    "            \n",
    "            return system, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8f958",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672a07d",
   "metadata": {},
   "source": [
    "Гамма лежит в апдейт, квадратик в aggr, а фи в месседж; в этом примере гамма и фи -- умножение на матрицу после конкатенации, а квадратик -- суммирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae848d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GConv(MessagePassing):\n",
    "    def __init__(self, dim_atom=103, dim_edge=2, out_channels=2):\n",
    "        super(GConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.phi_output = 3\n",
    "        self.lin_phi = torch.nn.Linear(dim_atom*2+dim_edge, self.phi_output, bias=False)\n",
    "        self.lin_gamma = torch.nn.Linear(dim_atom + self.phi_output, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr\n",
    "        \n",
    "        # x has shape [N -- количество атомов в системе(батче), in_channels -- размерность вектора-атома]\n",
    "        # edge_index has shape [2, E] -- каждое ребро задаётся парой вершин\n",
    "\n",
    "        # Start propagating messages. \n",
    "    \n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)  #не совсем понял что такое сайз\n",
    "\n",
    "    def message(self, x, x_i, x_j, edge_attr):\n",
    "        concatenated = torch.cat((x_i, x_j, edge_attr), 1)\n",
    "        \n",
    "        return self.lin_phi(concatenated)\n",
    "        \n",
    "    def update(self, aggr_out, x):\n",
    "                \n",
    "        concatenated = torch.cat((x, aggr_out), 1)\n",
    "\n",
    "        return self.lin_gamma(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1232c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#собственно нейросеть\n",
    "class ConvNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_atom=103, dim_edge=2):\n",
    "        \n",
    "        super().__init__()          \n",
    "        self.conv = GConv(dim_atom=dim_atom, dim_edge=dim_edge)\n",
    "        self.lin = torch.nn.Linear(2, 1, bias=False)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        convoluted_1 = self.conv(batch)\n",
    "        scattered = scatter(convoluted_1, batch.batch, dim=0, reduce='sum')\n",
    "        summed = scattered\n",
    "        energy = self.lin(summed)\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9d7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train -- ходим по батчам из итератора, обнуляем градиенты, предсказываем у, считаем лосс, считаем градиенты, делаем шаг оптимайзера, записываем лосс\n",
    "def train(model, iterator, optimizer, criterion, print_every=10):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for i, (systems, ys) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(systems).squeeze()\n",
    "        loss = criterion(predictions.float(), ys.to(device).float())\n",
    "        loss.backward()     \n",
    "        \n",
    "        optimizer.step()      \n",
    "        \n",
    "        epoch_loss += loss.item()  \n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(i)\n",
    "            print(f'Loss: {epoch_loss/i}')\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems, ys in iterator:   \n",
    "\n",
    "            predictions = model(systems).squeeze()\n",
    "            loss = criterion(predictions.float(), ys.to(device).float())        \n",
    "\n",
    "            epoch_loss += loss.item()  \n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31952209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferens(model, iterator):\n",
    "    y = torch.tensor([])\n",
    "\n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems, ys in iterator:   \n",
    "              predictions = model(systemhs).squeeze()\n",
    "              y = torch.cat((y, predictions))\n",
    "      \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c98223",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for colab\n",
    "dataset_file_path = \"/content/drive/MyDrive/ocp_datasets/data/is2re/10k/train/structures.pkl\"\n",
    "\n",
    "# user specific folder\n",
    "# dataset_file_path= \"/Users/humonen/Downloads/structures_train.pkl\"\n",
    "# dataset_file_path= \"../../ocp_datasets/data/is2re/10k/train/structures.pkl\"\n",
    "\n",
    "with open(dataset_file_path,'rb') as f:\n",
    "    data_ori = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#сливаем новые фичи и фичи из Data\n",
    "for system in data_ori:\n",
    "    for key in system['data']:\n",
    "        system[key[0]] = key[1]\n",
    "    del system['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e01f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(data_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea59d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#делим на обучующую и валидационную выборки\n",
    "df_train, df_val = train_test_split(df, test_size=0.15)\n",
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cba43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сбрасываем индексы\n",
    "df_train = df_train.reset_index()\n",
    "df_val = df_val.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ae949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_cols = ['voloroi_volumes', 'voronoi_surface_areas', 'electronegativity', \n",
    "#                  'dipole_polarizability', 'edge_index_new', 'distances_new', 'contact_solid_angles']\n",
    "\n",
    "features_cols = ['atomic_numbers', 'edge_index_new', 'distances_new', 'contact_solid_angles', 'tags', 'voloroi_volumes']\n",
    "target_col = 'y_relaxed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb945e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "training_set = Dataset(df_train, features_cols, target_col)\n",
    "training_generator = DataLoader(training_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d078bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "valid_set = Dataset(df_val, features_cols, target_col)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b90d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = []\n",
    "df_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ca059",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"out_base_model\"\n",
    "\n",
    "writer = SummaryWriter(log_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#хочется уметь рисовать граф модели\n",
    "if False:\n",
    "    trace_system = []\n",
    "    writer.add_graph(CGConv, trace_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0046a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы тензор по умолчанию заводился на куде\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = ConvNN(dim_atom=trainig_set.dim,dim_edge=)\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "epochs = 20\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    print(f'epoch{i}')\n",
    "    loss.append(train(model, training_generator, optimizer, criterion))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models",
   "language": "python",
   "name": "ocp-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
