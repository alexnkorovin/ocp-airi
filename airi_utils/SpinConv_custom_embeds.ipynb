{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ce2842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset, DataListLoader\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7b325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch_geometric.loader import DataListLoader\n",
    "from torch_geometric.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2250c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('../ocpmodels/models'))\n",
    "sys.path.append(os.path.expanduser('../../ocp-airi'))\n",
    "\n",
    "from spinconv_with_embeds import spinconv\n",
    "#from ocpmodels.common.data_parallel import OCPDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573982a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    keys = ['pos', 'atomic_numbers', 'cell', 'natoms']\n",
    "    features_dict = {}\n",
    "    for key in keys:\n",
    "        features_dict[key] = system[key]\n",
    "    return Data(**features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397b13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 45\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b3aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb9fa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fbcfc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data_mod2.lmdbz\")\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "\n",
    "training_generator = DataListLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4d197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data_mod2.lmdbz\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataListLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2074744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 10000\n",
      "info for item: 0\n",
      "atomic_numbers:...........      [86]\n",
      "cell:..................... [1, 3, 3]\n",
      "cell_offsets:............. [2964, 3]\n",
      "cell_offsets_new:......... [1214, 3]\n",
      "contact_solid_angles:.....    [1214]\n",
      "direct_neighbor:..........    [1214]\n",
      "distances:................    [2964]\n",
      "distances_new:............    [1214]\n",
      "edge_angles:..............       607\n",
      "edge_index:............... [2, 2964]\n",
      "edge_index_new:........... [2, 1214]\n",
      "fixed:....................      [86]\n",
      "force:....................   [86, 3]\n",
      "natoms:...................        86\n",
      "pos:......................   [86, 3]\n",
      "pos_relaxed:..............   [86, 3]\n",
      "sid:......................   2472718\n",
      "spherical_domain_radii:...      [86]\n",
      "tags:.....................      [86]\n",
      "voronoi_surface_areas:....      [86]\n",
      "voronoi_volumes:..........      [86]\n",
      "y_init:...................    6.2825\n",
      "y_relaxed:................   -0.0256\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e04d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = spinconv(None, None, 1, otf_graph=True, regress_forces=False)\n",
    "#model = OCPDataParallel(model, output_device=0, num_gpus=2)\n",
    "model = DataParallel(model)\n",
    "#model = DistributedDataParallel(model, device_ids=[0, 1])\n",
    "#model = torch.load(\"id_all_2021-09-24-17-19-54.pickle\")\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67a46c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-25-11-15-39\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bf1d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909de556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no graph\n",
      "CPU times: user 416 µs, sys: 162 µs, total: 578 µs\n",
      "Wall time: 520 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34baf9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ca61e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-25-11-15-39\n",
      "Start training model DataParallel(\n",
      "  (module): spinconv(\n",
      "    (act): Swish()\n",
      "    (distance_expansion_forces): GaussianSmearing()\n",
      "    (embeddingblock2): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "      (source_embedding): Embedding(90, 32)\n",
      "      (target_embedding): Embedding(90, 32)\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dist_block): DistanceBlock(\n",
      "      (distance_expansion): GaussianSmearing()\n",
      "      (dist_scalar): Embedding(8100, 1)\n",
      "      (dist_offset): Embedding(8100, 1)\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (message_blocks): ModuleList(\n",
      "      (0): MessageBlock(\n",
      "        (act): Swish()\n",
      "        (spinconvblock): SpinConvBlock(\n",
      "          (act): Swish()\n",
      "          (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "          (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "          (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "          (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (embeddingblock1): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (source_embedding): Embedding(90, 32)\n",
      "          (target_embedding): Embedding(90, 32)\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (embeddingblock2): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "          (source_embedding): Embedding(90, 32)\n",
      "          (target_embedding): Embedding(90, 32)\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (energyembeddingblock): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=32, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "      (source_embedding): Embedding(90, 32)\n",
      "      (target_embedding): Embedding(90, 32)\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (force_output_block): ForceOutputBlock(\n",
      "      (act): Swish()\n",
      "      (spinconvblock): SpinConvBlock(\n",
      "        (act): Swish()\n",
      "        (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "        (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "        (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "        (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (block1): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (source_embedding): Embedding(90, 32)\n",
      "        (target_embedding): Embedding(90, 32)\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (block2): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
      "        (source_embedding): Embedding(90, 32)\n",
      "        (target_embedding): Embedding(90, 32)\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch 0\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO Bootstrap : Using [0]eth0:10.233.122.86<0>\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO NET/IB : No device found.\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO NET/Socket : Using [0]eth0:10.233.122.86<0>\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda10.2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 00/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 01/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 02/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 03/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 04/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 05/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 06/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 07/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 08/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 09/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 10/12 :    0   1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 11/12 :    0   1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Trees [0] -1/-1/-1->1->0|0->1->-1/-1/-1 [1] -1/-1/-1->1->0|0->1->-1/-1/-1 [2] -1/-1/-1->1->0|0->1->-1/-1/-1 [3] 0/-1/-1->1->-1|-1->1->0/-1/-1 [4] 0/-1/-1->1->-1|-1->1->0/-1/-1 [5] 0/-1/-1->1->-1|-1->1->0/-1/-1 [6] -1/-1/-1->1->0|0->1->-1/-1/-1 [7] -1/-1/-1->1->0|0->1->-1/-1/-1 [8] -1/-1/-1->1->0|0->1->-1/-1/-1 [9] 0/-1/-1->1->-1|-1->1->0/-1/-1 [10] 0/-1/-1->1->-1|-1->1->0/-1/-1 [11] 0/-1/-1->1->-1|-1->1->0/-1/-1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Setting affinity for GPU 1 to ffffff00,0000ffff,ff000000\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] -1/-1/-1->0->1|1->0->-1/-1/-1 [4] -1/-1/-1->0->1|1->0->-1/-1/-1 [5] -1/-1/-1->0->1|1->0->-1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] -1/-1/-1->0->1|1->0->-1/-1/-1 [10] -1/-1/-1->0->1|1->0->-1/-1/-1 [11] -1/-1/-1->0->1|1->0->-1/-1/-1\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 00 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 00 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 01 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 01 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 02 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 02 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 03 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 03 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 04 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 04 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 05 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 05 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 06 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 06 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 07 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 07 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 08 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 08 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO Channel 09 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Channel 09 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "\n",
      "ml-test-server-0:55848:55868 [1] include/alloc.h:41 NCCL WARN Cuda failure 'out of memory'\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO transport/p2p.cc:184 -> 1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO transport.cc:30 -> 1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO transport.cc:49 -> 1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO init.cc:766 -> 1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO init.cc:840 -> 1\n",
      "ml-test-server-0:55848:55868 [1] NCCL INFO group.cc:73 -> 1 [Async thread]\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO Call to connect returned Connection refused, retrying\n",
      "\n",
      "ml-test-server-0:55848:55867 [0] include/socket.h:403 NCCL WARN Connect to 10.233.122.86<47601> failed : Connection refused\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO bootstrap.cc:95 -> 2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO bootstrap.cc:363 -> 2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO transport.cc:50 -> 2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO init.cc:766 -> 2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO init.cc:840 -> 2\n",
      "ml-test-server-0:55848:55867 [0] NCCL INFO group.cc:73 -> 2 [Async thread]\n",
      "ml-test-server-0:55848:55848 [0] NCCL INFO init.cc:906 -> 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NCCL Error 2: unhandled system error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/ocp-airi/airi_utils/ModelFunctions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, print_every, epoch, writer, device)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch_geometric/nn/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_list)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(self, module, device_ids)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(network, devices, detach)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mparam_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mparam_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_coalesced_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/parallel/replicate.py\u001b[0m in \u001b[0;36m_broadcast_coalesced_reshape\u001b[0;34m(tensors, devices, detach)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Use the autograd function to broadcast if not detach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mtensor_copies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             return [tensor_copies[i:i + len(tensors)]\n\u001b[1;32m     73\u001b[0m                     for i in range(0, len(tensor_copies), len(tensors))]\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, *inputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mnon_differentiables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_requires_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/envs/ocp_models/lib/python3.8/site-packages/torch/nn/parallel/comm.py\u001b[0m in \u001b[0;36mbroadcast_coalesced\u001b[0;34m(tensors, devices, buffer_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_handle_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_coalesced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NCCL Error 2: unhandled system error"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b91c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
