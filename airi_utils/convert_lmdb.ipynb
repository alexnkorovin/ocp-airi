{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a0a45-fec7-4fb6-84c0-40d19ab46b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import zlib\n",
    "import bz2\n",
    "# import lz4\n",
    "import tqdm\n",
    "\n",
    "import lmdb\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from DataClasses import lmdb_dataset\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "np.set_printoptions(linewidth=100, precision=4, suppress=True)\n",
    "\n",
    "from ModelFunctions import to_bins_torch, convert_angles, restore_edge_angles, preprocessing, my_reshape\n",
    "from torch_geometric.data import Data\n",
    "from functools import partial\n",
    "\n",
    "#feather\n",
    "\n",
    "#import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfb858-3fdc-4d0a-be88-cc61d38c572f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e7a01-ee16-42fb-b2c7-772121a8d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for train sample\n",
    "dataset_size_list = {\n",
    "    0: \"10k\",\n",
    "    1: \"100k\",\n",
    "    2: \"all\"\n",
    "}\n",
    "mode_list = {\n",
    "    0: \"train\",\n",
    "    1: \"val\",\n",
    "    2: \"test\"\n",
    "}\n",
    "dataset_list = {\n",
    "    1: \"id\",\n",
    "    2: \"ood_ads\",\n",
    "    3: \"ood_cat\",\n",
    "    4: \"ood_both\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdd1c6-21be-4184-8a0c-f5391030e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting section\n",
    "root = \"../../ocp_datasets/data/is2re\"\n",
    "dataset_size = dataset_size_list[0]\n",
    "mode = mode_list[0]\n",
    "dataset = dataset_list[4]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7cebb-b4eb-44cc-bb30-8068c025ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_build(root, dataset_size, mode, dataset): # : mode: \"origin, origin_old, target\"\n",
    "    path = f'{root}/{dataset_size}/{mode}'\n",
    "    if mode != mode_list[0]:\n",
    "        path = f'{path}_{dataset}'\n",
    "    return path\n",
    "    \n",
    "dataset_origin_path_pkl = f'{path_build(root, dataset_size, mode, dataset)}/structures.pkl'\n",
    "dataset_origin_path = f'{path_build(root, dataset_size, mode, dataset)}/data_mod.lmdb'\n",
    "dataset_target_path = f'{path_build(root, dataset_size, mode, dataset)}/data_mod_conv.lmdb'\n",
    "\n",
    "(print(\n",
    "    f'dataset_origin_path_pkl: {dataset_origin_path_pkl}',\n",
    "    f'dataset_origin_path: {dataset_origin_path}',\n",
    "    f'dataset_target_path: {dataset_target_path}',\n",
    "    sep='\\n')\n",
    ")\n",
    "#/home/alex/Documents/ocp_datasets/data/is2re/all/val_ood_both\n",
    "#/home/alex/Documents/ocp_datasets/data/is2re/all/test_ood_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df5266-6e29-4a36-9ba2-1ed684f9c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_origin_old = SinglePointLmdbDataset({\"src\": dataset_origin_old_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97e4b7-b41f-462b-8408-f58f4f59ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_origin_old[0]['distances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52d4c6-d503-42cc-b6be-b7d69da2ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_origin = pd.read_pickle(dataset_origin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f969ec8-0623-41af-833d-349b52c4bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10k = lmdb_dataset(dataset_origin_path, compressed=False)\n",
    "data_10k[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12ee31-df5f-490c-b42e-184a3095c320",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82859a85-4652-4c85-b5be-4a2712b067ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_dataset(dataset_target_path, dataset_origin_old_path, dataset_origin_path, features_names=None):\n",
    "    dataset_origin = pd.read_pickle(dataset_origin_path)\n",
    "    \n",
    "    dataset_origin_old = lmdb_dataset(dataset_origin_path)\n",
    "    \n",
    "    dataset_target = lmdb.open(\n",
    "        dataset_target_path,\n",
    "        map_size=int(1e9*5), #~ 5 Gbyte\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=True,\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for ii, data_object_origin_old in enumerate(dataset_origin_old):\n",
    "\n",
    "            # Substitute: edge_index -> edge_index_new\n",
    "            data_object = dataset_origin_old[ii]\n",
    "            for feature_name in features_names:\n",
    "                feature = torch.from_numpy(dataset_origin[ii][feature_name+'_new'])\n",
    "                data_object[feature_name] = feature\n",
    "\n",
    "            # Write to LMDB\n",
    "            txn = dataset_target.begin(write=True)\n",
    "            txn.put(f\"{idx}\".encode(\"ascii\"), pickle.dumps(data_object, protocol=-1))\n",
    "            txn.commit()\n",
    "            dataset_target.sync()\n",
    "            if idx % 1000 == 0:\n",
    "                print('{} of {} for file {}'.format(idx, len(dataset_origin_old), dataset_target_path))\n",
    "            idx += 1\n",
    "\n",
    "    dataset_target.close()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db7be19-92ee-40db-a006-cb187d4102ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### update_dataset_pyg2dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8488f-c225-4072-bed8-32621fe05d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_dataset_pyg2dict(dataset_target_path, dataset_origin_path):\n",
    "        \n",
    "    dataset_origin = lmdb_dataset(dataset_origin_path, compressed=False)\n",
    "    \n",
    "    dataset_target = lmdb.open(\n",
    "        dataset_target_path,\n",
    "        map_size=int(1e12), #~ 5 Gbyte\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=False,\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    for ii, element in enumerate(dataset_origin):\n",
    "\n",
    "            # Substitute: edge_index -> edge_index_new\n",
    "            \n",
    "            element = dict(list(element))\n",
    "            del element['edge_angles'][1::2]    \n",
    "            for ii, el in enumerate(element['edge_angles']):\n",
    "               element['edge_angles'][ii] = element['edge_angles'][ii].reset_index().values\n",
    "            \n",
    "            # Write to LMDB\n",
    "            \n",
    "            txn = dataset_target.begin(write=True)\n",
    "            txn.put(f\"{idx}\".encode(\"ascii\"), zlib.compress(pickle.dumps(element, protocol=-1), level=1))\n",
    "            \n",
    "            #txn.put(key=f\"{idx}\".encode(\"ascii\"), value=pickle.dumps(element, protocol=-1))\n",
    "            txn.commit()\n",
    "            dataset_target.sync()\n",
    "            \n",
    "            if idx==10:\n",
    "                break\n",
    "            \n",
    "            if idx%1000==0:\n",
    "                print('{} of {} for file {}'.format(idx, len(dataset_origin), dataset_target_path))\n",
    "            idx += 1\n",
    "            \n",
    "    print(dataset_target.info())\n",
    "    dataset_target.close()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9ae91-3cd1-4bbb-9c3e-4df1d9890a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_dataset_pyg2dict_1(dataset_target_path, dataset_origin_path):\n",
    "        \n",
    "    dataset_origin = lmdb_dataset(dataset_origin_path, compressed=False)\n",
    "    \n",
    "    dataset_target = lmdb.open(\n",
    "        dataset_target_path,\n",
    "        map_size=int(1e12), #~ 5 Gbyte\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=False,\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    for ii, element in enumerate(dataset_origin):\n",
    "\n",
    "            # Substitute: edge_index -> edge_index_new\n",
    "            \n",
    "            element = dict(list(element))\n",
    "            del element['edge_angles'][1::2]    \n",
    "            for ii, el in enumerate(element['edge_angles']):\n",
    "               element['edge_angles'][ii] = element['edge_angles'][ii].reset_index().values\n",
    "            \n",
    "            # Write to LMDB\n",
    "            \n",
    "            txn = dataset_target.begin(write=True)\n",
    "            txn.put(f\"{idx}\".encode(\"ascii\"), zlib.compress(pickle.dumps(element, protocol=-1), level=1))\n",
    "            \n",
    "            #txn.put(key=f\"{idx}\".encode(\"ascii\"), value=pickle.dumps(element, protocol=-1))\n",
    "            txn.commit()\n",
    "            dataset_target.sync()\n",
    "            \n",
    "            if idx==10:\n",
    "                break\n",
    "            \n",
    "            if idx%1000==0:\n",
    "                print('{} of {} for file {}'.format(idx, len(dataset_origin), dataset_target_path))\n",
    "            idx += 1\n",
    "            \n",
    "    print(dataset_target.info())\n",
    "    dataset_target.close()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf4134-9a49-485e-9d16-b5a3e473a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dataset_pyg2dict(dataset_target_path, dataset_origin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417be92-36e5-42ad-a020-87aa0be16b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target_path_test ='../../ocp_datasets/data/is2re/10k/train/data_mod.lmdb'\n",
    "suffix = '.lmdb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f182c5da-a082-48eb-9640-0dde71abfc19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Benchmark of diffferent options for .lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2847a5e-9c54-4525-8f32-db9e681596f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "def bench_dataset(el):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec826b5a-6052-46da-aad6-b68067b190d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255e6fd-c5ca-47b5-8c80-4e5c2234cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "a = Parallel(n_jobs=-1)(delayed(bench_dataset)(dataset_target[i]) for i in range(len(dataset_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1db68-7f4c-48e8-8e0b-b092703dd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path_test+'_orig'+suffix, compressed=False)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a54fd-d5fb-49f7-ae49-d303b9d29f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path_test+'_dict'+suffix, compressed=False)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d9d02-b8ee-4b60-a611-d1e640cb1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path_test+'_dict_short'+suffix, compressed=False)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda5831-bb74-4d2e-a295-30cb46b59d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path_test+'_dict_short_numpy'+suffix, compressed=False)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf19286-5d54-4fdb-907d-e11119f209e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset_target = lmdb_dataset(dataset_target_path_test+'_dict_short_numpy_zip'+suffix, compressed=True)\n",
    "for el in enumerate(dataset_target):\n",
    "    a = el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0458ed-e035-4b0d-8c84-9c15a2ccfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target = lmdb_dataset(dataset_target_path_test'_dict_short_numpy_zip'+suffix, compressed=True)\n",
    "dataset_target[0]['edge_angles'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde5b0b4-91ea-4cca-be20-1d4c6b60495b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Compressed pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365ca33-63db-4910-b22a-ec36226f60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('data_10k.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(dataset_target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec771929-c393-4243-91a9-5f43c7a4bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('data_10k.pkl', 'rb') as f:\n",
    "    data = f.read()\n",
    "    data = pickle.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372bbbc-b158-466c-b3e1-7967b306aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('data_10k.pbz2', 'wb') as f:\n",
    "    f.write(zlib.compress(pickle.dumps(dataset_target[0]), level = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72a99b-77fb-4488-88b6-698b43c1ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with open('data_10k.pbz2', 'rb') as f:\n",
    "    data = f.read()\n",
    "    data = pickle.loads(zlib.decompress(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b74c9-972a-4c0a-ad81-3e3d9927f1bc",
   "metadata": {},
   "source": [
    "#### Feather file-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb678d-9dd3-4610-a0fe-d0cfcaf118fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47e2b3d8-415e-4888-80a5-8f123a3b910a",
   "metadata": {},
   "source": [
    "#### restore_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea68f60-3b20-4811-a91f-18252ff9bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_angles(array):\n",
    "    array[:, 1] = np.pi - array[:, 1]\n",
    "    array[:, 3] = -array[:, 3]\n",
    "    return array\n",
    "\n",
    "def restore_edge_angles(list_of_arrays):\n",
    "    el_new= []\n",
    "    for el in list_of_arrays:\n",
    "        el_new.append(el)\n",
    "        el_new.append(convert_angles(el.copy()))        \n",
    "    return el_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8468670-4584-4ebf-924d-802ec2ef0536",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Benchmark preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effaaca-d1a0-4257-b14a-98e3bed9916b",
   "metadata": {},
   "source": [
    "#### mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54500db7-1e3c-44c7-aaf7-173611fd223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target_path ='../../ocp_datasets/data/is2re/10k/train/data_mod2.lmdbz'\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "suffix = '.lmdb'\n",
    "\n",
    "suffix = dataset_target_path.split('.')[-1]\n",
    "print(suffix)\n",
    "\n",
    "compressed = (\n",
    "    True if suffix == 'lmdbz'\n",
    "    else False\n",
    ")\n",
    "\n",
    "print(compressed)\n",
    "dataset_target.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041de39c-bb3f-467f-9d30-b80ef3b1587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(dataset_target_path)\n",
    "dataset_target = lmdb_dataset(dataset_target_path, compressed=True)\n",
    "for el in dataset_target:\n",
    "    a = preprocessing(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7625075-ebf8-40f0-b1af-936440eeb5d5",
   "metadata": {},
   "source": [
    "**multiprocessing (do not work with n_jobs > 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df419479-d722-49d9-858e-8ee8230b5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_target_path)\n",
    "dataset_target = lmdb_dataset(dataset_target_path, compressed=True)\n",
    "#a = Parallel(n_jobs=-1)(delayed(preprocessing)(el) for el in dataset_target)\n",
    "a = Parallel(n_jobs=-1)(delayed(preprocessing)(dataset_target[i]) for i in range(len(dataset_target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3a94d-4b50-4471-a063-17dd52f47d09",
   "metadata": {},
   "source": [
    "#### mod1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848af312-81f0-4216-8fbd-c7eec127de78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target_path ='../../ocp_datasets/data/is2re/10k/train/data_mod.lmdb'\n",
    "suffix = '.lmdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e86b9-6aeb-48c4-b9c7-27a1456460de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target = lmdb_dataset(dataset_target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1212b-7f6b-4455-961a-2622517a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf1aabd-1849-43bd-9577-2a5633e069e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(dataset_target_path)\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "for el in dataset_target:\n",
    "    a = preprocessing(el, opt='edges_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31063cf1-4128-4a59-8795-f4a9785b0327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(dataset_target_path)\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "a = Parallel(n_jobs=-1)(delayed(preprocessing)(dataset_target[i], opt='edges_only') for i in range(len(dataset_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb41ac-65fb-45d0-a27c-5a771f5718e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(dataset_target_path)\n",
    "dataset_target = lmdb_dataset(dataset_target_path)\n",
    "With Pool(12) as p:\n",
    "    a = p.map(preprocessing, dataset_target[i], opt='edges_only'), range(len(dataset_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236152f-752e-41b0-9903-e3277115cb59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Parallel test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dac03-f0ba-459c-beda-b1bda7db4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(x):\n",
    "#     #return sqrt(x)\n",
    "#     return np.sin(x)/np.cos(x)\n",
    "from test import func\n",
    "\n",
    "n = 1000000\n",
    "c = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc03d6e-b969-4f45-93f8-df603753f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838ae73-c140-4b8f-8519-7065771ad27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "list_comprehension = [func(i) for i in range(n)]\n",
    "print('Parallel: {} s'.format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf3710-cacd-45cd-b9ed-cc641312417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "if __name__ == '__main__':\n",
    "    list_from_parallel = Parallel(n_jobs=c)(delayed(func)(i) for i in range(n))\n",
    "    print('Parallel: {} s'.format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e0efb-5f85-4886-bf4d-a86b866de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "    results = Parallel(n_jobs=c)(delayed(func)(x) for x in range(n))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00063d8-6f3e-4c6d-aa93-81475de9839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor(c) as executor:\n",
    "    results = Parallel(n_jobs=c)(delayed(func)(x) for x in range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fcd072-98eb-49ed-b9ea-3f129dce3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "list_comprehension = [func(i) for i in range(n)]\n",
    "print('Parallel: 0 Pool, {} s'.format(time.time() - start_t))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    for c in range(1,13):\n",
    "        start_t = time.time()\n",
    "        with Pool(c) as p:\n",
    "            result = p.map(func, list(range(n)))\n",
    "            print('Parallel: {} core, {} s'.format(c, time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21f67e-dd4d-40ed-9620-7ab90cbc5031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a2b47-5cb9-495b-af57-e43d6a18b99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e614a-cef4-4a17-94bd-8e7d5d050235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.path import Path\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import sys\n",
    "\n",
    "## Check if one line segment contains another. \n",
    "\n",
    "def check_paths(path):\n",
    "    for other_path in a:\n",
    "        res='no cross'\n",
    "        chck = Path(other_path)\n",
    "        if chck.contains_path(path)==1:\n",
    "            res = 'cross'\n",
    "            break\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ## Create pairs of points for line segments\n",
    "    a = zip(np.random.rand(5000,2),np.random.rand(5000,2))\n",
    "    a = [Path(x) for x in a]\n",
    "    b = zip(np.random.rand(300,2),np.random.rand(300,2))\n",
    "    c = 2\n",
    "    now = time.time()\n",
    "\n",
    "    if c >= 2:\n",
    "        res = Parallel(n_jobs=c) (delayed(check_paths) (Path(points)) for points in b)\n",
    "    else:\n",
    "        res = [check_paths(Path(points)) for points in b]\n",
    "    print(\"Finished in\", time.time()-now , \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6959a6-2af8-4105-aeed-8d11ca3f11c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a55f6c6-d532-4da3-a948-736f71418d8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43046340-a8fc-4074-9546-2bfe5094a880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_datasets(dataset_origin_path_list, dataset_target_path, root_dir=\"\"):\n",
    "        \n",
    "    dataset_target = lmdb.open(\n",
    "      f'{root_dir}{dataset_target_path}',\n",
    "        map_size=int(1e12), #~ 5 Gbyte\n",
    "        subdir=False,\n",
    "        meminit=False,\n",
    "        map_async=True,\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "    \n",
    "    with dataset_target.begin(write=True) as txn:\n",
    "        for dataset_origin_file in dataset_origin_path_list:\n",
    "            if dataset_origin_file != \"batch10_data_mod1.lmdbz\":\n",
    "                to_dict = True\n",
    "                byte = False\n",
    "            else:\n",
    "                to_dict = False\n",
    "                byte = True\n",
    "\n",
    "            dataset_origin = lmdb_dataset(f'{root_dir}{dataset_origin_file}', byte=byte)\n",
    "\n",
    "            for element in dataset_origin:\n",
    "                    if to_dict: \n",
    "                        element = dict(list(element))\n",
    "                        # Write to LMDB\n",
    "                        txn.put(f\"{idx}\".encode(\"ascii\"), zlib.compress(pickle.dumps(element, protocol=-1), level=1))\n",
    "                        #txn.put(key=f\"{idx}\".encode(\"ascii\"), value=pickle.dumps(element, protocol=-1))\n",
    "                    else:\n",
    "                        txn.put(f\"{idx}\".encode(\"ascii\"), element)\n",
    "                    idx += 1\n",
    "\n",
    "                    if idx%5000==0:\n",
    "                        print('{} of {} for file {}'.format(idx, len(dataset_origin), dataset_target_path))\n",
    "                \n",
    "    print(dataset_target.info())\n",
    "    dataset_target.close()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4359cb3-eceb-4d5c-9ecb-50b27bbe079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_origin_path_list = ['data_mod1_0_50039.lmdbz',\n",
    "'batch10_data_mod1.lmdbz',\n",
    "'data_mod1_last.lmdbz']\n",
    "dataset_target_path = 'merged/data_mod1.lmdbz'\n",
    "root_dir = '/share/catalyst/ocp_datasets/is2re_test_challenge_2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b1aa3-c582-45c5-a377-12b64f7c0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_datasets(dataset_origin_path_list, dataset_target_path, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c193f-e4a3-4f3a-bd00-3ca468c10998",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# check lmdb file\n",
    "a = [0]\n",
    "data_10 = lmdb_dataset(root_dir+dataset_target_path, byte=True)\n",
    "for element in data_10:\n",
    "    a[0] = element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3e2c7-181f-4a12-a68f-94495305d580",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### get keys of lmdb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2114e-0c20-46b7-8c95-0c44df3fc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10_path = root_dir+dataset_origin_path_list[1]\n",
    "data_10_path_env = lmdb.open(\n",
    "            data_10_path,\n",
    "            subdir=False,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=True,\n",
    "            meminit=False,\n",
    "            max_readers=1000,\n",
    "        )\n",
    "\n",
    "data_10_path_env.stat()[\"entries\"]\n",
    "\n",
    "with data_10_path_env.begin() as txn:\n",
    "    with txn.cursor() as curs:\n",
    "        keys = [key for key, value in curs]\n",
    "        # print('key is:', curs.get('key'.encode('ascii')))\n",
    "\n",
    "print(keys[1])\n",
    "\n",
    "data_10_path_datapoint_pickled = data_10_path_env.begin().get(keys[1])\n",
    "print(type(data_10_path_datapoint_pickled))\n",
    "\n",
    "data_10_obj = pickle.loads(zlib.decompress(data_10_path_datapoint_pickled))\n",
    "print(data_10_obj['natoms'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
