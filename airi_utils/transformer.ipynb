{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec82612-795e-4dce-9284-f28fc73269ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2165b-8141-4724-b2b1-0176926d4e8d",
   "metadata": {},
   "source": [
    "### Google colab\n",
    "\n",
    "This notebook can be used in colab (**this is the fastest way to run calculation on unconfigured system**):\n",
    "\n",
    "In google colab https://colab.research.google.com/ go to File | Open notebook | GitHub - \n",
    "insert the path to the current notebook and open it: https://github.com/alexnkorovin/ocp-airi/blob/dev/airi_utils/our_base_model.ipynb\n",
    "\n",
    "Before start:\n",
    "\n",
    "1. Put this shared folder with datasets in your Google Drive root folder /drive/MyDrive/\n",
    "\n",
    "This folders  can are available by the **sharing** link below:\n",
    "\n",
    "*   ocp_datasets [[ share link to drive](https://drive.google.com/drive/folders/1Nn9t-zTJiRP1-34rdAugv6aY_2-BSQfN?usp=sharing)]<br>\n",
    "\n",
    "```\n",
    "Note:\n",
    "if this folder is saved by sharing link it should contain the following files\n",
    "\n",
    "ocp-datasets/data/is2re/train/all/val_ood_both/data.lmdb\n",
    "ocp-datasets/data/is2re/train/all/test_ood_both/data.lmdb\n",
    "ocp-datasets/data/is2re/train/all/test_ood_both/structures.pkl\n",
    "\n",
    " ```\n",
    "2. Enable GPU support in Edit/Notebook Settings\n",
    "\n",
    "### on local pc\n",
    "\n",
    "download specified data files by [link](https://drive.google.com/drive/folders/1Nn9t-zTJiRP1-34rdAugv6aY_2-BSQfN?usp=sharing) into local folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872f626-55f7-472d-9b53-c71e2f08d3df",
   "metadata": {},
   "source": [
    "### Use the cell below it to mount your google drive to dataset\n",
    " - go by the link\n",
    " - log in under your google accout\n",
    " - copy token key\n",
    " - imput it to this the imput line in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593343cf-6ab8-4e57-afce-8bf40c2fc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d80224-8dd8-4c54-a043-462929999211",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Enviroment installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9044a6",
   "metadata": {},
   "source": [
    "### on local pc\n",
    "```\n",
    "$ conda install pytorch-geometric -c rusty1s -c conda-forge\n",
    "```\n",
    "or via pip Wheels\n",
    "\n",
    "```\n",
    "$ python -c \"import torch; print(torch.__version__)\"\n",
    ">>> 1.9.0 - > {TORCH}=1.9.0\n",
    "python -c \"import torch; print(torch.version.cuda)\"\n",
    ">>> 11.1 - > {CUDA}=cu111\n",
    "```\n",
    "\n",
    "substite {TORCH} and {CUDA} in commands below by appropriate for your system\n",
    "```\n",
    "pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "pip install torch-geometric\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93ce2d-3a74-4185-b186-7fdb406c1271",
   "metadata": {},
   "source": [
    "#### on colab and also local pc (but on locat preferable is conda way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d60565-7dae-4aaf-bcd1-16b0ad4bbbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This might take about 10 min in Colab (нужно только в колабе)\n",
    "# !pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
    "# !pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
    "# !pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8e472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_preprocessing(system):\n",
    "    \n",
    "    tags = system['tags'].long().to(device)\n",
    "    tags = F.one_hot(tags, num_classes=3)\n",
    "    \n",
    "    atom_numbers = system['atomic_numbers'].long().to(device)\n",
    "    atom_numbers = F.one_hot(atom_numbers, num_classes=100)\n",
    "    \n",
    "    pos = system['pos'].to(device)\n",
    "    \n",
    "    atom_features = (tags, atom_numbers, pos)#, spherical_radii)\n",
    "    atom_embeds = torch.cat(atom_features, 1)\n",
    "                    \n",
    "    #padding\n",
    "    pad_value = 0#-float(\"Inf\")\n",
    "    pads = torch.full((MAX_LEN-atom_embeds.shape[0], atom_embeds.shape[1]), pad_value)\n",
    "    padding_mask = torch.cat((torch.full((atom_embeds.shape[0], ), False), torch.full((MAX_LEN-atom_embeds.shape[0], ), True)))\n",
    "    atom_embeds = torch.cat((atom_embeds, pads))\n",
    "    \n",
    "    return (atom_embeds, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#датасет, который умеет возвращать эелемент и собственную длину\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, features_fields, target_field, type_='train', preprocessing=simple_preprocessing):\n",
    "        \n",
    "        self.data = data[features_fields]\n",
    "        self.length = len(data)\n",
    "        self.target = torch.Tensor(data[target_field].values)\n",
    "        self.type_ = type_\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "        for feature in features_fields:\n",
    "             self.data[feature] = self.data[feature].apply(lambda x: x[:MAX_LEN])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        system = self.preprocessing(self.data.iloc[index])\n",
    "        \n",
    "        if self.type_ == 'train':\n",
    "            y = self.target[index]\n",
    "            \n",
    "            return system, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e1232c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#собственно нейросеть\n",
    "class NN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_atom=106):\n",
    "        \n",
    "        super().__init__() \n",
    "                \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=dim_atom, nhead=1)\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=3)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(dim_atom, 1, bias=True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        padded, src_key_padding_mask = batch[0], batch[1]\n",
    "                                \n",
    "        padded = padded.permute((1, 0, 2))\n",
    "\n",
    "        embeds = self.transformer_encoder(padded, src_key_padding_mask=src_key_padding_mask)\n",
    "                \n",
    "        embeds = embeds.permute((1, 0, 2))\n",
    "        \n",
    "        summed = torch.sum(embeds, 1)\n",
    "                \n",
    "        energy = self.lin(summed)\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20798f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_scalars(lr, loss, writer, step=-1, epoch=-1, type_='train'):\n",
    "    if type_ == 'train':\n",
    "        writer.add_scalar('lr per step on train', lr, step) \n",
    "        writer.add_scalar('loss per step on train', loss, step)\n",
    "    if type_ == 'val':\n",
    "        writer.add_scalar('loss per epoch on val', loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_hist(model, writer, step):\n",
    "    for name, weight in model.named_parameters():\n",
    "        try:\n",
    "            writer.add_histogram(name, weight, step)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc9d7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train -- ходим по батчам из итератора, обнуляем градиенты, предсказываем у, считаем лосс, считаем градиенты, делаем шаг оптимайзера, записываем лосс\n",
    "def train(model, iterator, optimizer, criterion, print_every=10, epoch=0, writer=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, (systems, ys) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(systems).squeeze()\n",
    "        \n",
    "        loss = criterion(predictions.float(), ys.to(device).float())\n",
    "        loss.backward()     \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = loss.item() \n",
    "        epoch_loss += batch_loss  \n",
    "        \n",
    "        if writer != None:\n",
    "            \n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            step = i + epoch*len(iterator)\n",
    "            \n",
    "            send_hist(model, writer, i)\n",
    "            send_scalars(lr, batch_loss, writer, step=step, epoch=epoch, type_='train')\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'step {i} from {len(iterator)} at epoch {epoch}')\n",
    "            print(f'Loss: {batch_loss}')\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8e76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, epoch=0, writer=False):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems, ys in iterator:   \n",
    "\n",
    "            predictions = model(systems).squeeze()\n",
    "            loss = criterion(predictions.float(), ys.to(device).float())        \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    overall_loss = epoch_loss / len(iterator)\n",
    "\n",
    "    if writer != None:\n",
    "        send_scalars(None, overall_loss, writer, step=None, epoch=epoch, type_='val')\n",
    "                \n",
    "    print(f'epoch loss {overall_loss}')\n",
    "            \n",
    "    return overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31952209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferens(model, iterator):\n",
    "    y = torch.tensor([])\n",
    "\n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems in iterator:   \n",
    "          predictions = model(systems).squeeze()\n",
    "          y = torch.cat((y, predictions))\n",
    "      \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c98223",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab42657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename):    \n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        data_ori = pickle.load(f)\n",
    "    \n",
    "    #сливаем новые фичи и фичи из Data\n",
    "    for system in data_ori:\n",
    "        for key in system['data']:\n",
    "            system[key[0]] = key[1]\n",
    "        del system['data']\n",
    "        \n",
    "    df = pd.DataFrame(data_ori)\n",
    "    data_ori=[]\n",
    "    print(df.columns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6fc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab\n",
    "# train_dataset_file_path = \"/content/drive/MyDrive/ocp_datasets/data/is2re/10k/train/structures_train.pkl\"\n",
    "\n",
    "# user specific folder\n",
    "# train_dataset_file_path = os.path.expanduser(\"~/Downloads/structures_train.pkl\")\n",
    "train_dataset_file_path= \"../../ocp_datasets/data/is2re/10k/train/structures_train.pkl\"\n",
    "\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/structures_val_ood_both.pkl\")\n",
    "# val_dataset_file_path = os.path.expanduser(\"~/Downloads/structures_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcfc1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'voronoi_volumes', 'voronoi_surface_areas',\n",
      "       'spherical_domain_radii', 'distances_new', 'contact_solid_angles',\n",
      "       'direct_neighbor', 'edge_index_new', 'atomic_numbers', 'cell',\n",
      "       'cell_offsets', 'distances', 'edge_index', 'fixed', 'force', 'natoms',\n",
      "       'pos', 'pos_relaxed', 'sid', 'tags', 'y_init', 'y_relaxed'],\n",
      "      dtype='object')\n",
      "Index(['id', 'voronoi_volumes', 'voronoi_surface_areas',\n",
      "       'spherical_domain_radii', 'distances_new', 'contact_solid_angles',\n",
      "       'direct_neighbor', 'edge_index_new', 'atomic_numbers', 'cell',\n",
      "       'cell_offsets', 'distances', 'edge_index', 'fixed', 'force', 'natoms',\n",
      "       'pos', 'pos_relaxed', 'sid', 'tags', 'y_init', 'y_relaxed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_train = read_df(train_dataset_file_path)\n",
    "df_val = read_df(val_dataset_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "476cdcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0\n",
    "MAX_LEN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c15ae949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_cols = ['atomic_numbers', 'edge_index_new', 'distances_new', \n",
    "#                  'contact_solid_angles', 'tags', 'voronoi_volumes', 'spherical_domain_radii']\n",
    "\n",
    "features_cols = ['pos', 'atomic_numbers', 'tags']\n",
    "\n",
    "target_col = 'y_relaxed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb945e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50789/1806769300.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[feature] = self.data[feature].apply(lambda x: x[:MAX_LEN])\n"
     ]
    }
   ],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "training_set = Dataset(df_train, features_cols, target_col)\n",
    "training_generator = DataLoader(training_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11d078bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50789/1806769300.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[feature] = self.data[feature].apply(lambda x: x[:MAX_LEN])\n"
     ]
    }
   ],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "valid_set = Dataset(df_val, features_cols, target_col)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b90d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = []\n",
    "df_val = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ca059",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0046a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#чтобы тензор по умолчанию заводился на куде\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fa2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = NN(dim_atom=next(iter(training_generator))[0][0].shape[2])\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc1c0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-06-18-42-16\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e477b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#граф модели\n",
    "trace_system = next(iter(training_generator))[0]\n",
    "writer.add_graph(model, (trace_system,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-06-18-42-16\n",
      "epoch 0\n",
      "step 9 from 157 at epoch 0\n",
      "Loss: 60.193321228027344\n",
      "step 19 from 157 at epoch 0\n",
      "Loss: 14.562389373779297\n",
      "step 29 from 157 at epoch 0\n",
      "Loss: 5.056543350219727\n",
      "step 39 from 157 at epoch 0\n",
      "Loss: 6.576595783233643\n",
      "step 49 from 157 at epoch 0\n",
      "Loss: 1.9704363346099854\n",
      "step 59 from 157 at epoch 0\n",
      "Loss: 2.0375914573669434\n",
      "step 69 from 157 at epoch 0\n",
      "Loss: 1.682887077331543\n",
      "step 79 from 157 at epoch 0\n",
      "Loss: 1.7606043815612793\n",
      "step 89 from 157 at epoch 0\n",
      "Loss: 2.0335230827331543\n",
      "step 99 from 157 at epoch 0\n",
      "Loss: 2.151097297668457\n",
      "step 109 from 157 at epoch 0\n",
      "Loss: 1.8127589225769043\n",
      "step 119 from 157 at epoch 0\n",
      "Loss: 1.8522560596466064\n",
      "step 129 from 157 at epoch 0\n",
      "Loss: 2.257084369659424\n",
      "step 139 from 157 at epoch 0\n",
      "Loss: 3.031787872314453\n",
      "step 149 from 157 at epoch 0\n",
      "Loss: 1.9613006114959717\n",
      "epoch loss 2.232994241177883\n",
      "epoch 1\n",
      "step 9 from 157 at epoch 1\n",
      "Loss: 1.8941553831100464\n",
      "step 19 from 157 at epoch 1\n",
      "Loss: 1.876897931098938\n",
      "step 29 from 157 at epoch 1\n",
      "Loss: 1.7281737327575684\n",
      "step 39 from 157 at epoch 1\n",
      "Loss: 3.0804481506347656\n",
      "step 49 from 157 at epoch 1\n",
      "Loss: 1.499625325202942\n",
      "step 59 from 157 at epoch 1\n",
      "Loss: 2.5995121002197266\n",
      "step 69 from 157 at epoch 1\n",
      "Loss: 1.6522012948989868\n",
      "step 79 from 157 at epoch 1\n",
      "Loss: 2.1566221714019775\n",
      "step 89 from 157 at epoch 1\n",
      "Loss: 1.9066565036773682\n",
      "step 99 from 157 at epoch 1\n",
      "Loss: 2.283419132232666\n",
      "step 109 from 157 at epoch 1\n",
      "Loss: 3.9582600593566895\n",
      "step 119 from 157 at epoch 1\n",
      "Loss: 2.1593194007873535\n",
      "step 129 from 157 at epoch 1\n",
      "Loss: 4.299829006195068\n",
      "step 139 from 157 at epoch 1\n",
      "Loss: 2.9823646545410156\n",
      "step 149 from 157 at epoch 1\n",
      "Loss: 3.0687508583068848\n",
      "epoch loss 3.067925276353841\n",
      "epoch 2\n",
      "step 9 from 157 at epoch 2\n",
      "Loss: 5.257871627807617\n",
      "step 19 from 157 at epoch 2\n",
      "Loss: 3.331895351409912\n",
      "step 29 from 157 at epoch 2\n",
      "Loss: 2.150027275085449\n",
      "step 39 from 157 at epoch 2\n",
      "Loss: 2.893078565597534\n",
      "step 49 from 157 at epoch 2\n",
      "Loss: 1.5507707595825195\n",
      "step 59 from 157 at epoch 2\n",
      "Loss: 1.8100416660308838\n",
      "step 69 from 157 at epoch 2\n",
      "Loss: 1.5785815715789795\n",
      "step 79 from 157 at epoch 2\n",
      "Loss: 2.2632882595062256\n",
      "step 89 from 157 at epoch 2\n",
      "Loss: 1.864622712135315\n",
      "step 99 from 157 at epoch 2\n",
      "Loss: 2.2351880073547363\n",
      "step 109 from 157 at epoch 2\n",
      "Loss: 1.7393440008163452\n",
      "step 119 from 157 at epoch 2\n",
      "Loss: 2.430464267730713\n",
      "step 129 from 157 at epoch 2\n",
      "Loss: 1.6727691888809204\n",
      "step 139 from 157 at epoch 2\n",
      "Loss: 2.464512586593628\n",
      "step 149 from 157 at epoch 2\n",
      "Loss: 1.9543166160583496\n",
      "epoch loss 2.7225894806025277\n",
      "epoch 3\n",
      "step 9 from 157 at epoch 3\n",
      "Loss: 2.0057382583618164\n",
      "step 19 from 157 at epoch 3\n",
      "Loss: 2.063383102416992\n",
      "step 29 from 157 at epoch 3\n",
      "Loss: 2.6028130054473877\n",
      "step 39 from 157 at epoch 3\n",
      "Loss: 2.27117657661438\n",
      "step 49 from 157 at epoch 3\n",
      "Loss: 1.8128620386123657\n",
      "step 59 from 157 at epoch 3\n",
      "Loss: 1.7395607233047485\n",
      "step 69 from 157 at epoch 3\n",
      "Loss: 3.766195058822632\n",
      "step 79 from 157 at epoch 3\n",
      "Loss: 2.1874654293060303\n",
      "step 89 from 157 at epoch 3\n",
      "Loss: 2.318962574005127\n",
      "step 99 from 157 at epoch 3\n",
      "Loss: 1.9972411394119263\n",
      "step 109 from 157 at epoch 3\n",
      "Loss: 1.7606204748153687\n",
      "step 119 from 157 at epoch 3\n",
      "Loss: 2.6846046447753906\n",
      "step 129 from 157 at epoch 3\n",
      "Loss: 1.9031907320022583\n",
      "step 139 from 157 at epoch 3\n",
      "Loss: 1.9356532096862793\n",
      "step 149 from 157 at epoch 3\n",
      "Loss: 1.8403520584106445\n",
      "epoch loss 3.29434616120575\n",
      "epoch 4\n",
      "step 9 from 157 at epoch 4\n",
      "Loss: 1.8632888793945312\n",
      "step 19 from 157 at epoch 4\n",
      "Loss: 1.9616987705230713\n",
      "step 29 from 157 at epoch 4\n",
      "Loss: 1.746661901473999\n",
      "step 39 from 157 at epoch 4\n",
      "Loss: 2.4414782524108887\n",
      "step 49 from 157 at epoch 4\n",
      "Loss: 1.8780440092086792\n",
      "step 59 from 157 at epoch 4\n",
      "Loss: 2.0115673542022705\n",
      "step 69 from 157 at epoch 4\n",
      "Loss: 1.3750689029693604\n",
      "step 79 from 157 at epoch 4\n",
      "Loss: 1.9193655252456665\n",
      "step 89 from 157 at epoch 4\n",
      "Loss: 1.9065589904785156\n",
      "step 99 from 157 at epoch 4\n",
      "Loss: 1.8983564376831055\n",
      "step 109 from 157 at epoch 4\n",
      "Loss: 1.9132570028305054\n",
      "step 119 from 157 at epoch 4\n",
      "Loss: 1.9072946310043335\n",
      "step 129 from 157 at epoch 4\n",
      "Loss: 2.351764678955078\n",
      "step 139 from 157 at epoch 4\n",
      "Loss: 2.213956832885742\n",
      "step 149 from 157 at epoch 4\n",
      "Loss: 1.8663662672042847\n",
      "epoch loss 2.192726793191622\n",
      "epoch 5\n",
      "step 9 from 157 at epoch 5\n",
      "Loss: 1.8820056915283203\n",
      "step 19 from 157 at epoch 5\n",
      "Loss: 2.029737949371338\n",
      "step 29 from 157 at epoch 5\n",
      "Loss: 1.8002570867538452\n",
      "step 39 from 157 at epoch 5\n",
      "Loss: 2.5021724700927734\n",
      "step 49 from 157 at epoch 5\n",
      "Loss: 1.633509874343872\n",
      "step 59 from 157 at epoch 5\n",
      "Loss: 1.9260293245315552\n",
      "step 69 from 157 at epoch 5\n",
      "Loss: 1.9083727598190308\n",
      "step 79 from 157 at epoch 5\n",
      "Loss: 1.6927754878997803\n",
      "step 89 from 157 at epoch 5\n",
      "Loss: 1.8655521869659424\n",
      "step 99 from 157 at epoch 5\n",
      "Loss: 2.2612805366516113\n",
      "step 109 from 157 at epoch 5\n",
      "Loss: 1.9693890810012817\n",
      "step 119 from 157 at epoch 5\n",
      "Loss: 1.8090434074401855\n",
      "step 129 from 157 at epoch 5\n",
      "Loss: 1.3082668781280518\n",
      "step 139 from 157 at epoch 5\n",
      "Loss: 1.9304155111312866\n",
      "step 149 from 157 at epoch 5\n",
      "Loss: 1.7355296611785889\n",
      "epoch loss 2.4561241157829303\n",
      "epoch 6\n",
      "step 9 from 157 at epoch 6\n",
      "Loss: 1.7767689228057861\n",
      "step 19 from 157 at epoch 6\n",
      "Loss: 1.8707975149154663\n",
      "step 29 from 157 at epoch 6\n",
      "Loss: 3.5322184562683105\n",
      "step 39 from 157 at epoch 6\n",
      "Loss: 1.8054091930389404\n",
      "step 49 from 157 at epoch 6\n",
      "Loss: 2.002819776535034\n",
      "step 59 from 157 at epoch 6\n",
      "Loss: 1.488762617111206\n",
      "step 69 from 157 at epoch 6\n",
      "Loss: 2.599529266357422\n",
      "step 79 from 157 at epoch 6\n",
      "Loss: 2.8418049812316895\n",
      "step 89 from 157 at epoch 6\n",
      "Loss: 1.695270299911499\n",
      "step 99 from 157 at epoch 6\n",
      "Loss: 1.8121306896209717\n",
      "step 109 from 157 at epoch 6\n",
      "Loss: 1.4415686130523682\n",
      "step 119 from 157 at epoch 6\n",
      "Loss: 2.29301118850708\n",
      "step 129 from 157 at epoch 6\n",
      "Loss: 1.2977676391601562\n",
      "step 139 from 157 at epoch 6\n",
      "Loss: 2.1693058013916016\n",
      "step 149 from 157 at epoch 6\n",
      "Loss: 2.196573495864868\n",
      "epoch loss 2.447681836764831\n",
      "epoch 7\n",
      "step 9 from 157 at epoch 7\n",
      "Loss: 1.5703296661376953\n",
      "step 19 from 157 at epoch 7\n",
      "Loss: 2.094407320022583\n",
      "step 29 from 157 at epoch 7\n",
      "Loss: 2.3190484046936035\n",
      "step 39 from 157 at epoch 7\n",
      "Loss: 1.7520077228546143\n",
      "step 49 from 157 at epoch 7\n",
      "Loss: 1.364312767982483\n",
      "step 59 from 157 at epoch 7\n",
      "Loss: 1.5314364433288574\n",
      "step 69 from 157 at epoch 7\n",
      "Loss: 1.1419881582260132\n",
      "step 79 from 157 at epoch 7\n",
      "Loss: 2.0780510902404785\n",
      "step 89 from 157 at epoch 7\n",
      "Loss: 1.8540663719177246\n",
      "step 99 from 157 at epoch 7\n",
      "Loss: 1.572352647781372\n",
      "step 109 from 157 at epoch 7\n",
      "Loss: 1.3070812225341797\n",
      "step 119 from 157 at epoch 7\n",
      "Loss: 1.5204921960830688\n",
      "step 129 from 157 at epoch 7\n",
      "Loss: 1.637451171875\n",
      "step 139 from 157 at epoch 7\n",
      "Loss: 2.094846248626709\n",
      "step 149 from 157 at epoch 7\n",
      "Loss: 1.652311086654663\n",
      "epoch loss 1.7569479064258469\n",
      "epoch 8\n",
      "step 9 from 157 at epoch 8\n",
      "Loss: 2.3399689197540283\n",
      "step 19 from 157 at epoch 8\n",
      "Loss: 1.9930846691131592\n",
      "step 29 from 157 at epoch 8\n",
      "Loss: 1.7315564155578613\n",
      "step 39 from 157 at epoch 8\n",
      "Loss: 1.61759614944458\n",
      "step 49 from 157 at epoch 8\n",
      "Loss: 1.1532604694366455\n",
      "step 59 from 157 at epoch 8\n",
      "Loss: 1.3847743272781372\n",
      "step 69 from 157 at epoch 8\n",
      "Loss: 1.2380180358886719\n",
      "step 79 from 157 at epoch 8\n",
      "Loss: 1.469211220741272\n",
      "step 89 from 157 at epoch 8\n",
      "Loss: 1.2834839820861816\n",
      "step 99 from 157 at epoch 8\n",
      "Loss: 1.4553894996643066\n",
      "step 109 from 157 at epoch 8\n",
      "Loss: 1.3045554161071777\n",
      "step 119 from 157 at epoch 8\n",
      "Loss: 1.7290711402893066\n",
      "step 129 from 157 at epoch 8\n",
      "Loss: 1.940861701965332\n",
      "step 139 from 157 at epoch 8\n",
      "Loss: 1.8097299337387085\n",
      "step 149 from 157 at epoch 8\n",
      "Loss: 1.4327445030212402\n",
      "epoch loss 2.649647182210937\n",
      "epoch 9\n",
      "step 9 from 157 at epoch 9\n",
      "Loss: 1.379441499710083\n",
      "step 19 from 157 at epoch 9\n",
      "Loss: 1.700204610824585\n",
      "step 29 from 157 at epoch 9\n",
      "Loss: 1.5624170303344727\n",
      "step 39 from 157 at epoch 9\n",
      "Loss: 1.7657053470611572\n",
      "step 49 from 157 at epoch 9\n",
      "Loss: 1.2996516227722168\n",
      "step 59 from 157 at epoch 9\n",
      "Loss: 1.2684311866760254\n",
      "step 69 from 157 at epoch 9\n",
      "Loss: 0.9896739721298218\n",
      "step 79 from 157 at epoch 9\n",
      "Loss: 1.4523683786392212\n",
      "step 89 from 157 at epoch 9\n",
      "Loss: 1.5890388488769531\n",
      "step 99 from 157 at epoch 9\n",
      "Loss: 1.9499938488006592\n",
      "step 109 from 157 at epoch 9\n",
      "Loss: 1.767634630203247\n",
      "step 119 from 157 at epoch 9\n",
      "Loss: 1.2753006219863892\n",
      "step 129 from 157 at epoch 9\n",
      "Loss: 1.1081156730651855\n",
      "step 139 from 157 at epoch 9\n",
      "Loss: 1.7566499710083008\n",
      "step 149 from 157 at epoch 9\n",
      "Loss: 1.4303549528121948\n",
      "epoch loss 1.7997703238216507\n",
      "epoch 10\n",
      "step 9 from 157 at epoch 10\n",
      "Loss: 1.4528944492340088\n",
      "step 19 from 157 at epoch 10\n",
      "Loss: 1.549288034439087\n",
      "step 29 from 157 at epoch 10\n",
      "Loss: 1.1374621391296387\n",
      "step 39 from 157 at epoch 10\n",
      "Loss: 1.960174798965454\n",
      "step 49 from 157 at epoch 10\n",
      "Loss: 1.0241223573684692\n",
      "step 59 from 157 at epoch 10\n",
      "Loss: 1.3548983335494995\n",
      "step 69 from 157 at epoch 10\n",
      "Loss: 1.1743632555007935\n",
      "step 79 from 157 at epoch 10\n",
      "Loss: 1.467321753501892\n",
      "step 89 from 157 at epoch 10\n",
      "Loss: 1.277414083480835\n",
      "step 99 from 157 at epoch 10\n",
      "Loss: 1.456843614578247\n",
      "step 109 from 157 at epoch 10\n",
      "Loss: 1.5333260297775269\n",
      "step 119 from 157 at epoch 10\n",
      "Loss: 1.161139726638794\n",
      "step 129 from 157 at epoch 10\n",
      "Loss: 1.3197848796844482\n",
      "step 139 from 157 at epoch 10\n",
      "Loss: 1.5919185876846313\n",
      "step 149 from 157 at epoch 10\n",
      "Loss: 1.387941598892212\n",
      "epoch loss 1.7974788234057024\n",
      "epoch 11\n",
      "step 9 from 157 at epoch 11\n",
      "Loss: 1.4243671894073486\n",
      "step 19 from 157 at epoch 11\n",
      "Loss: 1.6805812120437622\n",
      "step 29 from 157 at epoch 11\n",
      "Loss: 1.0546462535858154\n",
      "step 39 from 157 at epoch 11\n",
      "Loss: 1.5444424152374268\n",
      "step 49 from 157 at epoch 11\n",
      "Loss: 1.0352673530578613\n",
      "step 59 from 157 at epoch 11\n",
      "Loss: 1.2855546474456787\n",
      "step 69 from 157 at epoch 11\n",
      "Loss: 1.203843355178833\n",
      "step 79 from 157 at epoch 11\n",
      "Loss: 1.7379472255706787\n",
      "step 89 from 157 at epoch 11\n",
      "Loss: 1.352760910987854\n",
      "step 99 from 157 at epoch 11\n",
      "Loss: 1.3582837581634521\n",
      "step 109 from 157 at epoch 11\n",
      "Loss: 1.2358229160308838\n",
      "step 119 from 157 at epoch 11\n",
      "Loss: 1.2458436489105225\n",
      "step 129 from 157 at epoch 11\n",
      "Loss: 1.5887374877929688\n",
      "step 139 from 157 at epoch 11\n",
      "Loss: 1.636960506439209\n",
      "step 149 from 157 at epoch 11\n",
      "Loss: 1.4014220237731934\n",
      "epoch loss 1.8892130970650012\n",
      "epoch 12\n",
      "step 9 from 157 at epoch 12\n",
      "Loss: 1.600721001625061\n",
      "step 19 from 157 at epoch 12\n",
      "Loss: 1.5478062629699707\n",
      "step 29 from 157 at epoch 12\n",
      "Loss: 1.1989518404006958\n",
      "step 39 from 157 at epoch 12\n",
      "Loss: 1.7088711261749268\n",
      "step 49 from 157 at epoch 12\n",
      "Loss: 1.0622460842132568\n",
      "step 59 from 157 at epoch 12\n",
      "Loss: 1.5971601009368896\n",
      "step 69 from 157 at epoch 12\n",
      "Loss: 1.1552823781967163\n",
      "step 79 from 157 at epoch 12\n",
      "Loss: 1.2624915838241577\n",
      "step 89 from 157 at epoch 12\n",
      "Loss: 1.3255243301391602\n",
      "step 99 from 157 at epoch 12\n",
      "Loss: 1.3718011379241943\n",
      "step 109 from 157 at epoch 12\n",
      "Loss: 1.4305393695831299\n",
      "step 119 from 157 at epoch 12\n",
      "Loss: 1.0564420223236084\n",
      "step 129 from 157 at epoch 12\n",
      "Loss: 0.9792534708976746\n",
      "step 139 from 157 at epoch 12\n",
      "Loss: 1.5651884078979492\n",
      "step 149 from 157 at epoch 12\n",
      "Loss: 1.446045160293579\n",
      "epoch loss 1.3042603042119605\n",
      "epoch 13\n",
      "step 9 from 157 at epoch 13\n",
      "Loss: 1.5228869915008545\n",
      "step 19 from 157 at epoch 13\n",
      "Loss: 1.611696481704712\n",
      "step 29 from 157 at epoch 13\n",
      "Loss: 1.1341795921325684\n",
      "step 39 from 157 at epoch 13\n",
      "Loss: 1.3890419006347656\n",
      "step 49 from 157 at epoch 13\n",
      "Loss: 1.3300111293792725\n",
      "step 59 from 157 at epoch 13\n",
      "Loss: 1.245621919631958\n",
      "step 69 from 157 at epoch 13\n",
      "Loss: 1.0365893840789795\n",
      "step 79 from 157 at epoch 13\n",
      "Loss: 1.2834745645523071\n",
      "step 89 from 157 at epoch 13\n",
      "Loss: 1.3716938495635986\n",
      "step 99 from 157 at epoch 13\n",
      "Loss: 1.3267227411270142\n",
      "step 109 from 157 at epoch 13\n",
      "Loss: 1.2867074012756348\n",
      "step 119 from 157 at epoch 13\n",
      "Loss: 1.176646113395691\n",
      "step 129 from 157 at epoch 13\n",
      "Loss: 1.1745606660842896\n",
      "step 139 from 157 at epoch 13\n",
      "Loss: 1.5443718433380127\n",
      "step 149 from 157 at epoch 13\n",
      "Loss: 1.5254014730453491\n",
      "epoch loss 1.2104779690732737\n",
      "epoch 14\n",
      "step 9 from 157 at epoch 14\n",
      "Loss: 1.6169521808624268\n",
      "step 19 from 157 at epoch 14\n",
      "Loss: 1.5256037712097168\n",
      "step 29 from 157 at epoch 14\n",
      "Loss: 1.2662675380706787\n",
      "step 39 from 157 at epoch 14\n",
      "Loss: 1.347876787185669\n",
      "step 49 from 157 at epoch 14\n",
      "Loss: 1.0092105865478516\n",
      "step 59 from 157 at epoch 14\n",
      "Loss: 1.467205286026001\n",
      "step 69 from 157 at epoch 14\n",
      "Loss: 0.9500939846038818\n",
      "step 79 from 157 at epoch 14\n",
      "Loss: 1.3354055881500244\n",
      "step 89 from 157 at epoch 14\n",
      "Loss: 1.2533166408538818\n",
      "step 99 from 157 at epoch 14\n",
      "Loss: 1.3127753734588623\n",
      "step 109 from 157 at epoch 14\n",
      "Loss: 1.3034946918487549\n",
      "step 119 from 157 at epoch 14\n",
      "Loss: 1.3719966411590576\n",
      "step 129 from 157 at epoch 14\n",
      "Loss: 2.013652801513672\n",
      "step 139 from 157 at epoch 14\n",
      "Loss: 1.8731589317321777\n",
      "step 149 from 157 at epoch 14\n",
      "Loss: 1.4291666746139526\n",
      "epoch loss 1.9509849743465024\n",
      "epoch 15\n",
      "step 9 from 157 at epoch 15\n",
      "Loss: 1.5915896892547607\n",
      "step 19 from 157 at epoch 15\n",
      "Loss: 1.514541745185852\n",
      "step 29 from 157 at epoch 15\n",
      "Loss: 1.0996918678283691\n",
      "step 39 from 157 at epoch 15\n",
      "Loss: 1.3603606224060059\n",
      "step 49 from 157 at epoch 15\n",
      "Loss: 1.0538783073425293\n",
      "step 59 from 157 at epoch 15\n",
      "Loss: 1.2126970291137695\n",
      "step 69 from 157 at epoch 15\n",
      "Loss: 1.1207664012908936\n",
      "step 79 from 157 at epoch 15\n",
      "Loss: 1.3142527341842651\n",
      "step 89 from 157 at epoch 15\n",
      "Loss: 1.1654971837997437\n",
      "step 99 from 157 at epoch 15\n",
      "Loss: 1.2482019662857056\n",
      "step 109 from 157 at epoch 15\n",
      "Loss: 1.2336981296539307\n",
      "step 119 from 157 at epoch 15\n",
      "Loss: 1.0543951988220215\n",
      "step 129 from 157 at epoch 15\n",
      "Loss: 1.0323737859725952\n",
      "step 139 from 157 at epoch 15\n",
      "Loss: 1.454481840133667\n",
      "step 149 from 157 at epoch 15\n",
      "Loss: 1.3911848068237305\n",
      "epoch loss 1.5024707472842673\n",
      "epoch 16\n",
      "step 9 from 157 at epoch 16\n",
      "Loss: 1.9006937742233276\n",
      "step 19 from 157 at epoch 16\n",
      "Loss: 1.9415779113769531\n",
      "step 29 from 157 at epoch 16\n",
      "Loss: 1.9202830791473389\n",
      "step 39 from 157 at epoch 16\n",
      "Loss: 1.7804338932037354\n",
      "step 49 from 157 at epoch 16\n",
      "Loss: 1.0388318300247192\n",
      "step 59 from 157 at epoch 16\n",
      "Loss: 1.7256011962890625\n",
      "step 69 from 157 at epoch 16\n",
      "Loss: 1.171454668045044\n",
      "step 79 from 157 at epoch 16\n",
      "Loss: 1.4350066184997559\n",
      "step 89 from 157 at epoch 16\n",
      "Loss: 1.4204144477844238\n",
      "step 99 from 157 at epoch 16\n",
      "Loss: 1.249977469444275\n",
      "step 109 from 157 at epoch 16\n",
      "Loss: 1.2645924091339111\n",
      "step 119 from 157 at epoch 16\n",
      "Loss: 1.014439582824707\n",
      "step 129 from 157 at epoch 16\n",
      "Loss: 1.1142804622650146\n",
      "step 139 from 157 at epoch 16\n",
      "Loss: 1.540111780166626\n",
      "step 149 from 157 at epoch 16\n",
      "Loss: 1.411606788635254\n",
      "epoch loss 1.7653508643664972\n",
      "epoch 17\n",
      "step 9 from 157 at epoch 17\n",
      "Loss: 1.3903040885925293\n",
      "step 19 from 157 at epoch 17\n",
      "Loss: 1.7551878690719604\n",
      "step 29 from 157 at epoch 17\n",
      "Loss: 1.6676583290100098\n",
      "step 39 from 157 at epoch 17\n",
      "Loss: 1.4859545230865479\n",
      "step 49 from 157 at epoch 17\n",
      "Loss: 1.448776125907898\n",
      "step 59 from 157 at epoch 17\n",
      "Loss: 1.292581558227539\n",
      "step 69 from 157 at epoch 17\n",
      "Loss: 1.0082236528396606\n",
      "step 79 from 157 at epoch 17\n",
      "Loss: 1.288894772529602\n",
      "step 89 from 157 at epoch 17\n",
      "Loss: 1.2282428741455078\n",
      "step 99 from 157 at epoch 17\n",
      "Loss: 1.3707942962646484\n",
      "step 109 from 157 at epoch 17\n",
      "Loss: 1.1816065311431885\n",
      "step 119 from 157 at epoch 17\n",
      "Loss: 1.3365123271942139\n",
      "step 129 from 157 at epoch 17\n",
      "Loss: 1.004758358001709\n",
      "step 139 from 157 at epoch 17\n",
      "Loss: 1.4227079153060913\n",
      "step 149 from 157 at epoch 17\n",
      "Loss: 1.3831416368484497\n",
      "epoch loss 1.9169697048109207\n",
      "epoch 18\n",
      "step 9 from 157 at epoch 18\n",
      "Loss: 1.3462281227111816\n",
      "step 19 from 157 at epoch 18\n",
      "Loss: 1.7238047122955322\n",
      "step 29 from 157 at epoch 18\n",
      "Loss: 1.4118428230285645\n",
      "step 39 from 157 at epoch 18\n",
      "Loss: 1.692518949508667\n",
      "step 49 from 157 at epoch 18\n",
      "Loss: 0.9134010076522827\n",
      "step 59 from 157 at epoch 18\n",
      "Loss: 1.1725201606750488\n",
      "step 69 from 157 at epoch 18\n",
      "Loss: 1.0121952295303345\n",
      "step 79 from 157 at epoch 18\n",
      "Loss: 1.278533935546875\n",
      "step 89 from 157 at epoch 18\n",
      "Loss: 1.2512075901031494\n",
      "step 99 from 157 at epoch 18\n",
      "Loss: 1.288835048675537\n",
      "step 109 from 157 at epoch 18\n",
      "Loss: 1.165216088294983\n",
      "step 119 from 157 at epoch 18\n",
      "Loss: 1.5030848979949951\n",
      "step 129 from 157 at epoch 18\n",
      "Loss: 1.05054771900177\n",
      "step 139 from 157 at epoch 18\n",
      "Loss: 1.5825004577636719\n",
      "step 149 from 157 at epoch 18\n",
      "Loss: 1.400390625\n",
      "epoch loss 2.5897049044099307\n",
      "epoch 19\n",
      "step 9 from 157 at epoch 19\n",
      "Loss: 1.7032082080841064\n",
      "step 19 from 157 at epoch 19\n",
      "Loss: 1.5663270950317383\n",
      "step 29 from 157 at epoch 19\n",
      "Loss: 1.1934196949005127\n",
      "step 39 from 157 at epoch 19\n",
      "Loss: 1.632078766822815\n",
      "step 49 from 157 at epoch 19\n",
      "Loss: 0.9140807390213013\n",
      "step 59 from 157 at epoch 19\n",
      "Loss: 1.4141719341278076\n",
      "step 69 from 157 at epoch 19\n",
      "Loss: 1.0727291107177734\n",
      "step 79 from 157 at epoch 19\n",
      "Loss: 1.3068760633468628\n",
      "step 89 from 157 at epoch 19\n",
      "Loss: 1.280123233795166\n",
      "step 99 from 157 at epoch 19\n",
      "Loss: 1.3956172466278076\n",
      "step 109 from 157 at epoch 19\n",
      "Loss: 1.113784909248352\n",
      "step 119 from 157 at epoch 19\n",
      "Loss: 1.1864142417907715\n",
      "step 129 from 157 at epoch 19\n",
      "Loss: 0.9767276048660278\n",
      "step 139 from 157 at epoch 19\n",
      "Loss: 1.5017964839935303\n",
      "step 149 from 157 at epoch 19\n",
      "Loss: 1.3846880197525024\n",
      "epoch loss 1.8186872941453744\n",
      "epoch 20\n",
      "step 9 from 157 at epoch 20\n",
      "Loss: 1.470586895942688\n",
      "step 19 from 157 at epoch 20\n",
      "Loss: 1.6366279125213623\n",
      "step 29 from 157 at epoch 20\n",
      "Loss: 1.1593918800354004\n",
      "step 39 from 157 at epoch 20\n",
      "Loss: 1.4546542167663574\n",
      "step 49 from 157 at epoch 20\n",
      "Loss: 0.9686834812164307\n",
      "step 59 from 157 at epoch 20\n",
      "Loss: 1.3456546068191528\n",
      "step 69 from 157 at epoch 20\n",
      "Loss: 0.9901770353317261\n",
      "step 79 from 157 at epoch 20\n",
      "Loss: 1.4001173973083496\n",
      "step 89 from 157 at epoch 20\n",
      "Loss: 1.2733169794082642\n",
      "step 99 from 157 at epoch 20\n",
      "Loss: 1.3076457977294922\n",
      "step 109 from 157 at epoch 20\n",
      "Loss: 1.1111016273498535\n",
      "step 119 from 157 at epoch 20\n",
      "Loss: 1.0574672222137451\n",
      "step 129 from 157 at epoch 20\n",
      "Loss: 0.9757171273231506\n",
      "step 139 from 157 at epoch 20\n",
      "Loss: 1.4203848838806152\n",
      "step 149 from 157 at epoch 20\n",
      "Loss: 1.353967547416687\n",
      "epoch loss 2.643588414277567\n",
      "epoch 21\n",
      "step 9 from 157 at epoch 21\n",
      "Loss: 1.6212184429168701\n",
      "step 19 from 157 at epoch 21\n",
      "Loss: 1.4875483512878418\n",
      "step 29 from 157 at epoch 21\n",
      "Loss: 1.151039719581604\n",
      "step 39 from 157 at epoch 21\n",
      "Loss: 1.3905341625213623\n",
      "step 49 from 157 at epoch 21\n",
      "Loss: 0.8851523399353027\n",
      "step 59 from 157 at epoch 21\n",
      "Loss: 1.2461984157562256\n",
      "step 69 from 157 at epoch 21\n",
      "Loss: 0.9898155927658081\n",
      "step 79 from 157 at epoch 21\n",
      "Loss: 1.2937498092651367\n",
      "step 89 from 157 at epoch 21\n",
      "Loss: 1.261244297027588\n",
      "step 99 from 157 at epoch 21\n",
      "Loss: 1.4088010787963867\n",
      "step 109 from 157 at epoch 21\n",
      "Loss: 1.0530755519866943\n",
      "step 119 from 157 at epoch 21\n",
      "Loss: 1.1024996042251587\n",
      "step 129 from 157 at epoch 21\n",
      "Loss: 0.9833413362503052\n",
      "step 139 from 157 at epoch 21\n",
      "Loss: 1.4186557531356812\n",
      "step 149 from 157 at epoch 21\n",
      "Loss: 1.3419718742370605\n",
      "epoch loss 2.270179600666856\n",
      "epoch 22\n",
      "step 9 from 157 at epoch 22\n",
      "Loss: 1.4662493467330933\n",
      "step 19 from 157 at epoch 22\n",
      "Loss: 1.5313441753387451\n",
      "step 29 from 157 at epoch 22\n",
      "Loss: 1.133658766746521\n",
      "step 39 from 157 at epoch 22\n",
      "Loss: 1.3118972778320312\n",
      "step 49 from 157 at epoch 22\n",
      "Loss: 0.9056428670883179\n",
      "step 59 from 157 at epoch 22\n",
      "Loss: 1.3072264194488525\n",
      "step 69 from 157 at epoch 22\n",
      "Loss: 0.9592368602752686\n",
      "step 79 from 157 at epoch 22\n",
      "Loss: 1.3847861289978027\n",
      "step 89 from 157 at epoch 22\n",
      "Loss: 1.2792471647262573\n",
      "step 99 from 157 at epoch 22\n",
      "Loss: 1.5362098217010498\n",
      "step 109 from 157 at epoch 22\n",
      "Loss: 1.0723912715911865\n",
      "step 119 from 157 at epoch 22\n",
      "Loss: 1.1637797355651855\n",
      "step 129 from 157 at epoch 22\n",
      "Loss: 0.9945275783538818\n",
      "step 139 from 157 at epoch 22\n",
      "Loss: 1.423224687576294\n",
      "step 149 from 157 at epoch 22\n",
      "Loss: 1.3451696634292603\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "epochs = 50\n",
    "print(timestamp)\n",
    "#print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    print(f'epoch {i}')\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914e0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
