{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d618c1-7bd7-4b54-b5c6-cd8fab531f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reshape(tensor):\n",
    "    return torch.reshape(tensor, (tensor.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d80a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(system):\n",
    "    #spherical_radii = torch.Tensor(system['spherical_domain_radii'])\n",
    "    #spherical_radii = my_reshape(spherical_radii)\n",
    "    \n",
    "#     tags = system['tags'].long().to(device)\n",
    "#     tags = F.one_hot(tags, num_classes=3)\n",
    "    \n",
    "    atom_numbers = system['atomic_numbers'].long().to(device)\n",
    "    atom_numbers = F.one_hot(atom_numbers, num_classes=100).float()\n",
    "    \n",
    "#     voronoi_volumes = system['voronoi_volumes'].float().to(device)\n",
    "#     voronoi_volumes = my_reshape(voronoi_volumes)\n",
    "    \n",
    "    atom_features = (atom_numbers,) #tags, voronoi_volumes)#, spherical_radii)\n",
    "    atom_embeds = torch.cat(atom_features, 1)\n",
    "    \n",
    "    edge_index = system['edge_index'].long().to(device)\n",
    "    \n",
    "    distances = system['distances'].float().to(device)\n",
    "    distances = my_reshape(distances)\n",
    "    \n",
    "#     angles = system['contact_solid_angles'].float().to(device)\n",
    "#     angles = my_reshape(angles)\n",
    "    \n",
    "    edge_features = (distances,)# angles)\n",
    "    \n",
    "    edges_embeds = torch.cat(edge_features, 1)\n",
    "    \n",
    "    \n",
    "    return Data(x=atom_embeds.to(device), edge_index=edge_index.to(device), edge_attr=edges_embeds.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f277f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmearing(nn.Module):\n",
    "    def __init__(self, start=0.0, stop=8.0, num_gaussians=150):\n",
    "        super(GaussianSmearing, self).__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b069c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedSoftplus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShiftedSoftplus, self).__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softplus(x) - self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc9d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFconv(MessagePassing):\n",
    "    def __init__(self, dim_hidden, dim_edge):   #dim_edge можно и не передавать\n",
    "        super(CFconv, self).__init__(aggr='add')\n",
    "        self.rbf = GaussianSmearing(num_gaussians=smearing['rbf'])\n",
    "        #self.sa_bins = GaussianSmearing(start=0.0, stop=50.0, num_gaussians=smearing['sa_bins']) #кладём телесные углы в бины\n",
    "        self.blocks = nn.Sequential(nn.Linear(smearing['rbf']+smearing['sa_bins'], dim_hidden, bias=True),\n",
    "                                   ShiftedSoftplus(),\n",
    "                                   nn.Linear(dim_hidden, dim_hidden, bias=True),\n",
    "                                   ShiftedSoftplus())\n",
    "        self.lin_phi = torch.nn.Linear(dim_hidden, dim_hidden, bias=False)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.blocks[0].weight)\n",
    "        self.blocks[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.blocks[2].weight)\n",
    "        self.blocks[0].bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['x']\n",
    "        edge_index = batch['edge_index']\n",
    "        rbf_dist = self.rbf(batch['edge_attr'][:, 0])\n",
    "        #bins_angles = self.sa_bins(batch['edge_attr'][:, 1])\n",
    "        #edge_attr = torch.cat((rbf_dist, bins_angles), 1)\n",
    "        edge_attr = rbf_dist\n",
    "        edge_attr = self.blocks(edge_attr)\n",
    "        \n",
    "    \n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "\n",
    "    def message(self, x, x_i, x_j, edge_attr):\n",
    "        new_edges = self.lin_phi(edge_attr)\n",
    "        hd_product = x_j * new_edges\n",
    "        return hd_product\n",
    "        \n",
    "    def update(self, aggr_out):\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da342621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_hidden, dim_edge):\n",
    "        super().__init__()\n",
    "        self.atom_wise_64_1 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        self.cfconv = CFconv(dim_hidden, dim_edge)\n",
    "        self.atom_wise_64_2 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        self.shifted_softplus = ShiftedSoftplus()\n",
    "        self.atom_wise_64_3 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise_64_1.weight)\n",
    "        self.atom_wise_64_1.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise_64_2.weight)\n",
    "        self.atom_wise_64_2.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise_64_3.weight)\n",
    "        self.atom_wise_64_3.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x_input = batch['x'].clone().detach()\n",
    "        batch['x'] = self.atom_wise_64_1(batch['x'])\n",
    "        conved = self.cfconv(batch)\n",
    "        conved = self.atom_wise_64_2(conved)\n",
    "        ssp = self.shifted_softplus(conved)\n",
    "        v = self.atom_wise_64_3(ssp)\n",
    "        \n",
    "        return x_input + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e1232c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_atom=103, dim_edge=2, dim_hidden=64, num_int=3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(dim_atom, dim_hidden)\n",
    "        \n",
    "        int_blocks = []\n",
    "        for i in range(num_int):\n",
    "            int_blocks.append(Interaction(dim_hidden, dim_edge))\n",
    "        self.interactions = nn.Sequential(*int_blocks)\n",
    "        self.shifted_softplus = ShiftedSoftplus()\n",
    "        self.atom_wise_32 = nn.Linear(dim_hidden, 32, bias=True)\n",
    "        self.atom_wise_1 = nn.Linear(32, 1, bias=True)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise_32.weight)\n",
    "        self.atom_wise_32.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.atom_wise_1.weight)\n",
    "        self.atom_wise_1.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch['x'] = self.embedding(batch['x'])\n",
    "        batch = self.interactions(batch)\n",
    "        x_32 = self.atom_wise_32(batch['x'])\n",
    "        x_32 = self.shifted_softplus(x_32)\n",
    "        energies = self.atom_wise_1(x_32)\n",
    "        energy = scatter(energies, batch['batch'], dim=0, reduce='sum')\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1316697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 50\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['atomic_numbers', 'edge_index_new', 'distances_new', \n",
    "                 'contact_solid_angles', 'tags', 'voronoi_volumes', 'spherical_domain_radii'] #бесполезный массив\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "smearing = {'rbf' : 300, 'sa_bins' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3099636a-c3a8-4bf5-86f8-4983eba165c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы тензор по умолчанию заводился на куде\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2b308d-ffa4-4f48-adab-e218d7da0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf8ed5d-ba8c-44e7-a343-1e7092ffca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data_mod.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = DataLoader(training_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae852e60-b1ac-4a48-8120-af94ecec6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data_mod.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f64a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: 0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90ad46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2964, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][0]['edge_attr'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = ConvNN(dim_atom=training_set[0][0]['x'].shape[1], dim_edge=training_set[0][0]['edge_attr'].shape[1])\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc1c0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15-16-41-23\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e477b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 2.6 s, total: 14.2 s\n",
      "Wall time: 8.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"smearing\" : smearing\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "writer.add_graph(model, trace_system)\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15-16-41-23\n",
      "Start training model ConvNN(\n",
      "  (embedding): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (interaction1): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (interaction2): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (interaction3): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (shifted_softplus): ShiftedSoftplus()\n",
      "  (atom_wise_32): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (atom_wise_1): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0\n",
      "step 9 from 200 at epoch 0\n",
      "Loss: 3.106992483139038\n",
      "step 19 from 200 at epoch 0\n",
      "Loss: 2.0793673992156982\n",
      "step 29 from 200 at epoch 0\n",
      "Loss: 2.212209939956665\n",
      "step 39 from 200 at epoch 0\n",
      "Loss: 2.2461631298065186\n",
      "step 49 from 200 at epoch 0\n",
      "Loss: 2.104442834854126\n",
      "step 59 from 200 at epoch 0\n",
      "Loss: 2.157639980316162\n",
      "step 69 from 200 at epoch 0\n",
      "Loss: 2.5933144092559814\n",
      "step 79 from 200 at epoch 0\n",
      "Loss: 1.678766131401062\n",
      "step 89 from 200 at epoch 0\n",
      "Loss: 1.793563723564148\n",
      "step 99 from 200 at epoch 0\n",
      "Loss: 2.0343053340911865\n",
      "step 109 from 200 at epoch 0\n",
      "Loss: 1.5760809183120728\n",
      "step 119 from 200 at epoch 0\n",
      "Loss: 1.7331857681274414\n",
      "step 129 from 200 at epoch 0\n",
      "Loss: 1.807824730873108\n",
      "step 139 from 200 at epoch 0\n",
      "Loss: 1.9356951713562012\n",
      "step 149 from 200 at epoch 0\n",
      "Loss: 1.531144618988037\n",
      "step 159 from 200 at epoch 0\n",
      "Loss: 2.1282176971435547\n",
      "step 169 from 200 at epoch 0\n",
      "Loss: 1.5823276042938232\n",
      "step 179 from 200 at epoch 0\n",
      "Loss: 1.4925349950790405\n",
      "step 189 from 200 at epoch 0\n",
      "Loss: 1.5842907428741455\n",
      "step 199 from 200 at epoch 0\n",
      "Loss: 1.9297393560409546\n",
      "epoch 0 evaluation\n",
      "epoch loss 1.6123136858940124\n",
      "========================================================================================================\n",
      "epoch 1\n",
      "step 9 from 200 at epoch 1\n",
      "Loss: 1.8109718561172485\n",
      "step 19 from 200 at epoch 1\n",
      "Loss: 1.6407856941223145\n",
      "step 29 from 200 at epoch 1\n",
      "Loss: 1.448319673538208\n",
      "step 39 from 200 at epoch 1\n",
      "Loss: 1.4843754768371582\n",
      "step 49 from 200 at epoch 1\n",
      "Loss: 1.632493495941162\n",
      "step 59 from 200 at epoch 1\n",
      "Loss: 1.8188564777374268\n",
      "step 69 from 200 at epoch 1\n",
      "Loss: 2.0047707557678223\n",
      "step 79 from 200 at epoch 1\n",
      "Loss: 1.3243780136108398\n",
      "step 89 from 200 at epoch 1\n",
      "Loss: 1.2699910402297974\n",
      "step 99 from 200 at epoch 1\n",
      "Loss: 1.6078208684921265\n",
      "step 109 from 200 at epoch 1\n",
      "Loss: 1.098582148551941\n",
      "step 119 from 200 at epoch 1\n",
      "Loss: 1.1631535291671753\n",
      "step 129 from 200 at epoch 1\n",
      "Loss: 1.3312454223632812\n",
      "step 139 from 200 at epoch 1\n",
      "Loss: 1.5589349269866943\n",
      "step 149 from 200 at epoch 1\n",
      "Loss: 1.2457289695739746\n",
      "step 159 from 200 at epoch 1\n",
      "Loss: 1.5562800168991089\n",
      "step 169 from 200 at epoch 1\n",
      "Loss: 1.3737080097198486\n",
      "step 179 from 200 at epoch 1\n",
      "Loss: 1.1976323127746582\n",
      "step 189 from 200 at epoch 1\n",
      "Loss: 1.3535076379776\n",
      "step 199 from 200 at epoch 1\n",
      "Loss: 1.5449731349945068\n",
      "epoch 1 evaluation\n",
      "epoch loss 1.1764294403791427\n",
      "========================================================================================================\n",
      "epoch 2\n",
      "step 9 from 200 at epoch 2\n",
      "Loss: 1.2847955226898193\n",
      "step 19 from 200 at epoch 2\n",
      "Loss: 1.3852784633636475\n",
      "step 29 from 200 at epoch 2\n",
      "Loss: 0.9518733024597168\n",
      "step 39 from 200 at epoch 2\n",
      "Loss: 1.1910418272018433\n",
      "step 49 from 200 at epoch 2\n",
      "Loss: 1.2620776891708374\n",
      "step 59 from 200 at epoch 2\n",
      "Loss: 1.3043179512023926\n",
      "step 69 from 200 at epoch 2\n",
      "Loss: 1.3580862283706665\n",
      "step 79 from 200 at epoch 2\n",
      "Loss: 1.1206506490707397\n",
      "step 89 from 200 at epoch 2\n",
      "Loss: 1.3724884986877441\n",
      "step 99 from 200 at epoch 2\n",
      "Loss: 1.3572571277618408\n",
      "step 109 from 200 at epoch 2\n",
      "Loss: 0.8784565925598145\n",
      "step 119 from 200 at epoch 2\n",
      "Loss: 1.0360685586929321\n",
      "step 129 from 200 at epoch 2\n",
      "Loss: 1.1481256484985352\n",
      "step 139 from 200 at epoch 2\n",
      "Loss: 1.3492496013641357\n",
      "step 149 from 200 at epoch 2\n",
      "Loss: 1.168380618095398\n",
      "step 159 from 200 at epoch 2\n",
      "Loss: 1.4309136867523193\n",
      "step 169 from 200 at epoch 2\n",
      "Loss: 1.2060755491256714\n",
      "step 179 from 200 at epoch 2\n",
      "Loss: 1.1426657438278198\n",
      "step 189 from 200 at epoch 2\n",
      "Loss: 1.378092646598816\n",
      "step 199 from 200 at epoch 2\n",
      "Loss: 1.5245774984359741\n",
      "epoch 2 evaluation\n",
      "epoch loss 1.1235872223377228\n",
      "========================================================================================================\n",
      "epoch 3\n",
      "step 9 from 200 at epoch 3\n",
      "Loss: 1.2235854864120483\n",
      "step 19 from 200 at epoch 3\n",
      "Loss: 1.2385249137878418\n",
      "step 29 from 200 at epoch 3\n",
      "Loss: 0.9271645545959473\n",
      "step 39 from 200 at epoch 3\n",
      "Loss: 1.0659297704696655\n",
      "step 49 from 200 at epoch 3\n",
      "Loss: 1.2075581550598145\n",
      "step 59 from 200 at epoch 3\n",
      "Loss: 1.2004139423370361\n",
      "step 69 from 200 at epoch 3\n",
      "Loss: 1.436015009880066\n",
      "step 79 from 200 at epoch 3\n",
      "Loss: 1.0893962383270264\n",
      "step 89 from 200 at epoch 3\n",
      "Loss: 1.287509799003601\n",
      "step 99 from 200 at epoch 3\n",
      "Loss: 1.354140281677246\n",
      "step 109 from 200 at epoch 3\n",
      "Loss: 0.8306934833526611\n",
      "step 119 from 200 at epoch 3\n",
      "Loss: 0.9095370769500732\n",
      "step 129 from 200 at epoch 3\n",
      "Loss: 1.0769826173782349\n",
      "step 139 from 200 at epoch 3\n",
      "Loss: 1.312408447265625\n",
      "step 149 from 200 at epoch 3\n",
      "Loss: 1.088260293006897\n",
      "step 159 from 200 at epoch 3\n",
      "Loss: 1.4082084894180298\n",
      "step 169 from 200 at epoch 3\n",
      "Loss: 1.1669765710830688\n",
      "step 179 from 200 at epoch 3\n",
      "Loss: 1.0916508436203003\n",
      "step 189 from 200 at epoch 3\n",
      "Loss: 1.3745437860488892\n",
      "step 199 from 200 at epoch 3\n",
      "Loss: 1.4644536972045898\n",
      "epoch 3 evaluation\n",
      "epoch loss 1.1364797420501709\n",
      "========================================================================================================\n",
      "epoch 4\n",
      "step 9 from 200 at epoch 4\n",
      "Loss: 1.182047963142395\n",
      "step 19 from 200 at epoch 4\n",
      "Loss: 1.3599826097488403\n",
      "step 29 from 200 at epoch 4\n",
      "Loss: 0.8704996705055237\n",
      "step 39 from 200 at epoch 4\n",
      "Loss: 1.1435046195983887\n",
      "step 49 from 200 at epoch 4\n",
      "Loss: 1.214884638786316\n",
      "step 59 from 200 at epoch 4\n",
      "Loss: 1.1000210046768188\n",
      "step 69 from 200 at epoch 4\n",
      "Loss: 1.4486947059631348\n",
      "step 79 from 200 at epoch 4\n",
      "Loss: 1.0528641939163208\n",
      "step 89 from 200 at epoch 4\n",
      "Loss: 1.2614562511444092\n",
      "step 99 from 200 at epoch 4\n",
      "Loss: 1.369449496269226\n",
      "step 109 from 200 at epoch 4\n",
      "Loss: 0.8940429091453552\n",
      "step 119 from 200 at epoch 4\n",
      "Loss: 0.9778158068656921\n",
      "step 129 from 200 at epoch 4\n",
      "Loss: 1.061231255531311\n",
      "step 139 from 200 at epoch 4\n",
      "Loss: 1.3190289735794067\n",
      "step 149 from 200 at epoch 4\n",
      "Loss: 1.1882336139678955\n",
      "step 159 from 200 at epoch 4\n",
      "Loss: 1.4037845134735107\n",
      "step 169 from 200 at epoch 4\n",
      "Loss: 1.2260507345199585\n",
      "step 179 from 200 at epoch 4\n",
      "Loss: 1.1744595766067505\n",
      "step 189 from 200 at epoch 4\n",
      "Loss: 1.349476933479309\n",
      "step 199 from 200 at epoch 4\n",
      "Loss: 1.4460166692733765\n",
      "epoch 4 evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss 1.2012404930591583\n",
      "========================================================================================================\n",
      "epoch 5\n",
      "step 9 from 200 at epoch 5\n",
      "Loss: 1.1100280284881592\n",
      "step 19 from 200 at epoch 5\n",
      "Loss: 1.1877845525741577\n",
      "step 29 from 200 at epoch 5\n",
      "Loss: 1.0005531311035156\n",
      "step 39 from 200 at epoch 5\n",
      "Loss: 1.0828957557678223\n",
      "step 49 from 200 at epoch 5\n",
      "Loss: 1.175600528717041\n",
      "step 59 from 200 at epoch 5\n",
      "Loss: 1.1102113723754883\n",
      "step 69 from 200 at epoch 5\n",
      "Loss: 1.3149524927139282\n",
      "step 79 from 200 at epoch 5\n",
      "Loss: 1.0765595436096191\n",
      "step 89 from 200 at epoch 5\n",
      "Loss: 1.2583394050598145\n",
      "step 99 from 200 at epoch 5\n",
      "Loss: 1.313337802886963\n",
      "step 109 from 200 at epoch 5\n",
      "Loss: 0.9107667803764343\n",
      "step 119 from 200 at epoch 5\n",
      "Loss: 0.862470269203186\n",
      "step 129 from 200 at epoch 5\n",
      "Loss: 1.097718596458435\n",
      "step 139 from 200 at epoch 5\n",
      "Loss: 1.3699417114257812\n",
      "step 149 from 200 at epoch 5\n",
      "Loss: 1.0221527814865112\n",
      "step 159 from 200 at epoch 5\n",
      "Loss: 1.2767679691314697\n",
      "step 169 from 200 at epoch 5\n",
      "Loss: 1.1724004745483398\n",
      "step 179 from 200 at epoch 5\n",
      "Loss: 1.085688591003418\n",
      "step 189 from 200 at epoch 5\n",
      "Loss: 1.2301604747772217\n",
      "step 199 from 200 at epoch 5\n",
      "Loss: 1.4564296007156372\n",
      "epoch 5 evaluation\n",
      "epoch loss 1.1612242956161498\n",
      "========================================================================================================\n",
      "epoch 6\n",
      "step 9 from 200 at epoch 6\n",
      "Loss: 1.1659400463104248\n",
      "step 19 from 200 at epoch 6\n",
      "Loss: 1.1881320476531982\n",
      "step 29 from 200 at epoch 6\n",
      "Loss: 0.850878894329071\n",
      "step 39 from 200 at epoch 6\n",
      "Loss: 1.0571234226226807\n",
      "step 49 from 200 at epoch 6\n",
      "Loss: 1.17741060256958\n",
      "step 59 from 200 at epoch 6\n",
      "Loss: 1.0905684232711792\n",
      "step 69 from 200 at epoch 6\n",
      "Loss: 1.4573636054992676\n",
      "step 79 from 200 at epoch 6\n",
      "Loss: 0.8717250227928162\n",
      "step 89 from 200 at epoch 6\n",
      "Loss: 1.3217779397964478\n",
      "step 99 from 200 at epoch 6\n",
      "Loss: 1.3261120319366455\n",
      "step 109 from 200 at epoch 6\n",
      "Loss: 0.9234315752983093\n",
      "step 119 from 200 at epoch 6\n",
      "Loss: 0.9631507992744446\n",
      "step 129 from 200 at epoch 6\n",
      "Loss: 1.0218347311019897\n",
      "step 139 from 200 at epoch 6\n",
      "Loss: 1.2443383932113647\n",
      "step 149 from 200 at epoch 6\n",
      "Loss: 0.9967930316925049\n",
      "step 159 from 200 at epoch 6\n",
      "Loss: 1.2758762836456299\n",
      "step 169 from 200 at epoch 6\n",
      "Loss: 1.1471422910690308\n",
      "step 179 from 200 at epoch 6\n",
      "Loss: 1.1051552295684814\n",
      "step 189 from 200 at epoch 6\n",
      "Loss: 1.2792614698410034\n",
      "step 199 from 200 at epoch 6\n",
      "Loss: 1.374516248703003\n",
      "epoch 6 evaluation\n",
      "epoch loss 1.137194319963455\n",
      "========================================================================================================\n",
      "epoch 7\n",
      "step 9 from 200 at epoch 7\n",
      "Loss: 1.128151774406433\n",
      "step 19 from 200 at epoch 7\n",
      "Loss: 1.1875826120376587\n",
      "step 29 from 200 at epoch 7\n",
      "Loss: 0.7573958039283752\n",
      "step 39 from 200 at epoch 7\n",
      "Loss: 1.0904215574264526\n",
      "step 49 from 200 at epoch 7\n",
      "Loss: 1.2016582489013672\n",
      "step 59 from 200 at epoch 7\n",
      "Loss: 1.1499810218811035\n",
      "step 69 from 200 at epoch 7\n",
      "Loss: 1.3364847898483276\n",
      "step 79 from 200 at epoch 7\n",
      "Loss: 0.9342355132102966\n",
      "step 89 from 200 at epoch 7\n",
      "Loss: 1.1812800168991089\n",
      "step 99 from 200 at epoch 7\n",
      "Loss: 1.277026653289795\n",
      "step 109 from 200 at epoch 7\n",
      "Loss: 0.8484728932380676\n",
      "step 119 from 200 at epoch 7\n",
      "Loss: 0.936876654624939\n",
      "step 129 from 200 at epoch 7\n",
      "Loss: 1.0138633251190186\n",
      "step 139 from 200 at epoch 7\n",
      "Loss: 1.217091679573059\n",
      "step 149 from 200 at epoch 7\n",
      "Loss: 1.0591999292373657\n",
      "step 159 from 200 at epoch 7\n",
      "Loss: 1.3250792026519775\n",
      "step 169 from 200 at epoch 7\n",
      "Loss: 1.0518516302108765\n",
      "step 179 from 200 at epoch 7\n",
      "Loss: 1.0821623802185059\n",
      "step 189 from 200 at epoch 7\n",
      "Loss: 1.2866792678833008\n",
      "step 199 from 200 at epoch 7\n",
      "Loss: 1.4705097675323486\n",
      "epoch 7 evaluation\n",
      "epoch loss 1.2378885102272035\n",
      "========================================================================================================\n",
      "epoch 8\n",
      "step 9 from 200 at epoch 8\n",
      "Loss: 1.1013880968093872\n",
      "step 19 from 200 at epoch 8\n",
      "Loss: 1.1000490188598633\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca87be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models-env",
   "language": "python",
   "name": "ocp-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
