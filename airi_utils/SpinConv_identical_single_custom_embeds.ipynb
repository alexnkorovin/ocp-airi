{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddbd6cfb-9497-44ef-9021-6e071723c92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset, DataListLoader\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da48320d-740d-45a4-8461-7c7d48f9308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('../ocpmodels/models'))\n",
    "sys.path.append(os.path.expanduser('../../ocp_airi'))\n",
    "\n",
    "from spinconv_with_embeds_single import spinconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94d7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    keys = ['pos', 'atomic_numbers', 'cell', 'natoms']\n",
    "    features_dict = {}\n",
    "    for key in keys:\n",
    "        features_dict[key] = system[key]\n",
    "    return Data(**features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf0852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 30\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09825276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0184751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c69c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/all/train/data.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = DataListLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2803a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataListLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868049d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 460328\n",
      "info for item: 0\n",
      "edge_index:...............<class 'torch.Tensor'>..... [2, 2964]\n",
      "pos:......................<class 'torch.Tensor'>.....   [86, 3]\n",
      "cell:.....................<class 'torch.Tensor'>..... [1, 3, 3]\n",
      "atomic_numbers:...........<class 'torch.Tensor'>.....      [86]\n",
      "natoms:...................       <class 'int'>.....        86\n",
      "cell_offsets:.............<class 'torch.Tensor'>..... [2964, 3]\n",
      "force:....................<class 'torch.Tensor'>.....   [86, 3]\n",
      "distances:................<class 'torch.Tensor'>.....    [2964]\n",
      "fixed:....................<class 'torch.Tensor'>.....      [86]\n",
      "sid:......................       <class 'int'>.....   2472718\n",
      "tags:.....................<class 'torch.Tensor'>.....      [86]\n",
      "y_init:...................     <class 'float'>.....    6.2825\n",
      "y_relaxed:................     <class 'float'>.....   -0.0256\n",
      "pos_relaxed:..............<class 'torch.Tensor'>.....   [86, 3]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d789924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #model\n",
    "# model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, 0)\n",
    "# model = DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "# #optimizer and loss\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "# criterion = nn.L1Loss()\n",
    "\n",
    "# #переносим на куду если она есть\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae379cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05-14-31-17\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d4af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bda981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no graph\n",
      "CPU times: user 524 µs, sys: 107 µs, total: 631 µs\n",
      "Wall time: 443 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id'\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeeec25",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de590137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# loss = []\n",
    "# loss_eval = []\n",
    "\n",
    "# print(timestamp)\n",
    "# print(f'Start training model {str(model)}')\n",
    "# for i in range(epochs):\n",
    "#     loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "#     loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc01ae-3d65-4c85-a901-ba0155de0356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33])\n",
      "tensor([33])\n",
      "message tensor([33])\n",
      "tensor([33])\n",
      "tensor([33])\n",
      "tensor([33])\n",
      "tensor([33])\n",
      "tensor([33])\n",
      "tensor([33])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "2021-10-05-14-31-19\n",
      "no graph\n",
      "2021-10-05-14-31-19\n",
      "Start training model DataParallel(\n",
      "  (module): spinconv(\n",
      "    (act): Swish()\n",
      "    (distance_expansion_forces): GaussianSmearing()\n",
      "    (embeddingblock2): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dist_block): DistanceBlock(\n",
      "      (distance_expansion): GaussianSmearing()\n",
      "      (dist_scalar): Embedding(8100, 1)\n",
      "      (dist_offset): Embedding(8100, 1)\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (message_blocks): ModuleList(\n",
      "      (0): MessageBlock(\n",
      "        (act): Swish()\n",
      "        (spinconvblock): SpinConvBlock(\n",
      "          (act): Swish()\n",
      "          (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "          (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "          (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "          (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (embeddingblock1): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (embeddingblock2): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (energyembeddingblock): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=32, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (force_output_block): ForceOutputBlock(\n",
      "      (act): Swish()\n",
      "      (spinconvblock): SpinConvBlock(\n",
      "        (act): Swish()\n",
      "        (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "        (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "        (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "        (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (block1): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (block2): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch 0\n",
      "step 9 from 15345 at epoch 0\n",
      "Loss: 2.428978204727173\n",
      "step 19 from 15345 at epoch 0\n",
      "Loss: 2.078016519546509\n",
      "step 29 from 15345 at epoch 0\n",
      "Loss: 1.8403640985488892\n",
      "step 39 from 15345 at epoch 0\n",
      "Loss: 2.0798180103302\n",
      "step 49 from 15345 at epoch 0\n",
      "Loss: 1.6626611948013306\n",
      "step 59 from 15345 at epoch 0\n",
      "Loss: 1.634416937828064\n",
      "step 69 from 15345 at epoch 0\n",
      "Loss: 1.4805490970611572\n",
      "step 79 from 15345 at epoch 0\n",
      "Loss: 1.7850120067596436\n",
      "step 89 from 15345 at epoch 0\n",
      "Loss: 1.6046600341796875\n",
      "step 99 from 15345 at epoch 0\n",
      "Loss: 2.0370125770568848\n",
      "step 109 from 15345 at epoch 0\n",
      "Loss: 1.7763700485229492\n",
      "step 119 from 15345 at epoch 0\n",
      "Loss: 1.889818787574768\n",
      "step 129 from 15345 at epoch 0\n",
      "Loss: 1.6036571264266968\n",
      "step 139 from 15345 at epoch 0\n",
      "Loss: 1.5631929636001587\n",
      "step 149 from 15345 at epoch 0\n",
      "Loss: 1.3309532403945923\n",
      "step 159 from 15345 at epoch 0\n",
      "Loss: 1.4749895334243774\n",
      "step 169 from 15345 at epoch 0\n",
      "Loss: 1.8707304000854492\n",
      "step 179 from 15345 at epoch 0\n",
      "Loss: 1.644393801689148\n",
      "step 189 from 15345 at epoch 0\n",
      "Loss: 1.6307897567749023\n",
      "step 199 from 15345 at epoch 0\n",
      "Loss: 1.3163654804229736\n",
      "step 209 from 15345 at epoch 0\n",
      "Loss: 1.6553409099578857\n",
      "step 219 from 15345 at epoch 0\n",
      "Loss: 1.5643693208694458\n",
      "step 229 from 15345 at epoch 0\n",
      "Loss: 2.19917893409729\n",
      "step 239 from 15345 at epoch 0\n",
      "Loss: 1.4445180892944336\n",
      "step 249 from 15345 at epoch 0\n",
      "Loss: 1.5886822938919067\n",
      "step 259 from 15345 at epoch 0\n",
      "Loss: 1.489117980003357\n",
      "step 269 from 15345 at epoch 0\n",
      "Loss: 1.4099094867706299\n",
      "step 279 from 15345 at epoch 0\n",
      "Loss: 2.1014351844787598\n",
      "step 289 from 15345 at epoch 0\n",
      "Loss: 1.7287213802337646\n",
      "step 299 from 15345 at epoch 0\n",
      "Loss: 1.1001112461090088\n",
      "step 309 from 15345 at epoch 0\n",
      "Loss: 1.168993592262268\n",
      "step 319 from 15345 at epoch 0\n",
      "Loss: 1.087392807006836\n",
      "step 329 from 15345 at epoch 0\n",
      "Loss: 1.2782618999481201\n",
      "step 339 from 15345 at epoch 0\n",
      "Loss: 0.8898752331733704\n",
      "step 349 from 15345 at epoch 0\n",
      "Loss: 1.374110221862793\n",
      "step 359 from 15345 at epoch 0\n",
      "Loss: 1.4971339702606201\n",
      "step 369 from 15345 at epoch 0\n",
      "Loss: 1.5933387279510498\n",
      "step 379 from 15345 at epoch 0\n",
      "Loss: 1.1891252994537354\n",
      "step 389 from 15345 at epoch 0\n",
      "Loss: 1.1761740446090698\n",
      "step 399 from 15345 at epoch 0\n",
      "Loss: 1.5179424285888672\n",
      "step 409 from 15345 at epoch 0\n",
      "Loss: 1.0621740818023682\n",
      "step 419 from 15345 at epoch 0\n",
      "Loss: 1.5646271705627441\n",
      "step 429 from 15345 at epoch 0\n",
      "Loss: 1.6434190273284912\n",
      "step 439 from 15345 at epoch 0\n",
      "Loss: 0.8724789023399353\n",
      "step 449 from 15345 at epoch 0\n",
      "Loss: 1.123854160308838\n",
      "step 459 from 15345 at epoch 0\n",
      "Loss: 1.8283414840698242\n",
      "step 469 from 15345 at epoch 0\n",
      "Loss: 1.2860461473464966\n",
      "step 479 from 15345 at epoch 0\n",
      "Loss: 1.3811348676681519\n",
      "step 489 from 15345 at epoch 0\n",
      "Loss: 0.9114689230918884\n",
      "step 499 from 15345 at epoch 0\n",
      "Loss: 1.3615769147872925\n",
      "step 509 from 15345 at epoch 0\n",
      "Loss: 0.9099400043487549\n",
      "step 519 from 15345 at epoch 0\n",
      "Loss: 0.9839171767234802\n",
      "step 529 from 15345 at epoch 0\n",
      "Loss: 1.2458769083023071\n",
      "step 539 from 15345 at epoch 0\n",
      "Loss: 1.1451455354690552\n",
      "step 549 from 15345 at epoch 0\n",
      "Loss: 1.2814997434616089\n",
      "step 559 from 15345 at epoch 0\n",
      "Loss: 1.021313190460205\n",
      "step 569 from 15345 at epoch 0\n",
      "Loss: 1.4620277881622314\n",
      "step 579 from 15345 at epoch 0\n",
      "Loss: 1.1403518915176392\n",
      "step 589 from 15345 at epoch 0\n",
      "Loss: 1.050628423690796\n",
      "step 599 from 15345 at epoch 0\n",
      "Loss: 0.8658959865570068\n",
      "step 609 from 15345 at epoch 0\n",
      "Loss: 1.7462148666381836\n",
      "step 619 from 15345 at epoch 0\n",
      "Loss: 0.9922745823860168\n",
      "step 629 from 15345 at epoch 0\n",
      "Loss: 1.0857781171798706\n",
      "step 639 from 15345 at epoch 0\n",
      "Loss: 1.1975020170211792\n",
      "step 649 from 15345 at epoch 0\n",
      "Loss: 1.0398796796798706\n",
      "step 659 from 15345 at epoch 0\n",
      "Loss: 1.4228174686431885\n",
      "step 669 from 15345 at epoch 0\n",
      "Loss: 0.7323257923126221\n",
      "step 679 from 15345 at epoch 0\n",
      "Loss: 1.3292782306671143\n",
      "step 689 from 15345 at epoch 0\n",
      "Loss: 0.843113899230957\n",
      "step 699 from 15345 at epoch 0\n",
      "Loss: 1.1345678567886353\n",
      "step 709 from 15345 at epoch 0\n",
      "Loss: 1.113340973854065\n",
      "step 719 from 15345 at epoch 0\n",
      "Loss: 1.3067251443862915\n",
      "step 729 from 15345 at epoch 0\n",
      "Loss: 0.9858537316322327\n",
      "step 739 from 15345 at epoch 0\n",
      "Loss: 1.180248498916626\n",
      "step 749 from 15345 at epoch 0\n",
      "Loss: 1.468969464302063\n",
      "step 759 from 15345 at epoch 0\n",
      "Loss: 1.0630160570144653\n",
      "step 769 from 15345 at epoch 0\n",
      "Loss: 0.9245745539665222\n",
      "step 779 from 15345 at epoch 0\n",
      "Loss: 1.190551519393921\n",
      "step 789 from 15345 at epoch 0\n",
      "Loss: 1.0383490324020386\n",
      "step 799 from 15345 at epoch 0\n",
      "Loss: 1.2431714534759521\n",
      "step 809 from 15345 at epoch 0\n",
      "Loss: 1.2036924362182617\n",
      "step 819 from 15345 at epoch 0\n",
      "Loss: 1.0900945663452148\n",
      "step 829 from 15345 at epoch 0\n",
      "Loss: 1.1051864624023438\n",
      "step 839 from 15345 at epoch 0\n",
      "Loss: 0.8977494239807129\n",
      "step 849 from 15345 at epoch 0\n",
      "Loss: 1.029862642288208\n",
      "step 859 from 15345 at epoch 0\n",
      "Loss: 1.0144178867340088\n",
      "step 869 from 15345 at epoch 0\n",
      "Loss: 1.0783109664916992\n",
      "step 879 from 15345 at epoch 0\n",
      "Loss: 1.1740237474441528\n",
      "step 889 from 15345 at epoch 0\n",
      "Loss: 0.9799554944038391\n",
      "step 899 from 15345 at epoch 0\n",
      "Loss: 1.2492181062698364\n",
      "step 909 from 15345 at epoch 0\n",
      "Loss: 0.8205748796463013\n",
      "step 919 from 15345 at epoch 0\n",
      "Loss: 1.531720757484436\n",
      "step 929 from 15345 at epoch 0\n",
      "Loss: 1.3993587493896484\n",
      "step 939 from 15345 at epoch 0\n",
      "Loss: 0.7893152832984924\n",
      "step 949 from 15345 at epoch 0\n",
      "Loss: 1.007469654083252\n",
      "step 959 from 15345 at epoch 0\n",
      "Loss: 1.160200834274292\n",
      "step 969 from 15345 at epoch 0\n",
      "Loss: 1.429113745689392\n",
      "step 979 from 15345 at epoch 0\n",
      "Loss: 0.7993736863136292\n",
      "step 989 from 15345 at epoch 0\n",
      "Loss: 1.1206884384155273\n",
      "step 999 from 15345 at epoch 0\n",
      "Loss: 1.2067254781723022\n",
      "step 1009 from 15345 at epoch 0\n",
      "Loss: 1.1327158212661743\n",
      "step 1019 from 15345 at epoch 0\n",
      "Loss: 1.0995235443115234\n",
      "step 1029 from 15345 at epoch 0\n",
      "Loss: 1.1743714809417725\n",
      "step 1039 from 15345 at epoch 0\n",
      "Loss: 1.1699951887130737\n",
      "step 1049 from 15345 at epoch 0\n",
      "Loss: 0.9407461285591125\n",
      "step 1059 from 15345 at epoch 0\n",
      "Loss: 0.9446122050285339\n",
      "step 1069 from 15345 at epoch 0\n",
      "Loss: 1.2751516103744507\n",
      "step 1079 from 15345 at epoch 0\n",
      "Loss: 1.038480281829834\n",
      "step 1089 from 15345 at epoch 0\n",
      "Loss: 1.3187309503555298\n",
      "step 1099 from 15345 at epoch 0\n",
      "Loss: 0.9715356826782227\n",
      "step 1109 from 15345 at epoch 0\n",
      "Loss: 1.1870372295379639\n",
      "step 1119 from 15345 at epoch 0\n",
      "Loss: 1.2373937368392944\n",
      "step 1129 from 15345 at epoch 0\n",
      "Loss: 1.6826419830322266\n",
      "step 1139 from 15345 at epoch 0\n",
      "Loss: 0.8660679459571838\n",
      "step 1149 from 15345 at epoch 0\n",
      "Loss: 1.273607850074768\n",
      "step 1159 from 15345 at epoch 0\n",
      "Loss: 1.4078947305679321\n",
      "step 1169 from 15345 at epoch 0\n",
      "Loss: 0.9241517782211304\n",
      "step 1179 from 15345 at epoch 0\n",
      "Loss: 0.9646480679512024\n",
      "step 1189 from 15345 at epoch 0\n",
      "Loss: 1.2928576469421387\n",
      "step 1199 from 15345 at epoch 0\n",
      "Loss: 1.6786166429519653\n",
      "step 1209 from 15345 at epoch 0\n",
      "Loss: 1.1221179962158203\n",
      "step 1219 from 15345 at epoch 0\n",
      "Loss: 0.583706259727478\n",
      "step 1229 from 15345 at epoch 0\n",
      "Loss: 0.7666286826133728\n",
      "step 1239 from 15345 at epoch 0\n",
      "Loss: 0.8080565333366394\n",
      "step 1249 from 15345 at epoch 0\n",
      "Loss: 1.2720708847045898\n",
      "step 1259 from 15345 at epoch 0\n",
      "Loss: 0.7695231437683105\n",
      "step 1269 from 15345 at epoch 0\n",
      "Loss: 0.9688054919242859\n",
      "step 1279 from 15345 at epoch 0\n",
      "Loss: 0.7390531897544861\n",
      "step 1289 from 15345 at epoch 0\n",
      "Loss: 1.2739418745040894\n",
      "step 1299 from 15345 at epoch 0\n",
      "Loss: 0.8930158615112305\n",
      "step 1309 from 15345 at epoch 0\n",
      "Loss: 0.9028691053390503\n",
      "step 1319 from 15345 at epoch 0\n",
      "Loss: 1.1091550588607788\n",
      "step 1329 from 15345 at epoch 0\n",
      "Loss: 1.2281500101089478\n",
      "step 1339 from 15345 at epoch 0\n",
      "Loss: 0.7376582026481628\n",
      "step 1349 from 15345 at epoch 0\n",
      "Loss: 0.9173908233642578\n",
      "step 1359 from 15345 at epoch 0\n",
      "Loss: 0.8731407523155212\n",
      "step 1369 from 15345 at epoch 0\n",
      "Loss: 2.2718281745910645\n",
      "step 1379 from 15345 at epoch 0\n",
      "Loss: 0.8863726854324341\n",
      "step 1389 from 15345 at epoch 0\n",
      "Loss: 0.6745535731315613\n",
      "step 1399 from 15345 at epoch 0\n",
      "Loss: 1.0753896236419678\n",
      "step 1409 from 15345 at epoch 0\n",
      "Loss: 1.13136887550354\n",
      "step 1419 from 15345 at epoch 0\n",
      "Loss: 1.1761784553527832\n",
      "step 1429 from 15345 at epoch 0\n",
      "Loss: 1.4424543380737305\n",
      "step 1439 from 15345 at epoch 0\n",
      "Loss: 0.8569557070732117\n",
      "step 1449 from 15345 at epoch 0\n",
      "Loss: 1.3927063941955566\n",
      "step 1459 from 15345 at epoch 0\n",
      "Loss: 1.000339388847351\n",
      "step 1469 from 15345 at epoch 0\n",
      "Loss: 1.3522038459777832\n",
      "step 1479 from 15345 at epoch 0\n",
      "Loss: 1.0976319313049316\n",
      "step 1489 from 15345 at epoch 0\n",
      "Loss: 0.9745999574661255\n",
      "step 1499 from 15345 at epoch 0\n",
      "Loss: 1.3015552759170532\n",
      "step 1509 from 15345 at epoch 0\n",
      "Loss: 1.1099960803985596\n",
      "step 1519 from 15345 at epoch 0\n",
      "Loss: 1.016098976135254\n",
      "step 1529 from 15345 at epoch 0\n",
      "Loss: 1.0517587661743164\n",
      "step 1539 from 15345 at epoch 0\n",
      "Loss: 0.9186943769454956\n",
      "step 1549 from 15345 at epoch 0\n",
      "Loss: 0.91225665807724\n",
      "step 1559 from 15345 at epoch 0\n",
      "Loss: 1.0165458917617798\n",
      "step 1569 from 15345 at epoch 0\n",
      "Loss: 0.8871088027954102\n",
      "step 1579 from 15345 at epoch 0\n",
      "Loss: 0.942290186882019\n",
      "step 1589 from 15345 at epoch 0\n",
      "Loss: 1.0679335594177246\n",
      "step 1599 from 15345 at epoch 0\n",
      "Loss: 1.0170260667800903\n",
      "step 1609 from 15345 at epoch 0\n",
      "Loss: 1.1676098108291626\n",
      "step 1619 from 15345 at epoch 0\n",
      "Loss: 1.4107282161712646\n",
      "step 1629 from 15345 at epoch 0\n",
      "Loss: 0.9827550649642944\n",
      "step 1639 from 15345 at epoch 0\n",
      "Loss: 1.0397627353668213\n",
      "step 1649 from 15345 at epoch 0\n",
      "Loss: 1.3929812908172607\n",
      "step 1659 from 15345 at epoch 0\n",
      "Loss: 1.092084527015686\n",
      "step 1669 from 15345 at epoch 0\n",
      "Loss: 1.025058388710022\n",
      "step 1679 from 15345 at epoch 0\n",
      "Loss: 0.9482988119125366\n",
      "step 1689 from 15345 at epoch 0\n",
      "Loss: 1.0728638172149658\n",
      "step 1699 from 15345 at epoch 0\n",
      "Loss: 1.0970110893249512\n",
      "step 1709 from 15345 at epoch 0\n",
      "Loss: 1.0400015115737915\n",
      "step 1719 from 15345 at epoch 0\n",
      "Loss: 1.0530985593795776\n",
      "step 1729 from 15345 at epoch 0\n",
      "Loss: 1.212524175643921\n",
      "step 1739 from 15345 at epoch 0\n",
      "Loss: 1.522189974784851\n",
      "step 1749 from 15345 at epoch 0\n",
      "Loss: 0.9769559502601624\n",
      "step 1759 from 15345 at epoch 0\n",
      "Loss: 0.9290553331375122\n",
      "step 1769 from 15345 at epoch 0\n",
      "Loss: 1.150789737701416\n",
      "step 1779 from 15345 at epoch 0\n",
      "Loss: 1.1530981063842773\n",
      "step 1789 from 15345 at epoch 0\n",
      "Loss: 1.0307178497314453\n",
      "step 1799 from 15345 at epoch 0\n",
      "Loss: 0.9176979660987854\n",
      "step 1809 from 15345 at epoch 0\n",
      "Loss: 0.7446230053901672\n",
      "step 1819 from 15345 at epoch 0\n",
      "Loss: 0.9668669700622559\n",
      "step 1829 from 15345 at epoch 0\n",
      "Loss: 0.8747678399085999\n",
      "step 1839 from 15345 at epoch 0\n",
      "Loss: 0.8317097425460815\n",
      "step 1849 from 15345 at epoch 0\n",
      "Loss: 0.9689090847969055\n",
      "step 1859 from 15345 at epoch 0\n",
      "Loss: 0.9466410875320435\n",
      "step 1869 from 15345 at epoch 0\n",
      "Loss: 1.2460353374481201\n",
      "step 1879 from 15345 at epoch 0\n",
      "Loss: 1.187795877456665\n",
      "step 1889 from 15345 at epoch 0\n",
      "Loss: 1.3054126501083374\n",
      "step 1899 from 15345 at epoch 0\n",
      "Loss: 0.7235223054885864\n",
      "step 1909 from 15345 at epoch 0\n",
      "Loss: 1.3332682847976685\n",
      "step 1919 from 15345 at epoch 0\n",
      "Loss: 0.8941158056259155\n",
      "step 1929 from 15345 at epoch 0\n",
      "Loss: 1.0287004709243774\n",
      "step 1939 from 15345 at epoch 0\n",
      "Loss: 1.0333893299102783\n",
      "step 1949 from 15345 at epoch 0\n",
      "Loss: 1.195788860321045\n",
      "step 1959 from 15345 at epoch 0\n",
      "Loss: 0.7889554500579834\n",
      "step 1969 from 15345 at epoch 0\n",
      "Loss: 1.1566799879074097\n",
      "step 1979 from 15345 at epoch 0\n",
      "Loss: 0.8842547535896301\n",
      "step 1989 from 15345 at epoch 0\n",
      "Loss: 1.3146995306015015\n",
      "step 1999 from 15345 at epoch 0\n",
      "Loss: 0.9358744621276855\n",
      "step 2009 from 15345 at epoch 0\n",
      "Loss: 0.7924362421035767\n",
      "step 2019 from 15345 at epoch 0\n",
      "Loss: 0.8506460785865784\n",
      "step 2029 from 15345 at epoch 0\n",
      "Loss: 1.2510321140289307\n",
      "step 2039 from 15345 at epoch 0\n",
      "Loss: 1.067546010017395\n",
      "step 2049 from 15345 at epoch 0\n",
      "Loss: 0.7248246669769287\n",
      "step 2059 from 15345 at epoch 0\n",
      "Loss: 0.5781708359718323\n",
      "step 2069 from 15345 at epoch 0\n",
      "Loss: 0.7861341238021851\n",
      "step 2079 from 15345 at epoch 0\n",
      "Loss: 1.1856516599655151\n",
      "step 2089 from 15345 at epoch 0\n",
      "Loss: 0.9249194264411926\n",
      "step 2099 from 15345 at epoch 0\n",
      "Loss: 0.7046238780021667\n",
      "step 2109 from 15345 at epoch 0\n",
      "Loss: 0.9806351065635681\n",
      "step 2119 from 15345 at epoch 0\n",
      "Loss: 1.0294023752212524\n",
      "step 2129 from 15345 at epoch 0\n",
      "Loss: 1.2587835788726807\n",
      "step 2139 from 15345 at epoch 0\n",
      "Loss: 1.2186859846115112\n",
      "step 2149 from 15345 at epoch 0\n",
      "Loss: 0.7231960892677307\n",
      "step 2159 from 15345 at epoch 0\n",
      "Loss: 0.8036072254180908\n",
      "step 2169 from 15345 at epoch 0\n",
      "Loss: 1.059880256652832\n",
      "step 2179 from 15345 at epoch 0\n",
      "Loss: 1.0784202814102173\n",
      "step 2189 from 15345 at epoch 0\n",
      "Loss: 1.2944225072860718\n",
      "step 2199 from 15345 at epoch 0\n",
      "Loss: 0.8944107294082642\n",
      "step 2209 from 15345 at epoch 0\n",
      "Loss: 0.7715184688568115\n",
      "step 2219 from 15345 at epoch 0\n",
      "Loss: 1.0769851207733154\n",
      "step 2229 from 15345 at epoch 0\n",
      "Loss: 0.9479007124900818\n",
      "step 2239 from 15345 at epoch 0\n",
      "Loss: 1.0746150016784668\n",
      "step 2249 from 15345 at epoch 0\n",
      "Loss: 0.9151420593261719\n",
      "step 2259 from 15345 at epoch 0\n",
      "Loss: 1.2171518802642822\n",
      "step 2269 from 15345 at epoch 0\n",
      "Loss: 1.0419461727142334\n",
      "step 2279 from 15345 at epoch 0\n",
      "Loss: 0.9884421825408936\n",
      "step 2289 from 15345 at epoch 0\n",
      "Loss: 1.8517045974731445\n",
      "step 2299 from 15345 at epoch 0\n",
      "Loss: 0.6896488666534424\n",
      "step 2309 from 15345 at epoch 0\n",
      "Loss: 0.9550421833992004\n",
      "step 2319 from 15345 at epoch 0\n",
      "Loss: 1.3558484315872192\n",
      "step 2329 from 15345 at epoch 0\n",
      "Loss: 1.0246671438217163\n",
      "step 2339 from 15345 at epoch 0\n",
      "Loss: 1.6292967796325684\n",
      "step 2349 from 15345 at epoch 0\n",
      "Loss: 0.7812110185623169\n",
      "step 2359 from 15345 at epoch 0\n",
      "Loss: 1.3301515579223633\n",
      "step 2369 from 15345 at epoch 0\n",
      "Loss: 0.9145644307136536\n",
      "step 2379 from 15345 at epoch 0\n",
      "Loss: 0.7877485156059265\n",
      "step 2389 from 15345 at epoch 0\n",
      "Loss: 1.0585870742797852\n",
      "step 2399 from 15345 at epoch 0\n",
      "Loss: 0.8298651576042175\n",
      "step 2409 from 15345 at epoch 0\n",
      "Loss: 0.9276319742202759\n",
      "step 2419 from 15345 at epoch 0\n",
      "Loss: 1.0379879474639893\n",
      "step 2429 from 15345 at epoch 0\n",
      "Loss: 1.0085070133209229\n",
      "step 2439 from 15345 at epoch 0\n",
      "Loss: 0.7809475064277649\n",
      "step 2449 from 15345 at epoch 0\n",
      "Loss: 0.9538843035697937\n",
      "step 2459 from 15345 at epoch 0\n",
      "Loss: 1.1554017066955566\n",
      "step 2469 from 15345 at epoch 0\n",
      "Loss: 1.0732057094573975\n",
      "step 2479 from 15345 at epoch 0\n",
      "Loss: 0.9081259965896606\n",
      "step 2489 from 15345 at epoch 0\n",
      "Loss: 1.4357452392578125\n",
      "step 2499 from 15345 at epoch 0\n",
      "Loss: 1.090673804283142\n",
      "step 2509 from 15345 at epoch 0\n",
      "Loss: 1.6763887405395508\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, custom_embedding_value=torch.tensor([33]))\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "criterion = criterion.to(device)\n",
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)\n",
    "\n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)\n",
    "# %%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id',\n",
    "    \"custom_embedding_type\": \"electronegativity\"\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))\n",
    "# %%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))\n",
    "    path = '_'.join((timestamp, 'epoch', str(i), '.pickle'))\n",
    "    torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad4811-be9e-4ea5-9b34-5a5018a68bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0759d-b9bb-4388-912e-655b0d6a6dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
