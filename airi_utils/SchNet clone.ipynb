{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f595285-7cd2-42c2-8622-54f65926c049",
   "metadata": {},
   "source": [
    "## Utils and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d618c1-7bd7-4b54-b5c6-cd8fab531f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ff967c-f351-4f61-97d4-1009ca24ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import lmdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d50430de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_reshape(tensor):\n",
    "    return torch.reshape(tensor, (tensor.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3099636a-c3a8-4bf5-86f8-4983eba165c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы тензор по умолчанию заводился на куде\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2b308d-ffa4-4f48-adab-e218d7da0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "643edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер\n",
    "def simple_preprocessing(system):\n",
    "    #spherical_radii = torch.Tensor(system['spherical_domain_radii'])\n",
    "    #spherical_radii = my_reshape(spherical_radii)\n",
    "    \n",
    "    tags = system['tags'].long().to(device)\n",
    "    tags = F.one_hot(tags, num_classes=3)\n",
    "    \n",
    "    atom_numbers = system['atomic_numbers'].long().to(device)\n",
    "    atom_numbers = F.one_hot(atom_numbers, num_classes=100)\n",
    "    \n",
    "    voronoi_volumes = system['voronoi_volumes'].float().to(device)\n",
    "    voronoi_volumes = my_reshape(voronoi_volumes)\n",
    "    \n",
    "    atom_features = (tags, atom_numbers, voronoi_volumes)#, spherical_radii)\n",
    "    atom_embeds = torch.cat(atom_features, 1)\n",
    "    \n",
    "    edge_index = system['edge_index_new'].long().to(device)\n",
    "    \n",
    "    distances = system['distances_new'].float().to(device)\n",
    "    distances = my_reshape(distances)\n",
    "    \n",
    "    angles = system['contact_solid_angles'].float().to(device)\n",
    "    angles = my_reshape(angles)\n",
    "    \n",
    "    edges_embeds = torch.cat((distances, angles), 1)\n",
    "    \n",
    "    \n",
    "    return Data(x=atom_embeds.to(device), edge_index=edge_index.to(device), edge_attr=edges_embeds.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#датасет, который умеет возвращать эелемент и собственную длину\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, features_fields, target_field, type_='train', preprocessing=simple_preprocessing):\n",
    "        \n",
    "        self.data = lmdb_dataset({\"src\": data})\n",
    "        self.length = len(self.data)\n",
    "        #self.target = data[target_field]\n",
    "        self.type_ = type_\n",
    "        self.preprocessing = preprocessing\n",
    "        self.target = target_field\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        system = self.preprocessing(self.data[index])\n",
    "        \n",
    "        if self.type_ == 'train':\n",
    "            y = self.data[index][self.target]\n",
    "            \n",
    "            return system, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81347061-e7ae-4ed8-8957-d430e1443c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['atomic_numbers', 'edge_index_new', 'distances_new', \n",
    "                 'contact_solid_angles', 'tags', 'voronoi_volumes', 'spherical_domain_radii']\n",
    "\n",
    "target_col = 'y_relaxed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf8ed5d-ba8c-44e7-a343-1e7092ffca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data_mod.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col)\n",
    "training_generator = DataLoader(training_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae852e60-b1ac-4a48-8120-af94ecec6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data_mod.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f64a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: 0\n",
      "edge_index:............... [2, 2964]\n",
      "pos:......................   [86, 3]\n",
      "cell:..................... [1, 3, 3]\n",
      "atomic_numbers:...........      [86]\n",
      "natoms:...................        86\n",
      "cell_offsets:............. [2964, 3]\n",
      "force:....................   [86, 3]\n",
      "distances:................    [2964]\n",
      "fixed:....................      [86]\n",
      "sid:......................   2472718\n",
      "tags:.....................      [86]\n",
      "y_init:...................    6.2825\n",
      "y_relaxed:................   -0.0256\n",
      "pos_relaxed:..............   [86, 3]\n",
      "voronoi_volumes:..........      [86]\n",
      "voronoi_surface_areas:....      [86]\n",
      "spherical_domain_radii:...      [86]\n",
      "cell_offsets_new:......... [1214, 3]\n",
      "distances_new:............    [1214]\n",
      "contact_solid_angles:.....    [1214]\n",
      "direct_neighbor:..........    [1214]\n",
      "edge_index_new:........... [2, 1214]\n"
     ]
    }
   ],
   "source": [
    "lmdb_dataset({\"src\": train_dataset_file_path}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a77d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(self, start=0.0, stop=8.0, num_gaussians=300):\n",
    "        super(GaussianSmearing, self).__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb49e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftedSoftplus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShiftedSoftplus, self).__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.softplus(x) - self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8f958",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672a07d",
   "metadata": {},
   "source": [
    "Гамма лежит в апдейт, квадратик в aggr, а фи в месседж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ae848d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFconv(MessagePassing):\n",
    "    def __init__(self, dim_hidden, dim_edge):   #dim_edge с учётом смеаринга\n",
    "        super(CFconv, self).__init__(aggr='add')# \"Add\" aggregation\n",
    "        self.rbf = GaussianSmearing()\n",
    "        self.blocks = nn.Sequential(nn.Linear(dim_edge, dim_hidden),\n",
    "                                   ShiftedSoftplus(),\n",
    "                                   nn.Linear(dim_hidden, dim_hidden),\n",
    "                                   ShiftedSoftplus())\n",
    "        self.lin_phi = torch.nn.Linear(dim_hidden, dim_hidden, bias=False)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['x']\n",
    "        edge_index = batch['edge_index']\n",
    "        rbf_dist = self.rbf(batch['edge_attr'][:, 0])\n",
    "        edge_attr = torch.cat((rbf_dist, batch['edge_attr']), 1)\n",
    "        edge_attr = self.blocks(edge_attr)\n",
    "        \n",
    "    \n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "\n",
    "    def message(self, x, x_i, x_j, edge_attr):\n",
    "        new_edges = self.lin_phi(edge_attr)\n",
    "        hd_product = x_j * new_edges\n",
    "        return hd_product\n",
    "        \n",
    "    def update(self, aggr_out):\n",
    "\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfadfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_hidden, dim_edge):\n",
    "        super().__init__()\n",
    "        self.atom_wise_64_1 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        self.cfconv = CFconv(dim_hidden, dim_edge)\n",
    "        self.atom_wise_64_2 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        self.shifted_softplus = ShiftedSoftplus()\n",
    "        self.atom_wise_64_3 = nn.Linear(dim_hidden, dim_hidden, bias=True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x_input = batch['x'].clone().detach()\n",
    "        batch['x'] = self.atom_wise_64_1(batch['x'])\n",
    "        conved = self.cfconv(batch)\n",
    "        conved = self.atom_wise_64_2(conved)\n",
    "        ssp = self.shifted_softplus(conved)\n",
    "        v = self.atom_wise_64_3(ssp)\n",
    "        \n",
    "        return x_input + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e1232c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_atom=103, dim_edge=2, dim_hidden=64):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(dim_atom, dim_hidden)\n",
    "        self.interaction1 = Interaction(dim_hidden, dim_edge)\n",
    "        self.interaction2 = Interaction(dim_hidden, dim_edge)\n",
    "        self.interaction3 = Interaction(dim_hidden, dim_edge)\n",
    "        self.shifted_softplus = ShiftedSoftplus()\n",
    "        self.atom_wise_32 = nn.Linear(dim_hidden, 32, bias=True)\n",
    "        self.atom_wise_1 = nn.Linear(32, 1, bias=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch['x'] = self.embedding(batch['x'])\n",
    "        batch['x'] = self.interaction1(batch)\n",
    "        batch['x'] = self.interaction2(batch)\n",
    "        batch['x'] = self.interaction3(batch)\n",
    "        x_32 = self.atom_wise_32(batch['x'])\n",
    "        x_32 = self.shifted_softplus(x_32)\n",
    "        energies = self.atom_wise_1(x_32)\n",
    "        energy = scatter(energies, batch['batch'], dim=0, reduce='sum')\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20798f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_scalars(lr, loss, writer, step=-1, epoch=-1, type_='train'):\n",
    "    if type_ == 'train':\n",
    "        writer.add_scalar('lr per step on train', lr, step) \n",
    "        writer.add_scalar('loss per step on train', loss, step)\n",
    "    if type_ == 'val':\n",
    "        writer.add_scalar('loss per epoch on val', loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "862b1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_hist(model, writer, step):\n",
    "    for name, weight in model.named_parameters():\n",
    "        writer.add_histogram(name, weight, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9d7343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, print_every=10, epoch=0, writer=None):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for i, (systems, ys) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(systems).squeeze()\n",
    "        \n",
    "        loss = criterion(predictions.float(), ys.to(device).float())\n",
    "        loss.backward()     \n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = loss.item() \n",
    "        epoch_loss += batch_loss  \n",
    "        \n",
    "        if writer != None:\n",
    "            \n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            step = i + epoch*len(iterator)\n",
    "            \n",
    "            send_hist(model, writer, i)\n",
    "            send_scalars(lr, batch_loss, writer, step=step, epoch=epoch, type_='train')\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'step {i} from {len(iterator)} at epoch {epoch}')\n",
    "            print(f'Loss: {batch_loss}')\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a8e76f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, epoch=0, writer=False):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems, ys in iterator:   \n",
    "\n",
    "            predictions = model(systems).squeeze()\n",
    "            loss = criterion(predictions.float(), ys.to(device).float())        \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    overall_loss = epoch_loss / len(iterator)\n",
    "\n",
    "    if writer != None:\n",
    "        send_scalars(None, overall_loss, writer, step=None, epoch=epoch, type_='val')\n",
    "                \n",
    "    print(f'epoch loss {overall_loss}')\n",
    "            \n",
    "    return overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31952209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferens(model, iterator):\n",
    "    y = torch.tensor([])\n",
    "\n",
    "#    model.train(False)\n",
    "    model.eval()  \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for systems, ys in iterator:   \n",
    "          predictions = model(systemhs).squeeze()\n",
    "          y = torch.cat((y, predictions))\n",
    "      \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ca059",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = ConvNN(dim_atom=training_set[0][0].x.shape[1], dim_edge=training_set[0][0].edge_attr.shape[1]+300)\n",
    "\n",
    "#optimizer and loss\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc1c0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-09-09-19-13\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e477b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "writer.add_graph(model, trace_system)\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-09-09-19-13\n",
      "Start training model ConvNN(\n",
      "  (embedding): Linear(in_features=104, out_features=64, bias=True)\n",
      "  (interaction1): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (interaction2): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (interaction3): Interaction(\n",
      "    (atom_wise_64_1): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (cfconv): CFconv(\n",
      "      (rbf): GaussianSmearing()\n",
      "      (blocks): Sequential(\n",
      "        (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "        (1): ShiftedSoftplus()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (3): ShiftedSoftplus()\n",
      "      )\n",
      "      (lin_phi): Linear(in_features=64, out_features=64, bias=False)\n",
      "    )\n",
      "    (atom_wise_64_2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (shifted_softplus): ShiftedSoftplus()\n",
      "    (atom_wise_64_3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (shifted_softplus): ShiftedSoftplus()\n",
      "  (atom_wise_32): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (atom_wise_1): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0\n",
      "step 9 from 200 at epoch 0\n",
      "Loss: 4.493058681488037\n",
      "step 19 from 200 at epoch 0\n",
      "Loss: 6.776739597320557\n",
      "step 29 from 200 at epoch 0\n",
      "Loss: 4.468339443206787\n",
      "step 39 from 200 at epoch 0\n",
      "Loss: 2.3052163124084473\n",
      "step 49 from 200 at epoch 0\n",
      "Loss: 2.3242101669311523\n",
      "step 59 from 200 at epoch 0\n",
      "Loss: 2.5864620208740234\n",
      "step 69 from 200 at epoch 0\n",
      "Loss: 2.2693686485290527\n",
      "step 79 from 200 at epoch 0\n",
      "Loss: 2.0957236289978027\n",
      "step 89 from 200 at epoch 0\n",
      "Loss: 1.7768821716308594\n",
      "step 99 from 200 at epoch 0\n",
      "Loss: 2.0612335205078125\n",
      "step 109 from 200 at epoch 0\n",
      "Loss: 1.778444766998291\n",
      "step 119 from 200 at epoch 0\n",
      "Loss: 1.5584592819213867\n",
      "step 129 from 200 at epoch 0\n",
      "Loss: 1.6139578819274902\n",
      "step 139 from 200 at epoch 0\n",
      "Loss: 2.0985333919525146\n",
      "step 149 from 200 at epoch 0\n",
      "Loss: 1.7813818454742432\n",
      "step 159 from 200 at epoch 0\n",
      "Loss: 1.8865901231765747\n",
      "step 169 from 200 at epoch 0\n",
      "Loss: 1.5430281162261963\n",
      "step 179 from 200 at epoch 0\n",
      "Loss: 1.6494566202163696\n",
      "step 189 from 200 at epoch 0\n",
      "Loss: 1.4675400257110596\n",
      "step 199 from 200 at epoch 0\n",
      "Loss: 1.8375576734542847\n",
      "epoch 0 evaluation\n",
      "epoch loss 1.8445772268772125\n",
      "========================================================================================================\n",
      "epoch 1\n",
      "step 9 from 200 at epoch 1\n",
      "Loss: 1.6250723600387573\n",
      "step 19 from 200 at epoch 1\n",
      "Loss: 2.191901445388794\n",
      "step 29 from 200 at epoch 1\n",
      "Loss: 1.5094302892684937\n",
      "step 39 from 200 at epoch 1\n",
      "Loss: 1.5136793851852417\n",
      "step 49 from 200 at epoch 1\n",
      "Loss: 1.5815987586975098\n",
      "step 59 from 200 at epoch 1\n",
      "Loss: 2.979262590408325\n",
      "step 69 from 200 at epoch 1\n",
      "Loss: 1.6656951904296875\n",
      "step 79 from 200 at epoch 1\n",
      "Loss: 2.4551734924316406\n",
      "step 89 from 200 at epoch 1\n",
      "Loss: 1.3294553756713867\n",
      "step 99 from 200 at epoch 1\n",
      "Loss: 1.6513938903808594\n",
      "step 109 from 200 at epoch 1\n",
      "Loss: 1.6205012798309326\n",
      "step 119 from 200 at epoch 1\n",
      "Loss: 1.39780592918396\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    print(f'epoch {i}')\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer))\n",
    "    print(f'epoch {i} evaluation')\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer))\n",
    "    print('========================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models-env",
   "language": "python",
   "name": "ocp-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
