{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0bc839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset, DataListLoader\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('../ocpmodels/models'))\n",
    "sys.path.append(os.path.expanduser('../../ocp_airi'))\n",
    "\n",
    "from spinconv_with_embeds_single import spinconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bb08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    keys = ['pos', 'atomic_numbers', 'cell', 'natoms']\n",
    "    features_dict = {}\n",
    "    for key in keys:\n",
    "        features_dict[key] = system[key]\n",
    "    return Data(**features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c78a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 70\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136e247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf51cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/all/train/data.lmdb\")\n",
    "train_dataset_file = lmdb_dataset(train_dataset_file_path)\n",
    "training_set = Dataset(train_dataset_file, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = DataListLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc56aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\")\n",
    "val_dataset_file = lmdb_dataset(val_dataset_file_path)\n",
    "valid_set = Dataset(val_dataset_file, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataListLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ca58f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 460328\n",
      "info for item: 0\n",
      "edge_index:...............<class 'torch.Tensor'>..... [2, 2964]\n",
      "pos:......................<class 'torch.Tensor'>.....   [86, 3]\n",
      "cell:.....................<class 'torch.Tensor'>..... [1, 3, 3]\n",
      "atomic_numbers:...........<class 'torch.Tensor'>.....      [86]\n",
      "natoms:...................       <class 'int'>.....        86\n",
      "cell_offsets:.............<class 'torch.Tensor'>..... [2964, 3]\n",
      "force:....................<class 'torch.Tensor'>.....   [86, 3]\n",
      "distances:................<class 'torch.Tensor'>.....    [2964]\n",
      "fixed:....................<class 'torch.Tensor'>.....      [86]\n",
      "sid:......................       <class 'int'>.....   2472718\n",
      "tags:.....................<class 'torch.Tensor'>.....      [86]\n",
      "y_init:...................     <class 'float'>.....    6.2825\n",
      "y_relaxed:................     <class 'float'>.....   -0.0256\n",
      "pos_relaxed:..............<class 'torch.Tensor'>.....   [86, 3]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4083e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #model\n",
    "# model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, 0)\n",
    "# model = DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "# #optimizer and loss\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "# criterion = nn.L1Loss()\n",
    "\n",
    "# #переносим на куду если она есть\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552e9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05-14-40-54\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "timestamp = '2021-10-05-14-40-54'\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70fdea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e50b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no graph\n",
      "CPU times: user 712 µs, sys: 0 ns, total: 712 µs\n",
      "Wall time: 569 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id'\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42982a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2021-09-30-07-09-47\u001b[0m/  \u001b[01;34m2021-10-01-18-12-05\u001b[0m/  \u001b[01;34m2021-10-03-22-43-01\u001b[0m/\n",
      "\u001b[01;34m2021-09-30-07-16-30\u001b[0m/  \u001b[01;34m2021-10-01-18-13-22\u001b[0m/  \u001b[01;34m2021-10-04-00-30-46\u001b[0m/\n",
      "\u001b[01;34m2021-09-30-07-17-06\u001b[0m/  \u001b[01;34m2021-10-01-18-15-21\u001b[0m/  \u001b[01;34m2021-10-04-02-18-20\u001b[0m/\n",
      "\u001b[01;34m2021-09-30-07-30-08\u001b[0m/  \u001b[01;34m2021-10-01-18-18-08\u001b[0m/  \u001b[01;34m2021-10-04-04-06-01\u001b[0m/\n",
      "\u001b[01;34m2021-09-30-15-22-32\u001b[0m/  \u001b[01;34m2021-10-01-18-19-39\u001b[0m/  \u001b[01;34m2021-10-04-05-53-54\u001b[0m/\n",
      "\u001b[01;34m2021-09-30-15-23-11\u001b[0m/  \u001b[01;34m2021-10-01-18-23-49\u001b[0m/  \u001b[01;34m2021-10-05-06-59-34\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-06-49-39\u001b[0m/  \u001b[01;34m2021-10-01-18-31-51\u001b[0m/  \u001b[01;34m2021-10-05-08-19-25\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-08-00-57\u001b[0m/  \u001b[01;34m2021-10-01-18-32-52\u001b[0m/  \u001b[01;34m2021-10-05-10-05-42\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-08-36-22\u001b[0m/  \u001b[01;34m2021-10-01-18-34-30\u001b[0m/  \u001b[01;34m2021-10-05-10-06-21\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-09-46-06\u001b[0m/  \u001b[01;34m2021-10-01-18-36-08\u001b[0m/  \u001b[01;34m2021-10-05-10-06-58\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-10-11-32\u001b[0m/  \u001b[01;34m2021-10-01-18-57-46\u001b[0m/  \u001b[01;34m2021-10-05-10-07-44\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-12-15-55\u001b[0m/  \u001b[01;34m2021-10-01-19-04-00\u001b[0m/  \u001b[01;34m2021-10-05-10-18-46\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-12-19-55\u001b[0m/  \u001b[01;34m2021-10-01-19-06-16\u001b[0m/  \u001b[01;34m2021-10-05-10-19-42\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-16-43-31\u001b[0m/  \u001b[01;34m2021-10-01-19-07-01\u001b[0m/  \u001b[01;34m2021-10-05-10-22-18\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-17-35-24\u001b[0m/  \u001b[01;34m2021-10-01-19-09-20\u001b[0m/  \u001b[01;34m2021-10-05-10-23-19\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-17-41-07\u001b[0m/  \u001b[01;34m2021-10-03-15-20-06\u001b[0m/  \u001b[01;34m2021-10-05-10-24-06\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-17-45-10\u001b[0m/  \u001b[01;34m2021-10-03-15-22-28\u001b[0m/  \u001b[01;34m2021-10-05-10-24-46\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-17-46-28\u001b[0m/  \u001b[01;34m2021-10-03-15-23-25\u001b[0m/  \u001b[01;34m2021-10-05-10-25-17\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-17-57-53\u001b[0m/  \u001b[01;34m2021-10-03-15-25-05\u001b[0m/  \u001b[01;34m2021-10-05-10-26-42\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-00-38\u001b[0m/  \u001b[01;34m2021-10-03-15-26-06\u001b[0m/  \u001b[01;34m2021-10-05-10-27-16\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-01-49\u001b[0m/  \u001b[01;34m2021-10-03-15-26-50\u001b[0m/  \u001b[01;34m2021-10-05-10-27-52\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-03-26\u001b[0m/  \u001b[01;34m2021-10-03-15-27-30\u001b[0m/  \u001b[01;34m2021-10-05-11-22-41\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-05-41\u001b[0m/  \u001b[01;34m2021-10-03-17-17-58\u001b[0m/  \u001b[01;34m2021-10-05-14-40-54\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-06-40\u001b[0m/  \u001b[01;34m2021-10-03-19-06-51\u001b[0m/\n",
      "\u001b[01;34m2021-10-01-18-08-13\u001b[0m/  \u001b[01;34m2021-10-03-20-55-24\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls ../logs/tensorboard_airi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba0e5fa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92657ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# loss = []\n",
    "# loss_eval = []\n",
    "\n",
    "# print(timestamp)\n",
    "# print(f'Start training model {str(model)}')\n",
    "# for i in range(epochs):\n",
    "#     loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "#     loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c57563b-1076-446d-a287-9cf5486f39f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_discr = {\"group_onehot\" : list(range(18)),\n",
    "               \"period_onehot\": list(range(19, 27)),\n",
    "               \"block_onehot\" : list(range(28, 32)),\n",
    "               \"electronegativity\" : 33,\n",
    "               \"radius\" : 34,\n",
    "               \"valence\" : 35,\n",
    "               \"ionization\" : 36,\n",
    "               \"affinity\" : 37,\n",
    "               \"volume\": 38\n",
    "              }\n",
    "\n",
    "\n",
    "#model\n",
    "\n",
    "\n",
    "model_path = '../../ocp_airi/airi_utils/checkpoint/2021-10-05-14-40-54_epoch_0_.pickle'\n",
    "model_state_dict = '../../ocp_airi/airi_utils/checkpoint/2021-10-05-14-40-54_epoch_0_state_dict.pickle'\n",
    "\n",
    "# model = torch.load(model_path)\n",
    "\n",
    "model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, custom_embedding_value=torch.tensor(list(range(27))))\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_state_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3827358-0a2d-4d42-9779-479a7073505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05-14-40-54\n",
      "no graph\n",
      "2021-10-05-14-40-54\n",
      "Start training model DataParallel(\n",
      "  (module): spinconv(\n",
      "    (act): Swish()\n",
      "    (distance_expansion_forces): GaussianSmearing()\n",
      "    (embeddingblock2): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dist_block): DistanceBlock(\n",
      "      (distance_expansion): GaussianSmearing()\n",
      "      (dist_scalar): Embedding(8100, 1)\n",
      "      (dist_offset): Embedding(8100, 1)\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (message_blocks): ModuleList(\n",
      "      (0): MessageBlock(\n",
      "        (act): Swish()\n",
      "        (spinconvblock): SpinConvBlock(\n",
      "          (act): Swish()\n",
      "          (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "          (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "          (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "          (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (embeddingblock1): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (embeddingblock2): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (energyembeddingblock): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=32, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (force_output_block): ForceOutputBlock(\n",
      "      (act): Swish()\n",
      "      (spinconvblock): SpinConvBlock(\n",
      "        (act): Swish()\n",
      "        (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "        (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "        (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "        (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (block1): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (block2): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch 1\n",
      "step 9 from 6577 at epoch 1\n",
      "Loss: 0.9651602506637573\n",
      "step 19 from 6577 at epoch 1\n",
      "Loss: 0.8105707764625549\n",
      "step 29 from 6577 at epoch 1\n",
      "Loss: 0.8214519023895264\n",
      "step 39 from 6577 at epoch 1\n",
      "Loss: 0.8858839869499207\n",
      "step 49 from 6577 at epoch 1\n",
      "Loss: 0.8503207564353943\n",
      "step 59 from 6577 at epoch 1\n",
      "Loss: 0.9810636043548584\n",
      "step 69 from 6577 at epoch 1\n",
      "Loss: 0.9782435894012451\n",
      "step 79 from 6577 at epoch 1\n",
      "Loss: 0.7712267637252808\n",
      "step 89 from 6577 at epoch 1\n",
      "Loss: 0.9321230053901672\n",
      "step 99 from 6577 at epoch 1\n",
      "Loss: 0.760168731212616\n",
      "step 109 from 6577 at epoch 1\n",
      "Loss: 0.6812224388122559\n",
      "step 119 from 6577 at epoch 1\n",
      "Loss: 0.8886025547981262\n",
      "step 129 from 6577 at epoch 1\n",
      "Loss: 0.8395201563835144\n",
      "step 139 from 6577 at epoch 1\n",
      "Loss: 0.8456017971038818\n",
      "step 149 from 6577 at epoch 1\n",
      "Loss: 0.7446451187133789\n",
      "step 159 from 6577 at epoch 1\n",
      "Loss: 0.8496297597885132\n",
      "step 169 from 6577 at epoch 1\n",
      "Loss: 0.6849221587181091\n",
      "step 179 from 6577 at epoch 1\n",
      "Loss: 0.7700789570808411\n",
      "step 189 from 6577 at epoch 1\n",
      "Loss: 0.6603977680206299\n",
      "step 199 from 6577 at epoch 1\n",
      "Loss: 0.7999753952026367\n",
      "step 209 from 6577 at epoch 1\n",
      "Loss: 0.8425217866897583\n",
      "step 219 from 6577 at epoch 1\n",
      "Loss: 0.9803669452667236\n",
      "step 229 from 6577 at epoch 1\n",
      "Loss: 0.7332961559295654\n",
      "step 239 from 6577 at epoch 1\n",
      "Loss: 0.9865589737892151\n",
      "step 249 from 6577 at epoch 1\n",
      "Loss: 0.8987451791763306\n",
      "step 259 from 6577 at epoch 1\n",
      "Loss: 0.8662943243980408\n",
      "step 269 from 6577 at epoch 1\n",
      "Loss: 0.7051986455917358\n",
      "step 279 from 6577 at epoch 1\n",
      "Loss: 0.8751119375228882\n",
      "step 289 from 6577 at epoch 1\n",
      "Loss: 0.7487775683403015\n",
      "step 299 from 6577 at epoch 1\n",
      "Loss: 0.9049925804138184\n",
      "step 309 from 6577 at epoch 1\n",
      "Loss: 0.8260342478752136\n",
      "step 319 from 6577 at epoch 1\n",
      "Loss: 0.7135908007621765\n",
      "step 329 from 6577 at epoch 1\n",
      "Loss: 0.8261939883232117\n",
      "step 339 from 6577 at epoch 1\n",
      "Loss: 0.8188878297805786\n",
      "step 349 from 6577 at epoch 1\n",
      "Loss: 0.8920576572418213\n",
      "step 359 from 6577 at epoch 1\n",
      "Loss: 0.8548085689544678\n",
      "step 369 from 6577 at epoch 1\n",
      "Loss: 0.7965188026428223\n",
      "step 379 from 6577 at epoch 1\n",
      "Loss: 0.9024690985679626\n",
      "step 389 from 6577 at epoch 1\n",
      "Loss: 0.8216805458068848\n",
      "step 399 from 6577 at epoch 1\n",
      "Loss: 0.8589127659797668\n",
      "step 409 from 6577 at epoch 1\n",
      "Loss: 0.8976892232894897\n",
      "step 419 from 6577 at epoch 1\n",
      "Loss: 0.8280573487281799\n",
      "step 429 from 6577 at epoch 1\n",
      "Loss: 0.895634114742279\n",
      "step 439 from 6577 at epoch 1\n",
      "Loss: 0.9877999424934387\n",
      "step 449 from 6577 at epoch 1\n",
      "Loss: 0.7578473687171936\n",
      "step 459 from 6577 at epoch 1\n",
      "Loss: 0.9125754833221436\n",
      "step 469 from 6577 at epoch 1\n",
      "Loss: 0.7993796467781067\n",
      "step 479 from 6577 at epoch 1\n",
      "Loss: 0.7959867119789124\n",
      "step 489 from 6577 at epoch 1\n",
      "Loss: 0.7768663763999939\n",
      "step 499 from 6577 at epoch 1\n",
      "Loss: 0.9458034038543701\n",
      "step 509 from 6577 at epoch 1\n",
      "Loss: 0.8355653285980225\n",
      "step 519 from 6577 at epoch 1\n",
      "Loss: 0.8436937928199768\n",
      "step 529 from 6577 at epoch 1\n",
      "Loss: 0.825348436832428\n",
      "step 539 from 6577 at epoch 1\n",
      "Loss: 0.817672848701477\n",
      "step 549 from 6577 at epoch 1\n",
      "Loss: 0.9006808400154114\n",
      "step 559 from 6577 at epoch 1\n",
      "Loss: 0.8397768139839172\n",
      "step 569 from 6577 at epoch 1\n",
      "Loss: 0.8607764840126038\n",
      "step 579 from 6577 at epoch 1\n",
      "Loss: 0.8343799114227295\n",
      "step 589 from 6577 at epoch 1\n",
      "Loss: 0.8174376487731934\n",
      "step 599 from 6577 at epoch 1\n",
      "Loss: 0.8286861181259155\n",
      "step 609 from 6577 at epoch 1\n",
      "Loss: 0.7859888672828674\n",
      "step 619 from 6577 at epoch 1\n",
      "Loss: 0.8354711532592773\n",
      "step 629 from 6577 at epoch 1\n",
      "Loss: 0.8032300472259521\n",
      "step 639 from 6577 at epoch 1\n",
      "Loss: 0.793671190738678\n",
      "step 649 from 6577 at epoch 1\n",
      "Loss: 0.9467748403549194\n",
      "step 659 from 6577 at epoch 1\n",
      "Loss: 0.786470890045166\n",
      "step 669 from 6577 at epoch 1\n",
      "Loss: 0.6955435276031494\n",
      "step 679 from 6577 at epoch 1\n",
      "Loss: 1.0276954174041748\n",
      "step 689 from 6577 at epoch 1\n",
      "Loss: 1.017082929611206\n",
      "step 699 from 6577 at epoch 1\n",
      "Loss: 0.6715683937072754\n",
      "step 709 from 6577 at epoch 1\n",
      "Loss: 0.9563532471656799\n",
      "step 719 from 6577 at epoch 1\n",
      "Loss: 1.1309118270874023\n",
      "step 729 from 6577 at epoch 1\n",
      "Loss: 0.7789855003356934\n",
      "step 739 from 6577 at epoch 1\n",
      "Loss: 0.771907389163971\n",
      "step 749 from 6577 at epoch 1\n",
      "Loss: 0.6967570781707764\n",
      "step 759 from 6577 at epoch 1\n",
      "Loss: 0.8857076168060303\n",
      "step 769 from 6577 at epoch 1\n",
      "Loss: 0.9211094379425049\n",
      "step 779 from 6577 at epoch 1\n",
      "Loss: 0.8184212446212769\n",
      "step 789 from 6577 at epoch 1\n",
      "Loss: 0.6699414253234863\n",
      "step 799 from 6577 at epoch 1\n",
      "Loss: 0.6313244700431824\n",
      "step 809 from 6577 at epoch 1\n",
      "Loss: 0.8410351872444153\n",
      "step 819 from 6577 at epoch 1\n",
      "Loss: 0.7554588317871094\n",
      "step 829 from 6577 at epoch 1\n",
      "Loss: 0.7684444189071655\n",
      "step 839 from 6577 at epoch 1\n",
      "Loss: 0.8623579740524292\n",
      "step 849 from 6577 at epoch 1\n",
      "Loss: 0.9770547151565552\n",
      "step 859 from 6577 at epoch 1\n",
      "Loss: 0.9045031070709229\n",
      "step 869 from 6577 at epoch 1\n",
      "Loss: 1.010063886642456\n",
      "step 879 from 6577 at epoch 1\n",
      "Loss: 0.6648921966552734\n",
      "step 889 from 6577 at epoch 1\n",
      "Loss: 0.7833846211433411\n",
      "step 899 from 6577 at epoch 1\n",
      "Loss: 0.8319291472434998\n",
      "step 909 from 6577 at epoch 1\n",
      "Loss: 0.8993765711784363\n",
      "step 919 from 6577 at epoch 1\n",
      "Loss: 0.9464948177337646\n",
      "step 929 from 6577 at epoch 1\n",
      "Loss: 0.8606648445129395\n",
      "step 939 from 6577 at epoch 1\n",
      "Loss: 0.8502361178398132\n",
      "step 949 from 6577 at epoch 1\n",
      "Loss: 0.7370573282241821\n",
      "step 959 from 6577 at epoch 1\n",
      "Loss: 0.8636643886566162\n",
      "step 969 from 6577 at epoch 1\n",
      "Loss: 0.807170033454895\n",
      "step 979 from 6577 at epoch 1\n",
      "Loss: 0.8037818670272827\n",
      "step 989 from 6577 at epoch 1\n",
      "Loss: 0.9745433330535889\n",
      "step 999 from 6577 at epoch 1\n",
      "Loss: 0.70795077085495\n",
      "step 1009 from 6577 at epoch 1\n",
      "Loss: 0.880323052406311\n",
      "step 1019 from 6577 at epoch 1\n",
      "Loss: 0.8130984306335449\n",
      "step 1029 from 6577 at epoch 1\n",
      "Loss: 0.8408938050270081\n",
      "step 1039 from 6577 at epoch 1\n",
      "Loss: 0.6697991490364075\n",
      "step 1049 from 6577 at epoch 1\n",
      "Loss: 0.7390989661216736\n",
      "step 1059 from 6577 at epoch 1\n",
      "Loss: 0.6097384095191956\n",
      "step 1069 from 6577 at epoch 1\n",
      "Loss: 0.9912259578704834\n",
      "step 1079 from 6577 at epoch 1\n",
      "Loss: 0.8544018268585205\n",
      "step 1089 from 6577 at epoch 1\n",
      "Loss: 0.970928430557251\n",
      "step 1099 from 6577 at epoch 1\n",
      "Loss: 0.8492394089698792\n",
      "step 1109 from 6577 at epoch 1\n",
      "Loss: 0.7338082194328308\n",
      "step 1119 from 6577 at epoch 1\n",
      "Loss: 0.5666649341583252\n",
      "step 1129 from 6577 at epoch 1\n",
      "Loss: 0.7879128456115723\n",
      "step 1139 from 6577 at epoch 1\n",
      "Loss: 0.8718876242637634\n",
      "step 1149 from 6577 at epoch 1\n",
      "Loss: 0.7855916619300842\n",
      "step 1159 from 6577 at epoch 1\n",
      "Loss: 0.5807862281799316\n",
      "step 1169 from 6577 at epoch 1\n",
      "Loss: 0.7993359565734863\n",
      "step 1179 from 6577 at epoch 1\n",
      "Loss: 1.0130647420883179\n",
      "step 1189 from 6577 at epoch 1\n",
      "Loss: 0.8884141445159912\n",
      "step 1199 from 6577 at epoch 1\n",
      "Loss: 0.9318559169769287\n",
      "step 1209 from 6577 at epoch 1\n",
      "Loss: 0.840174674987793\n",
      "step 1219 from 6577 at epoch 1\n",
      "Loss: 0.8625968098640442\n",
      "step 1229 from 6577 at epoch 1\n",
      "Loss: 0.8920198678970337\n",
      "step 1239 from 6577 at epoch 1\n",
      "Loss: 0.6501760482788086\n",
      "step 1249 from 6577 at epoch 1\n",
      "Loss: 0.8789077997207642\n",
      "step 1259 from 6577 at epoch 1\n",
      "Loss: 0.8453664779663086\n",
      "step 1269 from 6577 at epoch 1\n",
      "Loss: 0.7226729393005371\n",
      "step 1279 from 6577 at epoch 1\n",
      "Loss: 1.0131300687789917\n",
      "step 1289 from 6577 at epoch 1\n",
      "Loss: 0.9749851822853088\n",
      "step 1299 from 6577 at epoch 1\n",
      "Loss: 0.8727136254310608\n",
      "step 1309 from 6577 at epoch 1\n",
      "Loss: 0.7408285140991211\n",
      "step 1319 from 6577 at epoch 1\n",
      "Loss: 0.7262444496154785\n",
      "step 1329 from 6577 at epoch 1\n",
      "Loss: 0.904385507106781\n",
      "step 1339 from 6577 at epoch 1\n",
      "Loss: 0.5783645510673523\n",
      "step 1349 from 6577 at epoch 1\n",
      "Loss: 0.6869222521781921\n",
      "step 1359 from 6577 at epoch 1\n",
      "Loss: 0.7625437378883362\n",
      "step 1369 from 6577 at epoch 1\n",
      "Loss: 0.8628395795822144\n",
      "step 1379 from 6577 at epoch 1\n",
      "Loss: 0.8494946360588074\n",
      "step 1389 from 6577 at epoch 1\n",
      "Loss: 0.787855327129364\n",
      "step 1399 from 6577 at epoch 1\n",
      "Loss: 0.7769683599472046\n",
      "step 1409 from 6577 at epoch 1\n",
      "Loss: 0.9685727953910828\n",
      "step 1419 from 6577 at epoch 1\n",
      "Loss: 0.5944059491157532\n",
      "step 1429 from 6577 at epoch 1\n",
      "Loss: 0.7500374913215637\n",
      "step 1439 from 6577 at epoch 1\n",
      "Loss: 0.7252342104911804\n",
      "step 1449 from 6577 at epoch 1\n",
      "Loss: 0.7956187725067139\n",
      "step 1459 from 6577 at epoch 1\n",
      "Loss: 0.754497230052948\n",
      "step 1469 from 6577 at epoch 1\n",
      "Loss: 0.7361962795257568\n",
      "step 1479 from 6577 at epoch 1\n",
      "Loss: 0.6859766244888306\n",
      "step 1489 from 6577 at epoch 1\n",
      "Loss: 0.9259615540504456\n",
      "step 1499 from 6577 at epoch 1\n",
      "Loss: 0.7867316007614136\n",
      "step 1509 from 6577 at epoch 1\n",
      "Loss: 0.8062790036201477\n",
      "step 1519 from 6577 at epoch 1\n",
      "Loss: 0.7366353869438171\n",
      "step 1529 from 6577 at epoch 1\n",
      "Loss: 0.6932045817375183\n",
      "step 1539 from 6577 at epoch 1\n",
      "Loss: 0.8022198677062988\n",
      "step 1549 from 6577 at epoch 1\n",
      "Loss: 0.9271858334541321\n",
      "step 1559 from 6577 at epoch 1\n",
      "Loss: 0.8405780792236328\n",
      "step 1569 from 6577 at epoch 1\n",
      "Loss: 0.7630472779273987\n",
      "step 1579 from 6577 at epoch 1\n",
      "Loss: 0.8506873250007629\n",
      "step 1589 from 6577 at epoch 1\n",
      "Loss: 0.7348117232322693\n",
      "step 1599 from 6577 at epoch 1\n",
      "Loss: 0.7888917326927185\n",
      "step 1609 from 6577 at epoch 1\n",
      "Loss: 1.0297865867614746\n",
      "step 1619 from 6577 at epoch 1\n",
      "Loss: 0.7225844264030457\n",
      "step 1629 from 6577 at epoch 1\n",
      "Loss: 0.7861040830612183\n"
     ]
    }
   ],
   "source": [
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "criterion = criterion.to(device)\n",
    "# timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "print(timestamp)\n",
    "\n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)\n",
    "# %%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id',\n",
    "    \"custom_embedding_type\": \"group+period\"\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))\n",
    "# %%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(1, epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))\n",
    "    path = '_'.join((timestamp, 'epoch', str(i), '.pickle'))\n",
    "    torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d44235-71e8-4270-8f5b-caf34c6de0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../../ocp_airi/airi_utils/checkpoint/2021-10-05-14-40-54_epoch_0_state_dict.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9d99f-2956-4977-91a1-b2033f8ed01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
