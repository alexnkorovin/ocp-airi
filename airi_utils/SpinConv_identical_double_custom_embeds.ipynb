{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0bc839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import MessagePassing, DataParallel\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset, DataListLoader\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e7c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.expanduser('../ocpmodels/models'))\n",
    "sys.path.append(os.path.expanduser('../../ocp-airi'))\n",
    "\n",
    "from spinconv_with_embeds_single import spinconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bb08e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    keys = ['pos', 'atomic_numbers', 'cell', 'natoms']\n",
    "    features_dict = {}\n",
    "    for key in keys:\n",
    "        features_dict[key] = system[key]\n",
    "    return Data(**features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c78a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 70\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['feature_1']\n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e76494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #чтобы тензор по умолчанию заводился на куде\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#     print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136e247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf51cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/all/train/data.lmdb\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "training_generator = DataListLoader(training_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc56aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/all/val_ood_both/data.lmdb\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataListLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ca58f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 460328\n",
      "info for item: 0\n",
      "edge_index:...............<class 'torch.Tensor'>..... [2, 2964]\n",
      "pos:......................<class 'torch.Tensor'>.....   [86, 3]\n",
      "cell:.....................<class 'torch.Tensor'>..... [1, 3, 3]\n",
      "atomic_numbers:...........<class 'torch.Tensor'>.....      [86]\n",
      "natoms:...................       <class 'int'>.....        86\n",
      "cell_offsets:.............<class 'torch.Tensor'>..... [2964, 3]\n",
      "force:....................<class 'torch.Tensor'>.....   [86, 3]\n",
      "distances:................<class 'torch.Tensor'>.....    [2964]\n",
      "fixed:....................<class 'torch.Tensor'>.....      [86]\n",
      "sid:......................       <class 'int'>.....   2472718\n",
      "tags:.....................<class 'torch.Tensor'>.....      [86]\n",
      "y_init:...................     <class 'float'>.....    6.2825\n",
      "y_relaxed:................     <class 'float'>.....   -0.0256\n",
      "pos_relaxed:..............<class 'torch.Tensor'>.....   [86, 3]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4083e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #model\n",
    "# model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, 0)\n",
    "# model = DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "# #optimizer and loss\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "# criterion = nn.L1Loss()\n",
    "\n",
    "# #переносим на куду если она есть\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "552e9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05-14-40-50\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70fdea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = \"../../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e50b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no graph\n",
      "CPU times: user 250 µs, sys: 56 µs, total: 306 µs\n",
      "Wall time: 250 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id'\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42982a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2021-09-22-19-37-27\u001b[0m/  \u001b[01;34m2021-09-23-14-29-22\u001b[0m/  \u001b[01;34m2021-09-24-16-50-37\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-19-38-48\u001b[0m/  \u001b[01;34m2021-09-23-14-29-49\u001b[0m/  \u001b[01;34m2021-09-24-16-51-56\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-19-42-58\u001b[0m/  \u001b[01;34m2021-09-23-14-41-34\u001b[0m/  \u001b[01;34m2021-09-24-16-55-06\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-19-44-54\u001b[0m/  \u001b[01;34m2021-09-23-14-50-43\u001b[0m/  \u001b[01;34m2021-09-24-16-56-28\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-19-45-56\u001b[0m/  \u001b[01;34m2021-09-23-15-32-41\u001b[0m/  \u001b[01;34m2021-09-24-16-57-11\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-20-33-00\u001b[0m/  \u001b[01;34m2021-09-23-19-37-50\u001b[0m/  \u001b[01;34m2021-09-24-17-07-45\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-22-21-05-04\u001b[0m/  \u001b[01;34m2021-09-23-20-00-39\u001b[0m/  \u001b[01;34m2021-09-24-17-12-50\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-08-30-01\u001b[0m/  \u001b[01;34m2021-09-24-16-10-40\u001b[0m/  \u001b[01;34m2021-09-24-17-13-20\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-08-31-39\u001b[0m/  \u001b[01;34m2021-09-24-16-16-35\u001b[0m/  \u001b[01;34m2021-09-24-17-14-59\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-08-41-24\u001b[0m/  \u001b[01;34m2021-09-24-16-17-49\u001b[0m/  \u001b[01;34m2021-09-24-17-15-37\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-08-42-59\u001b[0m/  \u001b[01;34m2021-09-24-16-20-07\u001b[0m/  \u001b[01;34m2021-09-24-17-16-24\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-08-45-46\u001b[0m/  \u001b[01;34m2021-09-24-16-31-00\u001b[0m/  \u001b[01;34m2021-09-24-17-17-14\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-09-17-46\u001b[0m/  \u001b[01;34m2021-09-24-16-32-08\u001b[0m/  \u001b[01;34m2021-09-24-17-17-52\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-09-21-18\u001b[0m/  \u001b[01;34m2021-09-24-16-37-58\u001b[0m/  \u001b[01;34m2021-09-24-17-18-19\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-10-06-16\u001b[0m/  \u001b[01;34m2021-09-24-16-39-20\u001b[0m/  \u001b[01;34m2021-09-24-17-19-54\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-10-07-02\u001b[0m/  \u001b[01;34m2021-09-24-16-39-45\u001b[0m/  \u001b[01;34m2021-09-25-11-15-39\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-10-09-32\u001b[0m/  \u001b[01;34m2021-09-24-16-42-06\u001b[0m/  \u001b[01;34m2021-09-25-11-23-25\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-10-10-45\u001b[0m/  \u001b[01;34m2021-09-24-16-43-27\u001b[0m/  \u001b[01;34m2021-10-05-11-13-58\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-12-01-22\u001b[0m/  \u001b[01;34m2021-09-24-16-44-06\u001b[0m/  \u001b[01;34m2021-10-05-11-32-20\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-12-02-47\u001b[0m/  \u001b[01;34m2021-09-24-16-45-28\u001b[0m/  \u001b[01;34m2021-10-05-12-49-13\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-12-03-34\u001b[0m/  \u001b[01;34m2021-09-24-16-46-19\u001b[0m/  \u001b[01;34m2021-10-05-12-54-32\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-12-51-47\u001b[0m/  \u001b[01;34m2021-09-24-16-47-05\u001b[0m/  \u001b[01;34m2021-10-05-14-03-10\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-12-54-38\u001b[0m/  \u001b[01;34m2021-09-24-16-48-11\u001b[0m/  \u001b[01;34m2021-10-05-14-36-33\u001b[0m/\r\n",
      "\u001b[01;34m2021-09-23-14-10-05\u001b[0m/  \u001b[01;34m2021-09-24-16-49-28\u001b[0m/  \u001b[01;34m2021-10-05-14-39-52\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../logs/tensorboard_airi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba0e5fa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92657ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# loss = []\n",
    "# loss_eval = []\n",
    "\n",
    "# print(timestamp)\n",
    "# print(f'Start training model {str(model)}')\n",
    "# for i in range(epochs):\n",
    "#     loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "#     loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "message tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "2021-10-05-14-40-54\n",
      "no graph\n",
      "2021-10-05-14-40-54\n",
      "Start training model DataParallel(\n",
      "  (module): spinconv(\n",
      "    (act): Swish()\n",
      "    (distance_expansion_forces): GaussianSmearing()\n",
      "    (embeddingblock2): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (dist_block): DistanceBlock(\n",
      "      (distance_expansion): GaussianSmearing()\n",
      "      (dist_scalar): Embedding(8100, 1)\n",
      "      (dist_offset): Embedding(8100, 1)\n",
      "      (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    )\n",
      "    (message_blocks): ModuleList(\n",
      "      (0): MessageBlock(\n",
      "        (act): Swish()\n",
      "        (spinconvblock): SpinConvBlock(\n",
      "          (act): Swish()\n",
      "          (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "          (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "          (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "          (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (embeddingblock1): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (embeddingblock2): EmbeddingBlock(\n",
      "          (act): Swish()\n",
      "          (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "          (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "          (fc3): Linear(in_features=200, out_features=32, bias=True)\n",
      "          (source_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (target_embedding): CustomEmbedding(\n",
      "            (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "          )\n",
      "          (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "          (softmax): Softmax(dim=1)\n",
      "        )\n",
      "        (distfc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (distfc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (energyembeddingblock): EmbeddingBlock(\n",
      "      (act): Swish()\n",
      "      (fc1): Linear(in_features=32, out_features=200, bias=True)\n",
      "      (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "      (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "      (source_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (target_embedding): CustomEmbedding(\n",
      "        (EmbeddingLayer): Linear(in_features=127, out_features=32, bias=True)\n",
      "      )\n",
      "      (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "      (softmax): Softmax(dim=1)\n",
      "    )\n",
      "    (force_output_block): ForceOutputBlock(\n",
      "      (act): Swish()\n",
      "      (spinconvblock): SpinConvBlock(\n",
      "        (act): Swish()\n",
      "        (ProjectLatLongSphere): ProjectLatLongSphere()\n",
      "        (conv1): Conv1d(480, 200, kernel_size=(9,), stride=(1,), padding=(4,), groups=4, padding_mode=circular)\n",
      "        (pool): AvgPool1d(kernel_size=(9,), stride=(9,), padding=(0,))\n",
      "        (GroupNorm): GroupNorm(4, 200, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (block1): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "      (block2): EmbeddingBlock(\n",
      "        (act): Swish()\n",
      "        (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
      "        (fc2): Linear(in_features=200, out_features=1600, bias=True)\n",
      "        (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
      "        (source_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (target_embedding): CustomEmbedding(\n",
      "          (EmbeddingLayer): Linear(in_features=101, out_features=32, bias=True)\n",
      "        )\n",
      "        (embed_fc1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (softmax): Softmax(dim=1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch 0\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO Bootstrap : Using [0]eth0:10.233.122.86<0>\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO NET/IB : No device found.\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO NET/Socket : Using [0]eth0:10.233.122.86<0>\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.7.8+cuda10.2\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Trees [0] -1/-1/-1->1->0|0->1->-1/-1/-1 [1] -1/-1/-1->1->0|0->1->-1/-1/-1 [2] -1/-1/-1->1->0|0->1->-1/-1/-1 [3] 0/-1/-1->1->-1|-1->1->0/-1/-1 [4] 0/-1/-1->1->-1|-1->1->0/-1/-1 [5] 0/-1/-1->1->-1|-1->1->0/-1/-1 [6] -1/-1/-1->1->0|0->1->-1/-1/-1 [7] -1/-1/-1->1->0|0->1->-1/-1/-1 [8] -1/-1/-1->1->0|0->1->-1/-1/-1 [9] 0/-1/-1->1->-1|-1->1->0/-1/-1 [10] 0/-1/-1->1->-1|-1->1->0/-1/-1 [11] 0/-1/-1->1->-1|-1->1->0/-1/-1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 00/12 :    0   1\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Setting affinity for GPU 1 to ffffff00,0000ffff,ff000000\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 01/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 02/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 03/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 04/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 05/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 06/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 07/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 08/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 09/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 10/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 11/12 :    0   1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 8/8/64\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1|-1->0->1/-1/-1 [1] 1/-1/-1->0->-1|-1->0->1/-1/-1 [2] 1/-1/-1->0->-1|-1->0->1/-1/-1 [3] -1/-1/-1->0->1|1->0->-1/-1/-1 [4] -1/-1/-1->0->1|1->0->-1/-1/-1 [5] -1/-1/-1->0->1|1->0->-1/-1/-1 [6] 1/-1/-1->0->-1|-1->0->1/-1/-1 [7] 1/-1/-1->0->-1|-1->0->1/-1/-1 [8] 1/-1/-1->0->-1|-1->0->1/-1/-1 [9] -1/-1/-1->0->1|1->0->-1/-1/-1 [10] -1/-1/-1->0->1|1->0->-1/-1/-1 [11] -1/-1/-1->0->1|1->0->-1/-1/-1\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffff0000,00ffffff\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 00 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 00 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 01 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 01 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 02 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 02 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 03 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 03 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 04 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 04 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 05 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 05 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 06 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 06 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 07 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 07 : 0[57000] -> 1[bc000] via P2P/direct pointer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 08 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 08 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 09 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 09 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 10 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 10 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO Channel 11 : 1[bc000] -> 0[57000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO Channel 11 : 0[57000] -> 1[bc000] via P2P/direct pointer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO 12 coll channels, 16 p2p channels, 16 p2p channels per peer\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO 12 coll channels, 16 p2p channels, 16 p2p channels per peer\n",
      "ml-test-server-0:24777:24799 [1] NCCL INFO comm 0x7fb5d4001060 rank 1 nranks 2 cudaDev 1 busId bc000 - Init COMPLETE\n",
      "ml-test-server-0:24777:24798 [0] NCCL INFO comm 0x7fb5d0001060 rank 0 nranks 2 cudaDev 0 busId 57000 - Init COMPLETE\n",
      "ml-test-server-0:24777:24777 [0] NCCL INFO Launch mode Group/CGMD\n",
      "step 9 from 6577 at epoch 0\n",
      "Loss: 1.8129243850708008\n",
      "step 19 from 6577 at epoch 0\n",
      "Loss: 1.6205222606658936\n",
      "step 29 from 6577 at epoch 0\n",
      "Loss: 1.5626109838485718\n",
      "step 39 from 6577 at epoch 0\n",
      "Loss: 1.679938793182373\n",
      "step 49 from 6577 at epoch 0\n",
      "Loss: 1.9696968793869019\n",
      "step 59 from 6577 at epoch 0\n",
      "Loss: 1.8589293956756592\n",
      "step 69 from 6577 at epoch 0\n",
      "Loss: 1.2947207689285278\n",
      "step 79 from 6577 at epoch 0\n",
      "Loss: 1.3329716920852661\n",
      "step 89 from 6577 at epoch 0\n",
      "Loss: 1.7006053924560547\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_discr = {\"group_onehot\" : list(range(18)),\n",
    "               \"period_onehot\": list(range(19, 27)),\n",
    "               \"block_onehot\" : list(range(28, 32)),\n",
    "               \"electronegativity\" : 33,\n",
    "               \"radius\" : 34,\n",
    "               \"valence\" : 35,\n",
    "               \"ionization\" : 36,\n",
    "               \"affinity\" : 37,\n",
    "               \"volume\": 38\n",
    "              }\n",
    "\n",
    "\n",
    "#model\n",
    "model = spinconv(None, None, 1, otf_graph=True, regress_forces=False, custom_embedding_value=torch.tensor(list(range(27))))\n",
    "model = DataParallel(model)\n",
    "model = model.to(device)\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "criterion = criterion.to(device)\n",
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)\n",
    "\n",
    "log_file_path = \"../logs/tensorboard_airi\"\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)\n",
    "# %%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"type\":'id',\n",
    "    \"custom_embedding_type\": \"group+period\"\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "try:\n",
    "    #trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "    writer.add_graph(model, trace_system)\n",
    "except:\n",
    "    print('no graph')\n",
    "writer.add_text(timestamp, str(logfile_str))\n",
    "# %%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))\n",
    "    path = '_'.join((timestamp, 'epoch', str(i), '.pickle'))\n",
    "    torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da910c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, valid_generator, criterion, epoch=i, writer=writer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7515a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp_models",
   "language": "python",
   "name": "ocp_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
