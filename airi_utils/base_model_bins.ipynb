{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d618c1-7bd7-4b54-b5c6-cd8fab531f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataClasses import lmdb_dataset, Dataset\n",
    "from ModelFunctions import train, evaluate, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8705ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b083eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_reshape(tensor):\n",
    "    return torch.reshape(tensor, (tensor.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82f4bae-3d55-42ec-a1b6-0b40219dac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_angles(array):\n",
    "    array[:, 1] = np.pi - array[:, 1]\n",
    "    array[:, 3] = - array[:, 3]\n",
    "    return array\n",
    "\n",
    "def restore_edge_angles(list_of_arrays):\n",
    "    el_new = []\n",
    "    for el in list_of_arrays:\n",
    "        el_new.append(el)\n",
    "        el_new.append(convert_angles(el.copy()))        \n",
    "    return el_new       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d3f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns=('edge_id', 'edge_theta', 'z', 'phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_offset(offset):\n",
    "    code = {-1 : 1, 0 : 2, 1 : 3}\n",
    "    coded = 0\n",
    "    for i, el in enumerate(offset):\n",
    "        coded += (10**i)*code[el.item()]\n",
    "    return coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cdd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bins_torch_constrains(system,\n",
    "                            direct_neighbors_only=True, dist_threshold=5):\n",
    "    \n",
    "    keys_to_mask = ['cell_offsets_new', 'contact_solid_angles', 'distances_new', 'direct_neighbor']\n",
    "    array_of_dfs = restore_edge_angles(system['edge_angles'])\n",
    "    end_points = system['edge_index_new'][1]\n",
    "    original_offsets = system['cell_offsets_new']\n",
    "    filtered_id = np.array(range(len(array_of_dfs)))\n",
    "    \n",
    "    if direct_neighbors_only :\n",
    "        mask_dn = (system['direct_neighbor'] == 1)\n",
    "    else:\n",
    "        mask_dn = torch.ones((len(array_of_dfs),), dtype=torch.bool)\n",
    "    \n",
    "    if dist_threshold != None :\n",
    "        mask_dt = (system['distances_new'] < dist_threshold)\n",
    "    else:\n",
    "        mask_dt = torch.ones((len(array_of_dfs),), dtype=torch.bool)\n",
    "\n",
    "    mask = mask_dn*mask_dt\n",
    "    \n",
    "    for key in keys_to_mask:\n",
    "        system[key] = system[key][mask]\n",
    "    array_of_dfs = [array_of_dfs[i] for i in range(len(array_of_dfs)) if mask[i]]\n",
    "    system['edge_index_new'] = ((system['edge_index_new'].T)[mask]).T\n",
    "    filtered_id = filtered_id[mask]\n",
    "    original_offsets = original_offsets[mask]\n",
    "    end_points = end_points[mask]\n",
    "    \n",
    "    thetas = []\n",
    "\n",
    "    for df in array_of_dfs:\n",
    "        df_index = df[:, 0]\n",
    "        df_index_filt = np.isin(filtered_id, df_index)\n",
    "        df_index_filt_for_df = np.isin(df_index, filtered_id)\n",
    "        df = df[df_index_filt_for_df]\n",
    "        end_point = end_points[df_index_filt]\n",
    "        end_point = end_point.reshape((len(end_point), 1))\n",
    "        coded_offsets = list(map(code_offset, original_offsets[df_index_filt]))\n",
    "        cell_offsets = np.array(coded_offsets)\n",
    "        cell_offsets = cell_offsets.reshape((len(coded_offsets), 1))\n",
    "        end_offcet = np.concatenate((end_point, cell_offsets), axis=1)\n",
    "        _, indices = np.unique(end_offcet, return_index=True, axis=0)\n",
    "        theta = torch.tensor(df[:, 1][indices])#.to('cpu')\n",
    "        theta = torch.histc(theta, bins=10, min=0, max=np.pi)\n",
    "        theta = torch.reshape(theta, (1, theta.shape[0]))\n",
    "        thetas.append(theta)\n",
    "        \n",
    "    thetas = torch.cat(thetas, 0).float()\n",
    "    \n",
    "#     return_dict = {'edge_index_new_f' : edge_index, 'cell_offsets_new_f' : cell_offsets ,\n",
    "#                 'distances_new_f' : distances ,'direct_neighbor_f' : direct_neighbors ,\n",
    "#                 'contact_solid_angles_f' : contact_solid_angles ,\n",
    "#                 'thetas' : thetas.float()}\n",
    "    \n",
    "#     for key in return_dict:\n",
    "#         system[key] = eturn_dict[key]\n",
    "#     print(thetas.shape)\n",
    "#     print(thetas)\n",
    "\n",
    "    system['thetas'] = thetas\n",
    "    \n",
    "    return system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643edca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вызывается каждый раз, когда датасет отдаёт элемент (систему)\n",
    "#делаем из данных матрицу векторов-атомов, список рёбер (edge_index) и матрицу векторов-рёбер; надо писать свою функцию для каждой сети\n",
    "def preprocessing(system):\n",
    "    \n",
    "    system = to_bins_torch_constrains(system)\n",
    "        \n",
    "    tags = system['tags'].long()\n",
    "    tags = F.one_hot(tags, num_classes=3)\n",
    "    \n",
    "    atom_numbers = system['atomic_numbers'].long()\n",
    "    atom_numbers = F.one_hot(atom_numbers, num_classes=100)\n",
    "    \n",
    "    voronoi_volumes = system['voronoi_volumes'].float()\n",
    "    voronoi_volumes = my_reshape(voronoi_volumes)\n",
    "    \n",
    "    atom_features = (tags, atom_numbers, voronoi_volumes)#, spherical_radii)\n",
    "    atom_embeds = torch.cat(atom_features, 1)\n",
    "    \n",
    "    edge_index = system['edge_index_new'].long()\n",
    "    \n",
    "    distances = system['distances_new'].float()\n",
    "    distances = my_reshape(distances)\n",
    "    \n",
    "    \n",
    "    thetas = system['thetas']\n",
    "#     angles = system['contact_solid_angles'].float().to(device)\n",
    "#     angles = my_reshape(angles)\n",
    "\n",
    "    edge_features = (distances, thetas)\n",
    "    \n",
    "    edges_embeds = torch.cat(edge_features, 1)\n",
    "    \n",
    "    \n",
    "    return Data(x=atom_embeds.to(device), edge_index=edge_index.to(device), edge_attr=edges_embeds.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8f958",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}_i^{(k)} = \\gamma^{(k)} \\left( \\mathbf{x}_i^{(k-1)}, \\square_{j \\in \\mathcal{N}(i)} \\, \\phi^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{j,i}\\right) \\right)\n",
    "$$\n",
    "\n",
    "Гамма лежит в апдейт, квадратик в aggr, а фи в месседж; в этом примере квадратик -- суммирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae848d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GConv(MessagePassing):\n",
    "    def __init__(self, dim_atom=104, dim_edge=11, out_channels=2):\n",
    "        super(GConv, self).__init__(aggr='add')  # \"Add\" aggregation\n",
    "        self.phi_output = 3\n",
    "        self.lin_phi = torch.nn.Linear(dim_atom*2+dim_edge, self.phi_output, bias=False)\n",
    "        self.lin_gamma = torch.nn.Linear(dim_atom + self.phi_output, out_channels, bias=False)\n",
    "        self.nonlin = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['x']\n",
    "        edge_index = batch['edge_index']\n",
    "        edge_attr = batch['edge_attr']\n",
    "        \n",
    "        # x has shape [N -- количество атомов в системе(батче), in_channels -- размерность вектора-атома]\n",
    "        # edge_index has shape [2, E] -- каждое ребро задаётся парой вершин\n",
    "\n",
    "        # Start propagating messages. \n",
    "    \n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr, size=None)\n",
    "\n",
    "    def message(self, x, x_i, x_j, edge_attr):\n",
    "        concatenated = torch.cat((x_i, x_j, edge_attr), 1)\n",
    "        phi = self.lin_phi(concatenated)\n",
    "        phi = self.nonlin(phi)\n",
    "        return phi\n",
    "        \n",
    "    def update(self, aggr_out, x, edge_attr, edge_index):\n",
    "                \n",
    "        concatenated = torch.cat((x, aggr_out), 1)\n",
    "        gamma = self.lin_gamma(concatenated)\n",
    "        gamma = self.nonlin(gamma)\n",
    "\n",
    "        return Data(x=gamma, edge_attr=edge_attr, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1232c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_atom=104, dim_edge=1):\n",
    "        \n",
    "        super().__init__()          \n",
    "        self.conv_last = GConv(dim_atom=dim_atom, dim_edge=dim_edge, out_channels=2)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(2, 1, bias=True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        convoluted_last = self.conv_last(batch)['x']\n",
    "        scattered = scatter(convoluted_last, batch['batch'], dim=0, reduce='sum')\n",
    "        summed = scattered\n",
    "        energy = self.lin(summed)\n",
    "        \n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690ec366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "batch_size = 50\n",
    "num_workers = 0\n",
    "\n",
    "features_cols = ['atomic_numbers', 'edge_index_new', 'distances_new', \n",
    "                 'contact_solid_angles', 'tags', 'voronoi_volumes', 'edge_angles'] #он не нужен \n",
    "\n",
    "target_col = 'y_relaxed'\n",
    "lr = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6e2796c-4bf3-4698-a99e-7059dd1f93d3",
   "metadata": {},
   "source": [
    "#чтобы тензор по умолчанию заводился на куде\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d2b308d-ffa4-4f48-adab-e218d7da0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a58334d-3330-4cae-ae42-39f067667787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_addr': 0, 'map_size': 3100106752, 'last_pgno': 756861, 'last_txnid': 10000, 'max_readers': 1000, 'num_readers': 0}\n"
     ]
    }
   ],
   "source": [
    "#инициализируем тренировочный датасети и тренировочный итератор\n",
    "train_dataset_file_path= os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data_mod2.lmdbz\")\n",
    "\n",
    "training_set = Dataset(train_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7305d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 404 ms, sys: 5.94 ms, total: 410 ms\n",
      "Wall time: 410 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Data(edge_attr=[912, 11], edge_index=[2, 912], x=[86, 104]),\n",
       " -0.025550085000020317)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce747097-e5fd-4c36-b033-a8e6f2f122bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataLoader(training_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae852e60-b1ac-4a48-8120-af94ecec6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_addr': 0, 'map_size': 3100106752, 'last_pgno': 756861, 'last_txnid': 10000, 'max_readers': 1000, 'num_readers': 0}\n"
     ]
    }
   ],
   "source": [
    "#инициализируем валидационный датасет и валидационный итератор\n",
    "val_dataset_file_path = os.path.expanduser(\"../../ocp_datasets/data/is2re/10k/train/data_mod2.lmdbz\")\n",
    "\n",
    "valid_set = Dataset(val_dataset_file_path, features_cols, target_col, preprocessing=preprocessing)\n",
    "valid_generator = DataLoader(valid_set, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f64a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map_addr': 0, 'map_size': 3100106752, 'last_pgno': 756861, 'last_txnid': 10000, 'max_readers': 1000, 'num_readers': 0}\n",
      "item: 0\n",
      "atomic_numbers:...........      [86]\n",
      "cell:..................... [1, 3, 3]\n",
      "cell_offsets:............. [2964, 3]\n",
      "cell_offsets_new:......... [1214, 3]\n",
      "contact_solid_angles:.....    [1214]\n",
      "direct_neighbor:..........    [1214]\n",
      "distances:................    [2964]\n",
      "distances_new:............    [1214]\n",
      "edge_angles:..............       607\n",
      "edge_index:............... [2, 2964]\n",
      "edge_index_new:........... [2, 1214]\n",
      "fixed:....................      [86]\n",
      "force:....................   [86, 3]\n",
      "natoms:...................        86\n",
      "pos:......................   [86, 3]\n",
      "pos_relaxed:..............   [86, 3]\n",
      "sid:......................   2472718\n",
      "spherical_domain_radii:...      [86]\n",
      "tags:.....................      [86]\n",
      "voronoi_surface_areas:....      [86]\n",
      "voronoi_volumes:..........      [86]\n",
      "y_init:...................    6.2825\n",
      "y_relaxed:................   -0.0256\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lmdb_dataset(train_dataset_file_path).describe()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93e4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = ConvNN(dim_atom=training_set[0][0]['x'].shape[1], dim_edge=training_set[0][0]['edge_attr'].shape[1])\n",
    "\n",
    "#optimizer and loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "#переносим на куду если она есть\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc1c0ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21-09-44-05\n"
     ]
    }
   ],
   "source": [
    "timestamp = str(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1cbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard writer, при первом запуске надо руками сделать папку для логов\n",
    "\n",
    "# server\n",
    "#log_folder_path = \"../../ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# colab\n",
    "# log_folder_path = \"/content/drive/MyDrive/ocp_results/logs/tensorboard/out_base_model\"\n",
    "\n",
    "# user_specific \n",
    "log_file_path = os.path.expanduser(\"~/Documents/ocp_datasets_hd/logs/tensorboard_airi\")\n",
    "\n",
    "writer = SummaryWriter(log_file_path + '/' + timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e477b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 165 ms, total: 19.1 s\n",
      "Wall time: 19.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logfile_str = {\n",
    "    \"train_dataset_file_path\": train_dataset_file_path,\n",
    "    \"val_dataset_file_path\": val_dataset_file_path,\n",
    "    \"features_cols\": features_cols,\n",
    "    \"target_col\": target_col,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr\n",
    "}\n",
    "\n",
    "#граф модели\n",
    "trace_system = dict(list(next(iter(training_generator))[0]))\n",
    "writer.add_graph(model, trace_system)\n",
    "writer.add_text(timestamp, str(logfile_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca95f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6c6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-21-09-44-05\n",
      "Start training model ConvNN(\n",
      "  (conv_last): GConv(\n",
      "    (lin_phi): Linear(in_features=219, out_features=3, bias=False)\n",
      "    (lin_gamma): Linear(in_features=107, out_features=2, bias=False)\n",
      "    (nonlin): Sigmoid()\n",
      "  )\n",
      "  (lin): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "epoch 0\n",
      "step 9 from 200 at epoch 0\n",
      "Loss: 10.266322135925293\n",
      "step 19 from 200 at epoch 0\n",
      "Loss: 7.874365329742432\n",
      "step 29 from 200 at epoch 0\n",
      "Loss: 5.131788730621338\n",
      "step 39 from 200 at epoch 0\n",
      "Loss: 3.2307043075561523\n",
      "step 49 from 200 at epoch 0\n",
      "Loss: 4.056908130645752\n",
      "step 59 from 200 at epoch 0\n",
      "Loss: 3.464606285095215\n",
      "step 69 from 200 at epoch 0\n",
      "Loss: 3.419398784637451\n",
      "step 79 from 200 at epoch 0\n",
      "Loss: 2.598348617553711\n",
      "step 89 from 200 at epoch 0\n",
      "Loss: 2.5404152870178223\n",
      "step 99 from 200 at epoch 0\n",
      "Loss: 2.9040415287017822\n",
      "step 109 from 200 at epoch 0\n",
      "Loss: 2.7117984294891357\n",
      "step 119 from 200 at epoch 0\n",
      "Loss: 2.867483139038086\n",
      "step 129 from 200 at epoch 0\n",
      "Loss: 2.0879173278808594\n",
      "step 139 from 200 at epoch 0\n",
      "Loss: 2.5167815685272217\n",
      "step 149 from 200 at epoch 0\n",
      "Loss: 2.3340041637420654\n",
      "step 159 from 200 at epoch 0\n",
      "Loss: 2.7365710735321045\n",
      "step 169 from 200 at epoch 0\n",
      "Loss: 2.1512818336486816\n",
      "step 179 from 200 at epoch 0\n",
      "Loss: 2.366212844848633\n",
      "step 189 from 200 at epoch 0\n",
      "Loss: 2.186237096786499\n",
      "step 199 from 200 at epoch 0\n",
      "Loss: 2.962153673171997\n",
      "epoch 0 evaluation\n",
      "epoch loss 2.3048397833108902\n",
      "========================================================================================================\n",
      "epoch 1\n",
      "step 9 from 200 at epoch 1\n",
      "Loss: 2.1369473934173584\n",
      "step 19 from 200 at epoch 1\n",
      "Loss: 2.3645999431610107\n",
      "step 29 from 200 at epoch 1\n",
      "Loss: 2.038254737854004\n",
      "step 39 from 200 at epoch 1\n",
      "Loss: 1.912168264389038\n",
      "step 49 from 200 at epoch 1\n",
      "Loss: 2.176036834716797\n",
      "step 59 from 200 at epoch 1\n",
      "Loss: 2.3339672088623047\n",
      "step 69 from 200 at epoch 1\n",
      "Loss: 2.557192802429199\n",
      "step 79 from 200 at epoch 1\n",
      "Loss: 1.8173004388809204\n",
      "step 89 from 200 at epoch 1\n",
      "Loss: 2.005060911178589\n",
      "step 99 from 200 at epoch 1\n",
      "Loss: 2.3970067501068115\n",
      "step 109 from 200 at epoch 1\n",
      "Loss: 2.2177045345306396\n",
      "step 119 from 200 at epoch 1\n",
      "Loss: 2.184363842010498\n",
      "step 129 from 200 at epoch 1\n",
      "Loss: 1.7119247913360596\n",
      "step 139 from 200 at epoch 1\n",
      "Loss: 2.1594088077545166\n",
      "step 149 from 200 at epoch 1\n",
      "Loss: 2.051147222518921\n",
      "step 159 from 200 at epoch 1\n",
      "Loss: 2.327226400375366\n",
      "step 169 from 200 at epoch 1\n",
      "Loss: 1.8913660049438477\n",
      "step 179 from 200 at epoch 1\n",
      "Loss: 2.0937530994415283\n",
      "step 189 from 200 at epoch 1\n",
      "Loss: 1.7998826503753662\n",
      "step 199 from 200 at epoch 1\n",
      "Loss: 2.6025521755218506\n",
      "epoch 1 evaluation\n",
      "epoch loss 2.0513584101200104\n",
      "========================================================================================================\n",
      "epoch 2\n",
      "step 9 from 200 at epoch 2\n",
      "Loss: 1.957735300064087\n",
      "step 19 from 200 at epoch 2\n",
      "Loss: 2.134143352508545\n",
      "step 29 from 200 at epoch 2\n",
      "Loss: 1.8563125133514404\n",
      "step 39 from 200 at epoch 2\n",
      "Loss: 1.7709524631500244\n",
      "step 49 from 200 at epoch 2\n",
      "Loss: 1.9219609498977661\n",
      "step 59 from 200 at epoch 2\n",
      "Loss: 2.166292905807495\n",
      "step 69 from 200 at epoch 2\n",
      "Loss: 2.3908305168151855\n",
      "step 79 from 200 at epoch 2\n",
      "Loss: 1.6579391956329346\n",
      "step 89 from 200 at epoch 2\n",
      "Loss: 1.8774229288101196\n",
      "step 99 from 200 at epoch 2\n",
      "Loss: 2.2691171169281006\n",
      "step 109 from 200 at epoch 2\n",
      "Loss: 2.0567238330841064\n",
      "step 119 from 200 at epoch 2\n",
      "Loss: 1.9866584539413452\n",
      "step 129 from 200 at epoch 2\n",
      "Loss: 1.6362276077270508\n",
      "step 139 from 200 at epoch 2\n",
      "Loss: 2.0649569034576416\n",
      "step 149 from 200 at epoch 2\n",
      "Loss: 1.9643670320510864\n",
      "step 159 from 200 at epoch 2\n",
      "Loss: 2.166365623474121\n",
      "step 169 from 200 at epoch 2\n",
      "Loss: 1.7794348001480103\n",
      "step 179 from 200 at epoch 2\n",
      "Loss: 1.9809539318084717\n",
      "step 189 from 200 at epoch 2\n",
      "Loss: 1.681103229522705\n",
      "step 199 from 200 at epoch 2\n",
      "Loss: 2.4632413387298584\n",
      "epoch 2 evaluation\n",
      "epoch loss 1.9466730612516403\n",
      "========================================================================================================\n",
      "epoch 3\n",
      "step 9 from 200 at epoch 3\n",
      "Loss: 1.8838129043579102\n",
      "step 19 from 200 at epoch 3\n",
      "Loss: 2.0334856510162354\n",
      "step 29 from 200 at epoch 3\n",
      "Loss: 1.770490288734436\n",
      "step 39 from 200 at epoch 3\n",
      "Loss: 1.7010000944137573\n",
      "step 49 from 200 at epoch 3\n",
      "Loss: 1.7939366102218628\n",
      "step 59 from 200 at epoch 3\n",
      "Loss: 2.0763559341430664\n",
      "step 69 from 200 at epoch 3\n",
      "Loss: 2.302081823348999\n",
      "step 79 from 200 at epoch 3\n",
      "Loss: 1.586592435836792\n",
      "step 89 from 200 at epoch 3\n",
      "Loss: 1.8004486560821533\n",
      "step 99 from 200 at epoch 3\n",
      "Loss: 2.2015492916107178\n",
      "step 109 from 200 at epoch 3\n",
      "Loss: 1.9607664346694946\n",
      "step 119 from 200 at epoch 3\n",
      "Loss: 1.8639956712722778\n",
      "step 129 from 200 at epoch 3\n",
      "Loss: 1.5961679220199585\n",
      "step 139 from 200 at epoch 3\n",
      "Loss: 2.0125977993011475\n",
      "step 149 from 200 at epoch 3\n",
      "Loss: 1.9235408306121826\n",
      "step 159 from 200 at epoch 3\n",
      "Loss: 2.07816219329834\n",
      "step 169 from 200 at epoch 3\n",
      "Loss: 1.7266786098480225\n",
      "step 179 from 200 at epoch 3\n",
      "Loss: 1.9157332181930542\n",
      "step 189 from 200 at epoch 3\n",
      "Loss: 1.6267578601837158\n",
      "step 199 from 200 at epoch 3\n",
      "Loss: 2.371110439300537\n",
      "epoch 3 evaluation\n",
      "epoch loss 1.8833847874403\n",
      "========================================================================================================\n",
      "epoch 4\n",
      "step 9 from 200 at epoch 4\n",
      "Loss: 1.848745584487915\n",
      "step 19 from 200 at epoch 4\n",
      "Loss: 1.9781560897827148\n",
      "step 29 from 200 at epoch 4\n",
      "Loss: 1.725112795829773\n",
      "step 39 from 200 at epoch 4\n",
      "Loss: 1.6606417894363403\n",
      "step 49 from 200 at epoch 4\n",
      "Loss: 1.7300769090652466\n",
      "step 59 from 200 at epoch 4\n",
      "Loss: 2.02091121673584\n",
      "step 69 from 200 at epoch 4\n",
      "Loss: 2.2483787536621094\n",
      "step 79 from 200 at epoch 4\n",
      "Loss: 1.546262264251709\n",
      "step 89 from 200 at epoch 4\n",
      "Loss: 1.7499080896377563\n",
      "step 99 from 200 at epoch 4\n",
      "Loss: 2.1580917835235596\n",
      "step 109 from 200 at epoch 4\n",
      "Loss: 1.8974610567092896\n",
      "step 119 from 200 at epoch 4\n",
      "Loss: 1.770783543586731\n",
      "step 129 from 200 at epoch 4\n",
      "Loss: 1.5723191499710083\n",
      "step 139 from 200 at epoch 4\n",
      "Loss: 1.9775304794311523\n",
      "step 149 from 200 at epoch 4\n",
      "Loss: 1.9001274108886719\n",
      "step 159 from 200 at epoch 4\n",
      "Loss: 2.018792152404785\n",
      "step 169 from 200 at epoch 4\n",
      "Loss: 1.7018251419067383\n",
      "step 179 from 200 at epoch 4\n",
      "Loss: 1.8780096769332886\n",
      "step 189 from 200 at epoch 4\n",
      "Loss: 1.5927672386169434\n",
      "step 199 from 200 at epoch 4\n",
      "Loss: 2.310622215270996\n",
      "epoch 4 evaluation\n",
      "epoch loss 1.8413365107774735\n",
      "========================================================================================================\n",
      "epoch 5\n",
      "step 9 from 200 at epoch 5\n",
      "Loss: 1.8331265449523926\n",
      "step 19 from 200 at epoch 5\n",
      "Loss: 1.9418303966522217\n",
      "step 29 from 200 at epoch 5\n",
      "Loss: 1.691306710243225\n",
      "step 39 from 200 at epoch 5\n",
      "Loss: 1.6286382675170898\n",
      "step 49 from 200 at epoch 5\n",
      "Loss: 1.7175085544586182\n",
      "step 59 from 200 at epoch 5\n",
      "Loss: 1.9776711463928223\n",
      "step 69 from 200 at epoch 5\n",
      "Loss: 2.20361065864563\n",
      "step 79 from 200 at epoch 5\n",
      "Loss: 1.523768663406372\n",
      "step 89 from 200 at epoch 5\n",
      "Loss: 1.712525486946106\n",
      "step 99 from 200 at epoch 5\n",
      "Loss: 2.128533124923706\n",
      "step 109 from 200 at epoch 5\n",
      "Loss: 1.847568154335022\n",
      "step 119 from 200 at epoch 5\n",
      "Loss: 1.6983857154846191\n",
      "step 129 from 200 at epoch 5\n",
      "Loss: 1.5563045740127563\n",
      "step 139 from 200 at epoch 5\n",
      "Loss: 1.9487820863723755\n",
      "step 149 from 200 at epoch 5\n",
      "Loss: 1.8867744207382202\n",
      "step 159 from 200 at epoch 5\n",
      "Loss: 1.9788700342178345\n",
      "step 169 from 200 at epoch 5\n",
      "Loss: 1.6838454008102417\n",
      "step 179 from 200 at epoch 5\n",
      "Loss: 1.8578109741210938\n",
      "step 189 from 200 at epoch 5\n",
      "Loss: 1.5705620050430298\n",
      "step 199 from 200 at epoch 5\n",
      "Loss: 2.2686755657196045\n",
      "epoch 5 evaluation\n",
      "epoch loss 1.8119374704360962\n",
      "========================================================================================================\n",
      "epoch 6\n",
      "step 9 from 200 at epoch 6\n",
      "Loss: 1.8268324136734009\n",
      "step 19 from 200 at epoch 6\n",
      "Loss: 1.9207665920257568\n",
      "step 29 from 200 at epoch 6\n",
      "Loss: 1.6693919897079468\n",
      "step 39 from 200 at epoch 6\n",
      "Loss: 1.6022034883499146\n",
      "step 49 from 200 at epoch 6\n",
      "Loss: 1.7232757806777954\n",
      "step 59 from 200 at epoch 6\n",
      "Loss: 1.94273042678833\n",
      "step 69 from 200 at epoch 6\n",
      "Loss: 2.168978214263916\n",
      "step 79 from 200 at epoch 6\n",
      "Loss: 1.5180363655090332\n",
      "step 89 from 200 at epoch 6\n",
      "Loss: 1.6808358430862427\n",
      "step 99 from 200 at epoch 6\n",
      "Loss: 2.105452299118042\n",
      "step 109 from 200 at epoch 6\n",
      "Loss: 1.8056961297988892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 119 from 200 at epoch 6\n",
      "Loss: 1.63834547996521\n",
      "step 129 from 200 at epoch 6\n",
      "Loss: 1.5524624586105347\n",
      "step 139 from 200 at epoch 6\n",
      "Loss: 1.926957130432129\n",
      "step 149 from 200 at epoch 6\n",
      "Loss: 1.8840402364730835\n",
      "step 159 from 200 at epoch 6\n",
      "Loss: 1.9510635137557983\n",
      "step 169 from 200 at epoch 6\n",
      "Loss: 1.670844554901123\n",
      "step 179 from 200 at epoch 6\n",
      "Loss: 1.844354510307312\n",
      "step 189 from 200 at epoch 6\n",
      "Loss: 1.5567595958709717\n",
      "step 199 from 200 at epoch 6\n",
      "Loss: 2.2366909980773926\n",
      "epoch 6 evaluation\n",
      "epoch loss 1.7911474937200547\n",
      "========================================================================================================\n",
      "epoch 7\n",
      "step 9 from 200 at epoch 7\n",
      "Loss: 1.8231115341186523\n",
      "step 19 from 200 at epoch 7\n",
      "Loss: 1.9057224988937378\n",
      "step 29 from 200 at epoch 7\n",
      "Loss: 1.6549640893936157\n",
      "step 39 from 200 at epoch 7\n",
      "Loss: 1.5873585939407349\n",
      "step 49 from 200 at epoch 7\n",
      "Loss: 1.7342692613601685\n",
      "step 59 from 200 at epoch 7\n",
      "Loss: 1.919680118560791\n",
      "step 69 from 200 at epoch 7\n",
      "Loss: 2.1396350860595703\n",
      "step 79 from 200 at epoch 7\n",
      "Loss: 1.5215580463409424\n",
      "step 89 from 200 at epoch 7\n",
      "Loss: 1.6528897285461426\n",
      "step 99 from 200 at epoch 7\n",
      "Loss: 2.0871856212615967\n",
      "step 109 from 200 at epoch 7\n",
      "Loss: 1.768757939338684\n",
      "step 119 from 200 at epoch 7\n",
      "Loss: 1.5891109704971313\n",
      "step 129 from 200 at epoch 7\n",
      "Loss: 1.5529472827911377\n",
      "step 139 from 200 at epoch 7\n",
      "Loss: 1.9128124713897705\n",
      "step 149 from 200 at epoch 7\n",
      "Loss: 1.8820513486862183\n",
      "step 159 from 200 at epoch 7\n",
      "Loss: 1.9295358657836914\n",
      "step 169 from 200 at epoch 7\n",
      "Loss: 1.661472201347351\n",
      "step 179 from 200 at epoch 7\n",
      "Loss: 1.8331506252288818\n",
      "step 189 from 200 at epoch 7\n",
      "Loss: 1.5513298511505127\n",
      "step 199 from 200 at epoch 7\n",
      "Loss: 2.2139835357666016\n",
      "epoch 7 evaluation\n",
      "epoch loss 1.776250159740448\n",
      "========================================================================================================\n",
      "epoch 8\n",
      "step 9 from 200 at epoch 8\n",
      "Loss: 1.8202999830245972\n",
      "step 19 from 200 at epoch 8\n",
      "Loss: 1.8934346437454224\n",
      "step 29 from 200 at epoch 8\n",
      "Loss: 1.6439205408096313\n",
      "step 39 from 200 at epoch 8\n",
      "Loss: 1.5782246589660645\n",
      "step 49 from 200 at epoch 8\n",
      "Loss: 1.7463445663452148\n",
      "step 59 from 200 at epoch 8\n",
      "Loss: 1.9026292562484741\n",
      "step 69 from 200 at epoch 8\n",
      "Loss: 2.1171343326568604\n",
      "step 79 from 200 at epoch 8\n",
      "Loss: 1.5245431661605835\n",
      "step 89 from 200 at epoch 8\n",
      "Loss: 1.629531741142273\n",
      "step 99 from 200 at epoch 8\n",
      "Loss: 2.0748915672302246\n",
      "step 109 from 200 at epoch 8\n",
      "Loss: 1.73810613155365\n",
      "step 119 from 200 at epoch 8\n",
      "Loss: 1.5489492416381836\n",
      "step 129 from 200 at epoch 8\n",
      "Loss: 1.557693600654602\n",
      "step 139 from 200 at epoch 8\n",
      "Loss: 1.904649019241333\n",
      "step 149 from 200 at epoch 8\n",
      "Loss: 1.880569577217102\n",
      "step 159 from 200 at epoch 8\n",
      "Loss: 1.9170178174972534\n",
      "step 169 from 200 at epoch 8\n",
      "Loss: 1.6567223072052002\n",
      "step 179 from 200 at epoch 8\n",
      "Loss: 1.8241393566131592\n",
      "step 189 from 200 at epoch 8\n",
      "Loss: 1.5487911701202393\n",
      "step 199 from 200 at epoch 8\n",
      "Loss: 2.1963918209075928\n",
      "epoch 8 evaluation\n",
      "epoch loss 1.7664990067481994\n",
      "========================================================================================================\n",
      "epoch 9\n",
      "step 9 from 200 at epoch 9\n",
      "Loss: 1.8237570524215698\n",
      "step 19 from 200 at epoch 9\n",
      "Loss: 1.88673996925354\n",
      "step 29 from 200 at epoch 9\n",
      "Loss: 1.6390659809112549\n",
      "step 39 from 200 at epoch 9\n",
      "Loss: 1.5737009048461914\n",
      "step 49 from 200 at epoch 9\n",
      "Loss: 1.7589935064315796\n",
      "step 59 from 200 at epoch 9\n",
      "Loss: 1.8918182849884033\n",
      "step 69 from 200 at epoch 9\n",
      "Loss: 2.1001946926116943\n",
      "step 79 from 200 at epoch 9\n",
      "Loss: 1.5269804000854492\n",
      "step 89 from 200 at epoch 9\n",
      "Loss: 1.6125057935714722\n",
      "step 99 from 200 at epoch 9\n",
      "Loss: 2.0658059120178223\n",
      "step 109 from 200 at epoch 9\n",
      "Loss: 1.7137335538864136\n",
      "step 119 from 200 at epoch 9\n",
      "Loss: 1.5200427770614624\n",
      "step 129 from 200 at epoch 9\n",
      "Loss: 1.5632755756378174\n",
      "step 139 from 200 at epoch 9\n",
      "Loss: 1.901929497718811\n",
      "step 149 from 200 at epoch 9\n",
      "Loss: 1.8794455528259277\n",
      "step 159 from 200 at epoch 9\n",
      "Loss: 1.907767653465271\n",
      "step 169 from 200 at epoch 9\n",
      "Loss: 1.6549361944198608\n",
      "step 179 from 200 at epoch 9\n",
      "Loss: 1.8180869817733765\n",
      "step 189 from 200 at epoch 9\n",
      "Loss: 1.547888159751892\n",
      "step 199 from 200 at epoch 9\n",
      "Loss: 2.182779550552368\n",
      "epoch 9 evaluation\n",
      "epoch loss 1.7606367284059525\n",
      "========================================================================================================\n",
      "epoch 10\n",
      "step 9 from 200 at epoch 10\n",
      "Loss: 1.8291970491409302\n",
      "step 19 from 200 at epoch 10\n",
      "Loss: 1.8839868307113647\n",
      "step 29 from 200 at epoch 10\n",
      "Loss: 1.637475609779358\n",
      "step 39 from 200 at epoch 10\n",
      "Loss: 1.5705795288085938\n",
      "step 49 from 200 at epoch 10\n",
      "Loss: 1.7689913511276245\n",
      "step 59 from 200 at epoch 10\n",
      "Loss: 1.8836474418640137\n",
      "step 69 from 200 at epoch 10\n",
      "Loss: 2.0878336429595947\n",
      "step 79 from 200 at epoch 10\n",
      "Loss: 1.5288631916046143\n",
      "step 89 from 200 at epoch 10\n",
      "Loss: 1.6023879051208496\n",
      "step 99 from 200 at epoch 10\n",
      "Loss: 2.0602309703826904\n",
      "step 109 from 200 at epoch 10\n",
      "Loss: 1.6959079504013062\n",
      "step 119 from 200 at epoch 10\n",
      "Loss: 1.5012866258621216\n",
      "step 129 from 200 at epoch 10\n",
      "Loss: 1.569181203842163\n",
      "step 139 from 200 at epoch 10\n",
      "Loss: 1.9005684852600098\n",
      "step 149 from 200 at epoch 10\n",
      "Loss: 1.8785583972930908\n",
      "step 159 from 200 at epoch 10\n",
      "Loss: 1.9008445739746094\n",
      "step 169 from 200 at epoch 10\n",
      "Loss: 1.6560640335083008\n",
      "step 179 from 200 at epoch 10\n",
      "Loss: 1.8159619569778442\n",
      "step 189 from 200 at epoch 10\n",
      "Loss: 1.5471841096878052\n",
      "step 199 from 200 at epoch 10\n",
      "Loss: 2.1718595027923584\n",
      "epoch 10 evaluation\n",
      "epoch loss 1.756956353187561\n",
      "========================================================================================================\n",
      "epoch 11\n",
      "step 9 from 200 at epoch 11\n",
      "Loss: 1.8341511487960815\n",
      "step 19 from 200 at epoch 11\n",
      "Loss: 1.8842822313308716\n",
      "step 29 from 200 at epoch 11\n",
      "Loss: 1.6398746967315674\n",
      "step 39 from 200 at epoch 11\n",
      "Loss: 1.5692366361618042\n",
      "step 49 from 200 at epoch 11\n",
      "Loss: 1.7763043642044067\n",
      "step 59 from 200 at epoch 11\n",
      "Loss: 1.8801488876342773\n",
      "step 69 from 200 at epoch 11\n",
      "Loss: 2.0786521434783936\n",
      "step 79 from 200 at epoch 11\n",
      "Loss: 1.5302637815475464\n",
      "step 89 from 200 at epoch 11\n",
      "Loss: 1.5947738885879517\n",
      "step 99 from 200 at epoch 11\n",
      "Loss: 2.0561044216156006\n",
      "step 109 from 200 at epoch 11\n",
      "Loss: 1.6830627918243408\n",
      "step 119 from 200 at epoch 11\n",
      "Loss: 1.4897292852401733\n",
      "step 129 from 200 at epoch 11\n",
      "Loss: 1.5736100673675537\n",
      "step 139 from 200 at epoch 11\n",
      "Loss: 1.8994084596633911\n",
      "step 149 from 200 at epoch 11\n",
      "Loss: 1.8786453008651733\n",
      "step 159 from 200 at epoch 11\n",
      "Loss: 1.8978173732757568\n",
      "step 169 from 200 at epoch 11\n",
      "Loss: 1.6578609943389893\n",
      "step 179 from 200 at epoch 11\n",
      "Loss: 1.8145699501037598\n",
      "step 189 from 200 at epoch 11\n",
      "Loss: 1.5466279983520508\n",
      "step 199 from 200 at epoch 11\n",
      "Loss: 2.163600206375122\n",
      "epoch 11 evaluation\n",
      "epoch loss 1.7548423165082931\n",
      "========================================================================================================\n",
      "epoch 12\n",
      "step 9 from 200 at epoch 12\n",
      "Loss: 1.8376301527023315\n",
      "step 19 from 200 at epoch 12\n",
      "Loss: 1.8849396705627441\n",
      "step 29 from 200 at epoch 12\n",
      "Loss: 1.6417880058288574\n",
      "step 39 from 200 at epoch 12\n",
      "Loss: 1.5707284212112427\n",
      "step 49 from 200 at epoch 12\n",
      "Loss: 1.781122088432312\n",
      "step 59 from 200 at epoch 12\n",
      "Loss: 1.877823829650879\n",
      "step 69 from 200 at epoch 12\n",
      "Loss: 2.072674036026001\n",
      "step 79 from 200 at epoch 12\n",
      "Loss: 1.5312185287475586\n",
      "step 89 from 200 at epoch 12\n",
      "Loss: 1.5894917249679565\n",
      "step 99 from 200 at epoch 12\n",
      "Loss: 2.0543715953826904\n",
      "step 109 from 200 at epoch 12\n",
      "Loss: 1.6740306615829468\n",
      "step 119 from 200 at epoch 12\n",
      "Loss: 1.482871413230896\n",
      "step 129 from 200 at epoch 12\n",
      "Loss: 1.5766125917434692\n",
      "step 139 from 200 at epoch 12\n",
      "Loss: 1.8990256786346436\n",
      "step 149 from 200 at epoch 12\n",
      "Loss: 1.8789775371551514\n",
      "step 159 from 200 at epoch 12\n",
      "Loss: 1.8956278562545776\n",
      "step 169 from 200 at epoch 12\n",
      "Loss: 1.6592071056365967\n",
      "step 179 from 200 at epoch 12\n",
      "Loss: 1.8134047985076904\n",
      "step 189 from 200 at epoch 12\n",
      "Loss: 1.5461699962615967\n",
      "step 199 from 200 at epoch 12\n",
      "Loss: 2.157289981842041\n",
      "epoch 12 evaluation\n",
      "epoch loss 1.753478275537491\n",
      "========================================================================================================\n",
      "epoch 13\n",
      "step 9 from 200 at epoch 13\n",
      "Loss: 1.8400850296020508\n",
      "step 19 from 200 at epoch 13\n",
      "Loss: 1.88519287109375\n",
      "step 29 from 200 at epoch 13\n",
      "Loss: 1.643123745918274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39 from 200 at epoch 13\n",
      "Loss: 1.5725260972976685\n",
      "step 49 from 200 at epoch 13\n",
      "Loss: 1.7843724489212036\n",
      "step 59 from 200 at epoch 13\n",
      "Loss: 1.8761355876922607\n",
      "step 69 from 200 at epoch 13\n",
      "Loss: 2.068847417831421\n",
      "step 79 from 200 at epoch 13\n",
      "Loss: 1.5323727130889893\n",
      "step 89 from 200 at epoch 13\n",
      "Loss: 1.5855287313461304\n",
      "step 99 from 200 at epoch 13\n",
      "Loss: 2.052938461303711\n",
      "step 109 from 200 at epoch 13\n",
      "Loss: 1.6670811176300049\n",
      "step 119 from 200 at epoch 13\n",
      "Loss: 1.4781934022903442\n",
      "step 129 from 200 at epoch 13\n",
      "Loss: 1.5787243843078613\n",
      "step 139 from 200 at epoch 13\n",
      "Loss: 1.89936101436615\n",
      "step 149 from 200 at epoch 13\n",
      "Loss: 1.879145622253418\n",
      "step 159 from 200 at epoch 13\n",
      "Loss: 1.8938409090042114\n",
      "step 169 from 200 at epoch 13\n",
      "Loss: 1.6608192920684814\n",
      "step 179 from 200 at epoch 13\n",
      "Loss: 1.812362551689148\n",
      "step 189 from 200 at epoch 13\n",
      "Loss: 1.5457921028137207\n",
      "step 199 from 200 at epoch 13\n",
      "Loss: 2.152639865875244\n",
      "epoch 13 evaluation\n",
      "epoch loss 1.7525192803144456\n",
      "========================================================================================================\n",
      "epoch 14\n",
      "step 9 from 200 at epoch 14\n",
      "Loss: 1.8422675132751465\n",
      "step 19 from 200 at epoch 14\n",
      "Loss: 1.8850878477096558\n",
      "step 29 from 200 at epoch 14\n",
      "Loss: 1.6439764499664307\n",
      "step 39 from 200 at epoch 14\n",
      "Loss: 1.5738043785095215\n",
      "step 49 from 200 at epoch 14\n",
      "Loss: 1.786861777305603\n",
      "step 59 from 200 at epoch 14\n",
      "Loss: 1.8749924898147583\n",
      "step 69 from 200 at epoch 14\n",
      "Loss: 2.066366195678711\n",
      "step 79 from 200 at epoch 14\n",
      "Loss: 1.5333572626113892\n",
      "step 89 from 200 at epoch 14\n",
      "Loss: 1.5829429626464844\n",
      "step 99 from 200 at epoch 14\n",
      "Loss: 2.0518598556518555\n",
      "step 109 from 200 at epoch 14\n",
      "Loss: 1.663204312324524\n",
      "step 119 from 200 at epoch 14\n",
      "Loss: 1.4752432107925415\n",
      "step 129 from 200 at epoch 14\n",
      "Loss: 1.5797048807144165\n",
      "step 139 from 200 at epoch 14\n",
      "Loss: 1.8994702100753784\n",
      "step 149 from 200 at epoch 14\n",
      "Loss: 1.87908935546875\n",
      "step 159 from 200 at epoch 14\n",
      "Loss: 1.8924744129180908\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = []\n",
    "loss_eval = []\n",
    "\n",
    "print(timestamp)\n",
    "print(f'Start training model {str(model)}')\n",
    "for i in range(epochs):\n",
    "    loss.append(train(model, training_generator, optimizer, criterion, epoch=i, writer=writer, device=device))\n",
    "    loss_eval.append(evaluate(model, valid_generator, criterion, epoch=i, writer=writer, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d158ed43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocp-models-env",
   "language": "python",
   "name": "ocp-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
